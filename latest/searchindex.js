Search.setIndex({"docnames": ["autoapi/neural_compressor/algorithm/algorithm/index", "autoapi/neural_compressor/algorithm/fast_bias_correction/index", "autoapi/neural_compressor/algorithm/index", "autoapi/neural_compressor/algorithm/smooth_quant/index", "autoapi/neural_compressor/algorithm/weight_correction/index", "autoapi/neural_compressor/benchmark/index", "autoapi/neural_compressor/common/base_config/index", "autoapi/neural_compressor/common/base_tuning/index", "autoapi/neural_compressor/common/benchmark/index", "autoapi/neural_compressor/common/index", "autoapi/neural_compressor/common/tuning_param/index", "autoapi/neural_compressor/common/utils/constants/index", "autoapi/neural_compressor/common/utils/index", "autoapi/neural_compressor/common/utils/logger/index", "autoapi/neural_compressor/common/utils/save_load/index", "autoapi/neural_compressor/common/utils/utility/index", "autoapi/neural_compressor/config/index", "autoapi/neural_compressor/contrib/index", "autoapi/neural_compressor/contrib/strategy/index", "autoapi/neural_compressor/contrib/strategy/sigopt/index", "autoapi/neural_compressor/contrib/strategy/tpe/index", "autoapi/neural_compressor/data/datasets/bert_dataset/index", "autoapi/neural_compressor/data/datasets/coco_dataset/index", "autoapi/neural_compressor/data/datasets/dataset/index", "autoapi/neural_compressor/data/datasets/dummy_dataset/index", "autoapi/neural_compressor/data/datasets/dummy_dataset_v2/index", "autoapi/neural_compressor/data/datasets/imagenet_dataset/index", "autoapi/neural_compressor/data/datasets/index", "autoapi/neural_compressor/data/datasets/style_transfer_dataset/index", "autoapi/neural_compressor/data/filters/coco_filter/index", "autoapi/neural_compressor/data/filters/filter/index", "autoapi/neural_compressor/data/filters/index", "autoapi/neural_compressor/data/index", "autoapi/neural_compressor/data/transforms/imagenet_transform/index", "autoapi/neural_compressor/data/transforms/index", "autoapi/neural_compressor/data/transforms/postprocess/index", "autoapi/neural_compressor/data/transforms/tokenization/index", "autoapi/neural_compressor/data/transforms/transform/index", "autoapi/neural_compressor/index", "autoapi/neural_compressor/metric/bleu/index", "autoapi/neural_compressor/metric/bleu_util/index", "autoapi/neural_compressor/metric/coco_label_map/index", "autoapi/neural_compressor/metric/coco_tools/index", "autoapi/neural_compressor/metric/evaluate_squad/index", "autoapi/neural_compressor/metric/f1/index", "autoapi/neural_compressor/metric/index", "autoapi/neural_compressor/metric/metric/index", "autoapi/neural_compressor/mix_precision/index", "autoapi/neural_compressor/model/base_model/index", "autoapi/neural_compressor/model/index", "autoapi/neural_compressor/model/keras_model/index", "autoapi/neural_compressor/model/model/index", "autoapi/neural_compressor/model/mxnet_model/index", "autoapi/neural_compressor/model/nets_factory/index", "autoapi/neural_compressor/model/onnx_model/index", "autoapi/neural_compressor/model/tensorflow_model/index", "autoapi/neural_compressor/model/torch_model/index", "autoapi/neural_compressor/objective/index", "autoapi/neural_compressor/profiling/index", "autoapi/neural_compressor/quantization/index", "autoapi/neural_compressor/strategy/auto/index", "autoapi/neural_compressor/strategy/auto_mixed_precision/index", "autoapi/neural_compressor/strategy/basic/index", "autoapi/neural_compressor/strategy/bayesian/index", "autoapi/neural_compressor/strategy/conservative/index", "autoapi/neural_compressor/strategy/exhaustive/index", "autoapi/neural_compressor/strategy/hawq_v2/index", "autoapi/neural_compressor/strategy/index", "autoapi/neural_compressor/strategy/mse/index", "autoapi/neural_compressor/strategy/mse_v2/index", "autoapi/neural_compressor/strategy/random/index", "autoapi/neural_compressor/strategy/strategy/index", "autoapi/neural_compressor/strategy/utils/constant/index", "autoapi/neural_compressor/strategy/utils/index", "autoapi/neural_compressor/strategy/utils/tuning_sampler/index", "autoapi/neural_compressor/strategy/utils/tuning_space/index", "autoapi/neural_compressor/strategy/utils/tuning_structs/index", "autoapi/neural_compressor/strategy/utils/utility/index", "autoapi/neural_compressor/tensorflow/algorithms/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/tensorflow/index", "autoapi/neural_compressor/tensorflow/index", "autoapi/neural_compressor/tensorflow/keras/index", "autoapi/neural_compressor/tensorflow/keras/layers/conv2d/index", "autoapi/neural_compressor/tensorflow/keras/layers/dense/index", "autoapi/neural_compressor/tensorflow/keras/layers/depthwise_conv2d/index", "autoapi/neural_compressor/tensorflow/keras/layers/index", "autoapi/neural_compressor/tensorflow/keras/layers/layer_initializer/index", "autoapi/neural_compressor/tensorflow/keras/layers/pool2d/index", "autoapi/neural_compressor/tensorflow/keras/layers/separable_conv2d/index", "autoapi/neural_compressor/tensorflow/keras/quantization/config/index", "autoapi/neural_compressor/tensorflow/keras/quantization/index", "autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index", "autoapi/neural_compressor/tensorflow/quantization/autotune/index", "autoapi/neural_compressor/tensorflow/quantization/config/index", "autoapi/neural_compressor/tensorflow/quantization/index", "autoapi/neural_compressor/tensorflow/quantization/quantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/bf16_convert/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/dequantize_cast_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_fake_quant/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_requantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_requantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/meta_op_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_hostconst_converter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_quantized_op_cse/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/scale_propagation/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/insert_qdq_pattern/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/merge_duplicated_qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/share_qdq_y_pattern/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index", "autoapi/neural_compressor/tensorflow/quantization/utils/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_concatv2/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_deconv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_in/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_matmul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_pooling/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/optimize_qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_concatv2/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_for_intel_cpu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_matmul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_pooling/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/bias_correction/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/graph_transform_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/insert_logging/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/rerange_quantized_concat/index", "autoapi/neural_compressor/tensorflow/quantization/utils/utility/index", "autoapi/neural_compressor/tensorflow/utils/constants/index", "autoapi/neural_compressor/tensorflow/utils/data/index", "autoapi/neural_compressor/tensorflow/utils/index", "autoapi/neural_compressor/tensorflow/utils/model/index", "autoapi/neural_compressor/tensorflow/utils/model_wrappers/index", "autoapi/neural_compressor/tensorflow/utils/utility/index", "autoapi/neural_compressor/torch/algorithms/base_algorithm/index", "autoapi/neural_compressor/torch/algorithms/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/load/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index", "autoapi/neural_compressor/torch/algorithms/mixed_precision/half_precision_convert/index", "autoapi/neural_compressor/torch/algorithms/mixed_precision/index", "autoapi/neural_compressor/torch/algorithms/mixed_precision/module_wrappers/index", "autoapi/neural_compressor/torch/algorithms/mx_quant/index", "autoapi/neural_compressor/torch/algorithms/mx_quant/mx/index", "autoapi/neural_compressor/torch/algorithms/mx_quant/utils/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/core/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/half_precision_rewriter/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/save_load/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/utility/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/save_load/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/smooth_quant/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/utility/index", "autoapi/neural_compressor/torch/algorithms/static_quant/index", "autoapi/neural_compressor/torch/algorithms/static_quant/save_load/index", "autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index", "autoapi/neural_compressor/torch/algorithms/static_quant/utility/index", "autoapi/neural_compressor/torch/algorithms/weight_only/autoround/index", "autoapi/neural_compressor/torch/algorithms/weight_only/awq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index", "autoapi/neural_compressor/torch/algorithms/weight_only/index", "autoapi/neural_compressor/torch/algorithms/weight_only/modules/index", "autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index", "autoapi/neural_compressor/torch/algorithms/weight_only/save_load/index", "autoapi/neural_compressor/torch/algorithms/weight_only/teq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/utility/index", "autoapi/neural_compressor/torch/export/index", "autoapi/neural_compressor/torch/export/pt2e_export/index", "autoapi/neural_compressor/torch/index", "autoapi/neural_compressor/torch/quantization/algorithm_entry/index", "autoapi/neural_compressor/torch/quantization/autotune/index", "autoapi/neural_compressor/torch/quantization/config/index", "autoapi/neural_compressor/torch/quantization/index", "autoapi/neural_compressor/torch/quantization/load_entry/index", "autoapi/neural_compressor/torch/quantization/quantize/index", "autoapi/neural_compressor/torch/utils/auto_accelerator/index", "autoapi/neural_compressor/torch/utils/constants/index", "autoapi/neural_compressor/torch/utils/environ/index", "autoapi/neural_compressor/torch/utils/index", "autoapi/neural_compressor/torch/utils/utility/index", "autoapi/neural_compressor/training/index", "autoapi/neural_compressor/utils/collect_layer_histogram/index", "autoapi/neural_compressor/utils/constant/index", "autoapi/neural_compressor/utils/create_obj_from_config/index", "autoapi/neural_compressor/utils/export/index", "autoapi/neural_compressor/utils/export/qlinear2qdq/index", "autoapi/neural_compressor/utils/export/tf2onnx/index", "autoapi/neural_compressor/utils/export/torch2onnx/index", "autoapi/neural_compressor/utils/index", "autoapi/neural_compressor/utils/kl_divergence/index", "autoapi/neural_compressor/utils/load_huggingface/index", "autoapi/neural_compressor/utils/logger/index", "autoapi/neural_compressor/utils/options/index", "autoapi/neural_compressor/utils/pytorch/index", "autoapi/neural_compressor/utils/utility/index", "autoapi/neural_compressor/utils/weights_details/index", "autoapi/neural_compressor/version/index", "docs/3x/PT_FP8Quant", "docs/build_docs/source/index", "docs/source/2x_user_guide", "docs/source/3x/PT_DynamicQuant", "docs/source/3x/PT_MXQuant", "docs/source/3x/PT_MixedPrecision", "docs/source/3x/PT_SmoothQuant", "docs/source/3x/PT_StaticQuant", "docs/source/3x/PT_WeightOnlyQuant", "docs/source/3x/PyTorch", "docs/source/3x/TF_Quant", "docs/source/3x/TF_SQ", "docs/source/3x/TensorFlow", "docs/source/3x/autotune", "docs/source/3x/benchmark", "docs/source/3x/client_quant", "docs/source/3x/design", "docs/source/3x/gaudi_version_map", "docs/source/3x/llm_recipes", "docs/source/3x/quantization", "docs/source/CODE_OF_CONDUCT", "docs/source/CONTRIBUTING", "docs/source/FX", "docs/source/SECURITY", "docs/source/Welcome", "docs/source/adaptor", "docs/source/add_new_adaptor", "docs/source/add_new_data_type", "docs/source/api-doc/adaptor", "docs/source/api-doc/adaptor/onnxrt", "docs/source/api-doc/adaptor/torch_utils", "docs/source/api-doc/api_2", "docs/source/api-doc/api_3", "docs/source/api-doc/api_doc_example", "docs/source/api-doc/apis", "docs/source/api-doc/benchmark", "docs/source/api-doc/compression", "docs/source/api-doc/config", "docs/source/api-doc/mix_precision", "docs/source/api-doc/model", "docs/source/api-doc/objective", "docs/source/api-doc/quantization", "docs/source/api-doc/strategy", "docs/source/api-doc/tf_quantization_autotune", "docs/source/api-doc/tf_quantization_common", "docs/source/api-doc/tf_quantization_config", "docs/source/api-doc/torch_quantization_autotune", "docs/source/api-doc/torch_quantization_common", "docs/source/api-doc/torch_quantization_config", "docs/source/api-doc/training", "docs/source/benchmark", "docs/source/calibration", "docs/source/coding_style", "docs/source/dataloader", "docs/source/design", "docs/source/distillation_quantization", "docs/source/distributed", "docs/source/examples_readme", "docs/source/export", "docs/source/faq", "docs/source/framework_yaml", "docs/source/get_started", "docs/source/incompatible_changes", "docs/source/infrastructure", "docs/source/installation_guide", "docs/source/legal_information", "docs/source/llm_recipes", "docs/source/metric", "docs/source/migration", "docs/source/mixed_precision", "docs/source/model", "docs/source/mx_quantization", "docs/source/objective", "docs/source/orchestration", "docs/source/pruning", "docs/source/publication_list", "docs/source/quantization", "docs/source/quantization_layer_wise", "docs/source/quantization_mixed_precision", "docs/source/quantization_weight_only", "docs/source/releases_info", "docs/source/sigopt_strategy", "docs/source/smooth_quant", "docs/source/transform", "docs/source/tuning_strategies", "docs/source/validated_model_list", "index"], "filenames": ["autoapi/neural_compressor/algorithm/algorithm/index.rst", "autoapi/neural_compressor/algorithm/fast_bias_correction/index.rst", "autoapi/neural_compressor/algorithm/index.rst", "autoapi/neural_compressor/algorithm/smooth_quant/index.rst", "autoapi/neural_compressor/algorithm/weight_correction/index.rst", "autoapi/neural_compressor/benchmark/index.rst", "autoapi/neural_compressor/common/base_config/index.rst", "autoapi/neural_compressor/common/base_tuning/index.rst", "autoapi/neural_compressor/common/benchmark/index.rst", "autoapi/neural_compressor/common/index.rst", "autoapi/neural_compressor/common/tuning_param/index.rst", "autoapi/neural_compressor/common/utils/constants/index.rst", "autoapi/neural_compressor/common/utils/index.rst", "autoapi/neural_compressor/common/utils/logger/index.rst", "autoapi/neural_compressor/common/utils/save_load/index.rst", "autoapi/neural_compressor/common/utils/utility/index.rst", "autoapi/neural_compressor/config/index.rst", "autoapi/neural_compressor/contrib/index.rst", "autoapi/neural_compressor/contrib/strategy/index.rst", "autoapi/neural_compressor/contrib/strategy/sigopt/index.rst", "autoapi/neural_compressor/contrib/strategy/tpe/index.rst", "autoapi/neural_compressor/data/datasets/bert_dataset/index.rst", "autoapi/neural_compressor/data/datasets/coco_dataset/index.rst", "autoapi/neural_compressor/data/datasets/dataset/index.rst", "autoapi/neural_compressor/data/datasets/dummy_dataset/index.rst", "autoapi/neural_compressor/data/datasets/dummy_dataset_v2/index.rst", "autoapi/neural_compressor/data/datasets/imagenet_dataset/index.rst", "autoapi/neural_compressor/data/datasets/index.rst", "autoapi/neural_compressor/data/datasets/style_transfer_dataset/index.rst", "autoapi/neural_compressor/data/filters/coco_filter/index.rst", "autoapi/neural_compressor/data/filters/filter/index.rst", "autoapi/neural_compressor/data/filters/index.rst", "autoapi/neural_compressor/data/index.rst", "autoapi/neural_compressor/data/transforms/imagenet_transform/index.rst", "autoapi/neural_compressor/data/transforms/index.rst", "autoapi/neural_compressor/data/transforms/postprocess/index.rst", "autoapi/neural_compressor/data/transforms/tokenization/index.rst", "autoapi/neural_compressor/data/transforms/transform/index.rst", "autoapi/neural_compressor/index.rst", "autoapi/neural_compressor/metric/bleu/index.rst", "autoapi/neural_compressor/metric/bleu_util/index.rst", "autoapi/neural_compressor/metric/coco_label_map/index.rst", "autoapi/neural_compressor/metric/coco_tools/index.rst", "autoapi/neural_compressor/metric/evaluate_squad/index.rst", "autoapi/neural_compressor/metric/f1/index.rst", "autoapi/neural_compressor/metric/index.rst", "autoapi/neural_compressor/metric/metric/index.rst", "autoapi/neural_compressor/mix_precision/index.rst", "autoapi/neural_compressor/model/base_model/index.rst", "autoapi/neural_compressor/model/index.rst", "autoapi/neural_compressor/model/keras_model/index.rst", "autoapi/neural_compressor/model/model/index.rst", "autoapi/neural_compressor/model/mxnet_model/index.rst", "autoapi/neural_compressor/model/nets_factory/index.rst", "autoapi/neural_compressor/model/onnx_model/index.rst", "autoapi/neural_compressor/model/tensorflow_model/index.rst", "autoapi/neural_compressor/model/torch_model/index.rst", "autoapi/neural_compressor/objective/index.rst", "autoapi/neural_compressor/profiling/index.rst", "autoapi/neural_compressor/quantization/index.rst", "autoapi/neural_compressor/strategy/auto/index.rst", "autoapi/neural_compressor/strategy/auto_mixed_precision/index.rst", "autoapi/neural_compressor/strategy/basic/index.rst", "autoapi/neural_compressor/strategy/bayesian/index.rst", "autoapi/neural_compressor/strategy/conservative/index.rst", "autoapi/neural_compressor/strategy/exhaustive/index.rst", "autoapi/neural_compressor/strategy/hawq_v2/index.rst", "autoapi/neural_compressor/strategy/index.rst", "autoapi/neural_compressor/strategy/mse/index.rst", "autoapi/neural_compressor/strategy/mse_v2/index.rst", "autoapi/neural_compressor/strategy/random/index.rst", "autoapi/neural_compressor/strategy/strategy/index.rst", "autoapi/neural_compressor/strategy/utils/constant/index.rst", "autoapi/neural_compressor/strategy/utils/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_sampler/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_space/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_structs/index.rst", "autoapi/neural_compressor/strategy/utils/utility/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/tensorflow/index.rst", "autoapi/neural_compressor/tensorflow/index.rst", "autoapi/neural_compressor/tensorflow/keras/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/conv2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/dense/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/depthwise_conv2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/layer_initializer/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/pool2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/separable_conv2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/quantization/config/index.rst", "autoapi/neural_compressor/tensorflow/keras/quantization/index.rst", "autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/tensorflow/quantization/autotune/index.rst", "autoapi/neural_compressor/tensorflow/quantization/config/index.rst", "autoapi/neural_compressor/tensorflow/quantization/index.rst", "autoapi/neural_compressor/tensorflow/quantization/quantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/bf16_convert/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/dequantize_cast_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_fake_quant/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_requantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_requantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/meta_op_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_hostconst_converter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_quantized_op_cse/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/scale_propagation/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/insert_qdq_pattern/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/merge_duplicated_qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/share_qdq_y_pattern/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_concatv2/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_deconv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_in/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_matmul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_pooling/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/optimize_qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_concatv2/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_for_intel_cpu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_matmul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_pooling/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/bias_correction/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/graph_transform_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/insert_logging/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/rerange_quantized_concat/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/utility/index.rst", "autoapi/neural_compressor/tensorflow/utils/constants/index.rst", "autoapi/neural_compressor/tensorflow/utils/data/index.rst", "autoapi/neural_compressor/tensorflow/utils/index.rst", "autoapi/neural_compressor/tensorflow/utils/model/index.rst", "autoapi/neural_compressor/tensorflow/utils/model_wrappers/index.rst", "autoapi/neural_compressor/tensorflow/utils/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/base_algorithm/index.rst", "autoapi/neural_compressor/torch/algorithms/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/load/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index.rst", "autoapi/neural_compressor/torch/algorithms/mixed_precision/half_precision_convert/index.rst", "autoapi/neural_compressor/torch/algorithms/mixed_precision/index.rst", "autoapi/neural_compressor/torch/algorithms/mixed_precision/module_wrappers/index.rst", "autoapi/neural_compressor/torch/algorithms/mx_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/mx_quant/mx/index.rst", "autoapi/neural_compressor/torch/algorithms/mx_quant/utils/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/core/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/half_precision_rewriter/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/smooth_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/autoround/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/awq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/modules/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/teq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/utility/index.rst", "autoapi/neural_compressor/torch/export/index.rst", "autoapi/neural_compressor/torch/export/pt2e_export/index.rst", "autoapi/neural_compressor/torch/index.rst", "autoapi/neural_compressor/torch/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/torch/quantization/autotune/index.rst", "autoapi/neural_compressor/torch/quantization/config/index.rst", "autoapi/neural_compressor/torch/quantization/index.rst", "autoapi/neural_compressor/torch/quantization/load_entry/index.rst", "autoapi/neural_compressor/torch/quantization/quantize/index.rst", "autoapi/neural_compressor/torch/utils/auto_accelerator/index.rst", "autoapi/neural_compressor/torch/utils/constants/index.rst", "autoapi/neural_compressor/torch/utils/environ/index.rst", "autoapi/neural_compressor/torch/utils/index.rst", "autoapi/neural_compressor/torch/utils/utility/index.rst", "autoapi/neural_compressor/training/index.rst", "autoapi/neural_compressor/utils/collect_layer_histogram/index.rst", "autoapi/neural_compressor/utils/constant/index.rst", "autoapi/neural_compressor/utils/create_obj_from_config/index.rst", "autoapi/neural_compressor/utils/export/index.rst", "autoapi/neural_compressor/utils/export/qlinear2qdq/index.rst", "autoapi/neural_compressor/utils/export/tf2onnx/index.rst", "autoapi/neural_compressor/utils/export/torch2onnx/index.rst", "autoapi/neural_compressor/utils/index.rst", "autoapi/neural_compressor/utils/kl_divergence/index.rst", "autoapi/neural_compressor/utils/load_huggingface/index.rst", "autoapi/neural_compressor/utils/logger/index.rst", "autoapi/neural_compressor/utils/options/index.rst", "autoapi/neural_compressor/utils/pytorch/index.rst", "autoapi/neural_compressor/utils/utility/index.rst", "autoapi/neural_compressor/utils/weights_details/index.rst", "autoapi/neural_compressor/version/index.rst", "docs/3x/PT_FP8Quant.md", "docs/build_docs/source/index.rst", "docs/source/2x_user_guide.md", "docs/source/3x/PT_DynamicQuant.md", "docs/source/3x/PT_MXQuant.md", "docs/source/3x/PT_MixedPrecision.md", "docs/source/3x/PT_SmoothQuant.md", "docs/source/3x/PT_StaticQuant.md", "docs/source/3x/PT_WeightOnlyQuant.md", "docs/source/3x/PyTorch.md", "docs/source/3x/TF_Quant.md", "docs/source/3x/TF_SQ.md", "docs/source/3x/TensorFlow.md", "docs/source/3x/autotune.md", "docs/source/3x/benchmark.md", "docs/source/3x/client_quant.md", "docs/source/3x/design.md", "docs/source/3x/gaudi_version_map.md", "docs/source/3x/llm_recipes.md", "docs/source/3x/quantization.md", "docs/source/CODE_OF_CONDUCT.md", "docs/source/CONTRIBUTING.md", "docs/source/FX.md", "docs/source/SECURITY.md", "docs/source/Welcome.md", "docs/source/adaptor.md", "docs/source/add_new_adaptor.md", "docs/source/add_new_data_type.md", "docs/source/api-doc/adaptor.rst", "docs/source/api-doc/adaptor/onnxrt.rst", "docs/source/api-doc/adaptor/torch_utils.rst", "docs/source/api-doc/api_2.rst", "docs/source/api-doc/api_3.rst", "docs/source/api-doc/api_doc_example.rst", "docs/source/api-doc/apis.rst", "docs/source/api-doc/benchmark.rst", "docs/source/api-doc/compression.rst", "docs/source/api-doc/config.rst", "docs/source/api-doc/mix_precision.rst", "docs/source/api-doc/model.rst", "docs/source/api-doc/objective.rst", "docs/source/api-doc/quantization.rst", "docs/source/api-doc/strategy.rst", "docs/source/api-doc/tf_quantization_autotune.rst", "docs/source/api-doc/tf_quantization_common.rst", "docs/source/api-doc/tf_quantization_config.rst", "docs/source/api-doc/torch_quantization_autotune.rst", "docs/source/api-doc/torch_quantization_common.rst", "docs/source/api-doc/torch_quantization_config.rst", "docs/source/api-doc/training.rst", "docs/source/benchmark.md", "docs/source/calibration.md", "docs/source/coding_style.md", "docs/source/dataloader.md", "docs/source/design.md", "docs/source/distillation_quantization.md", "docs/source/distributed.md", "docs/source/examples_readme.md", "docs/source/export.md", "docs/source/faq.md", "docs/source/framework_yaml.md", "docs/source/get_started.md", "docs/source/incompatible_changes.md", "docs/source/infrastructure.md", "docs/source/installation_guide.md", "docs/source/legal_information.md", "docs/source/llm_recipes.md", "docs/source/metric.md", "docs/source/migration.md", "docs/source/mixed_precision.md", "docs/source/model.md", "docs/source/mx_quantization.md", "docs/source/objective.md", "docs/source/orchestration.md", "docs/source/pruning.md", "docs/source/publication_list.md", "docs/source/quantization.md", "docs/source/quantization_layer_wise.md", "docs/source/quantization_mixed_precision.md", "docs/source/quantization_weight_only.md", "docs/source/releases_info.md", "docs/source/sigopt_strategy.md", "docs/source/smooth_quant.md", "docs/source/transform.md", "docs/source/tuning_strategies.md", "docs/source/validated_model_list.md", "index.rst"], "titles": ["neural_compressor.algorithm.algorithm", "neural_compressor.algorithm.fast_bias_correction", "neural_compressor.algorithm", "neural_compressor.algorithm.smooth_quant", "neural_compressor.algorithm.weight_correction", "neural_compressor.benchmark", "neural_compressor.common.base_config", "neural_compressor.common.base_tuning", "neural_compressor.common.benchmark", "neural_compressor.common", "neural_compressor.common.tuning_param", "neural_compressor.common.utils.constants", "neural_compressor.common.utils", "neural_compressor.common.utils.logger", "neural_compressor.common.utils.save_load", "neural_compressor.common.utils.utility", "neural_compressor.config", "neural_compressor.contrib", "neural_compressor.contrib.strategy", "neural_compressor.contrib.strategy.sigopt", "neural_compressor.contrib.strategy.tpe", "neural_compressor.data.datasets.bert_dataset", "neural_compressor.data.datasets.coco_dataset", "neural_compressor.data.datasets.dataset", "neural_compressor.data.datasets.dummy_dataset", "neural_compressor.data.datasets.dummy_dataset_v2", "neural_compressor.data.datasets.imagenet_dataset", "neural_compressor.data.datasets", "neural_compressor.data.datasets.style_transfer_dataset", "neural_compressor.data.filters.coco_filter", "neural_compressor.data.filters.filter", "neural_compressor.data.filters", "neural_compressor.data", "neural_compressor.data.transforms.imagenet_transform", "neural_compressor.data.transforms", "neural_compressor.data.transforms.postprocess", "neural_compressor.data.transforms.tokenization", "neural_compressor.data.transforms.transform", "neural_compressor", "neural_compressor.metric.bleu", "neural_compressor.metric.bleu_util", "neural_compressor.metric.coco_label_map", "neural_compressor.metric.coco_tools", "neural_compressor.metric.evaluate_squad", "neural_compressor.metric.f1", "neural_compressor.metric", "neural_compressor.metric.metric", "neural_compressor.mix_precision", "neural_compressor.model.base_model", "neural_compressor.model", "neural_compressor.model.keras_model", "neural_compressor.model.model", "neural_compressor.model.mxnet_model", "neural_compressor.model.nets_factory", "neural_compressor.model.onnx_model", "neural_compressor.model.tensorflow_model", "neural_compressor.model.torch_model", "neural_compressor.objective", "neural_compressor.profiling", "neural_compressor.quantization", "neural_compressor.strategy.auto", "neural_compressor.strategy.auto_mixed_precision", "neural_compressor.strategy.basic", "neural_compressor.strategy.bayesian", "neural_compressor.strategy.conservative", "neural_compressor.strategy.exhaustive", "neural_compressor.strategy.hawq_v2", "neural_compressor.strategy", "neural_compressor.strategy.mse", "neural_compressor.strategy.mse_v2", "neural_compressor.strategy.random", "neural_compressor.strategy.strategy", "neural_compressor.strategy.utils.constant", "neural_compressor.strategy.utils", "neural_compressor.strategy.utils.tuning_sampler", "neural_compressor.strategy.utils.tuning_space", "neural_compressor.strategy.utils.tuning_structs", "neural_compressor.strategy.utils.utility", "neural_compressor.tensorflow.algorithms", "neural_compressor.tensorflow.algorithms.smoother.calibration", "neural_compressor.tensorflow.algorithms.smoother.core", "neural_compressor.tensorflow.algorithms.smoother", "neural_compressor.tensorflow.algorithms.smoother.scaler", "neural_compressor.tensorflow.algorithms.static_quant", "neural_compressor.tensorflow.algorithms.static_quant.keras", "neural_compressor.tensorflow.algorithms.static_quant.tensorflow", "neural_compressor.tensorflow", "neural_compressor.tensorflow.keras", "neural_compressor.tensorflow.keras.layers.conv2d", "neural_compressor.tensorflow.keras.layers.dense", "neural_compressor.tensorflow.keras.layers.depthwise_conv2d", "neural_compressor.tensorflow.keras.layers", "neural_compressor.tensorflow.keras.layers.layer_initializer", "neural_compressor.tensorflow.keras.layers.pool2d", "neural_compressor.tensorflow.keras.layers.separable_conv2d", "neural_compressor.tensorflow.keras.quantization.config", "neural_compressor.tensorflow.keras.quantization", "neural_compressor.tensorflow.quantization.algorithm_entry", "neural_compressor.tensorflow.quantization.autotune", "neural_compressor.tensorflow.quantization.config", "neural_compressor.tensorflow.quantization", "neural_compressor.tensorflow.quantization.quantize", "neural_compressor.tensorflow.quantization.utils.graph_converter", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base", "neural_compressor.tensorflow.quantization.utils.graph_rewriter", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq", "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern", "neural_compressor.tensorflow.quantization.utils.graph_util", "neural_compressor.tensorflow.quantization.utils", "neural_compressor.tensorflow.quantization.utils.quantize_graph", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq", "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul", "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling", "neural_compressor.tensorflow.quantization.utils.quantize_graph_common", "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction", "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base", "neural_compressor.tensorflow.quantization.utils.transform_graph", "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging", "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat", "neural_compressor.tensorflow.quantization.utils.utility", "neural_compressor.tensorflow.utils.constants", "neural_compressor.tensorflow.utils.data", "neural_compressor.tensorflow.utils", "neural_compressor.tensorflow.utils.model", "neural_compressor.tensorflow.utils.model_wrappers", "neural_compressor.tensorflow.utils.utility", "neural_compressor.torch.algorithms.base_algorithm", "neural_compressor.torch.algorithms", "neural_compressor.torch.algorithms.layer_wise", "neural_compressor.torch.algorithms.layer_wise.load", "neural_compressor.torch.algorithms.layer_wise.modified_pickle", "neural_compressor.torch.algorithms.layer_wise.utils", "neural_compressor.torch.algorithms.mixed_precision.half_precision_convert", "neural_compressor.torch.algorithms.mixed_precision", "neural_compressor.torch.algorithms.mixed_precision.module_wrappers", "neural_compressor.torch.algorithms.mx_quant", "neural_compressor.torch.algorithms.mx_quant.mx", "neural_compressor.torch.algorithms.mx_quant.utils", "neural_compressor.torch.algorithms.pt2e_quant.core", "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter", "neural_compressor.torch.algorithms.pt2e_quant", "neural_compressor.torch.algorithms.pt2e_quant.save_load", "neural_compressor.torch.algorithms.pt2e_quant.utility", "neural_compressor.torch.algorithms.smooth_quant", "neural_compressor.torch.algorithms.smooth_quant.save_load", "neural_compressor.torch.algorithms.smooth_quant.smooth_quant", "neural_compressor.torch.algorithms.smooth_quant.utility", "neural_compressor.torch.algorithms.static_quant", "neural_compressor.torch.algorithms.static_quant.save_load", "neural_compressor.torch.algorithms.static_quant.static_quant", "neural_compressor.torch.algorithms.static_quant.utility", "neural_compressor.torch.algorithms.weight_only.autoround", "neural_compressor.torch.algorithms.weight_only.awq", "neural_compressor.torch.algorithms.weight_only.gptq", "neural_compressor.torch.algorithms.weight_only.hqq.bitpack", "neural_compressor.torch.algorithms.weight_only.hqq.config", "neural_compressor.torch.algorithms.weight_only.hqq.core", "neural_compressor.torch.algorithms.weight_only.hqq", "neural_compressor.torch.algorithms.weight_only.hqq.optimizer", "neural_compressor.torch.algorithms.weight_only.hqq.qtensor", "neural_compressor.torch.algorithms.weight_only.hqq.quantizer", "neural_compressor.torch.algorithms.weight_only", "neural_compressor.torch.algorithms.weight_only.modules", "neural_compressor.torch.algorithms.weight_only.rtn", "neural_compressor.torch.algorithms.weight_only.save_load", "neural_compressor.torch.algorithms.weight_only.teq", "neural_compressor.torch.algorithms.weight_only.utility", "neural_compressor.torch.export", "neural_compressor.torch.export.pt2e_export", "neural_compressor.torch", "neural_compressor.torch.quantization.algorithm_entry", "neural_compressor.torch.quantization.autotune", "neural_compressor.torch.quantization.config", "neural_compressor.torch.quantization", "neural_compressor.torch.quantization.load_entry", "neural_compressor.torch.quantization.quantize", "neural_compressor.torch.utils.auto_accelerator", "neural_compressor.torch.utils.constants", "neural_compressor.torch.utils.environ", "neural_compressor.torch.utils", "neural_compressor.torch.utils.utility", "neural_compressor.training", "neural_compressor.utils.collect_layer_histogram", "neural_compressor.utils.constant", "neural_compressor.utils.create_obj_from_config", "neural_compressor.utils.export", "neural_compressor.utils.export.qlinear2qdq", "neural_compressor.utils.export.tf2onnx", "neural_compressor.utils.export.torch2onnx", "neural_compressor.utils", "neural_compressor.utils.kl_divergence", "neural_compressor.utils.load_huggingface", "neural_compressor.utils.logger", "neural_compressor.utils.options", "neural_compressor.utils.pytorch", "neural_compressor.utils.utility", "neural_compressor.utils.weights_details", "neural_compressor.version", "FP8 Quantization", "Intel\u00ae Neural Compressor Documentation", "2.X API User Guide", "Dynamic Quantization", "Microscaling Quantization", "PyTorch Mixed Precision", "PyTorch Smooth Quantization", "PyTorch Static Quantization", "PyTorch Weight Only Quantization", "Torch", "TensorFlow Quantization", "Smooth Quant", "TensorFlow", "AutoTune", "Benchmark", "Quantization on Client", "Design", "Version mapping between Intel Neural Compressor to Gaudi Software Stack", "&lt;no title&gt;", "Quantization", "Contributor Covenant Code of Conduct", "Contribution Guidelines", "FX", "Security Policy", "Intel\u00ae Neural Compressor", "Adaptor", "How to Add An Adaptor", "How to Support New Data Type, Like Int4, with a Few Line Changes", "Adaptor", "ONNX Runtime", "Torch Utils", "2.0 API", "3.0 API", "API Document Example", "APIs", "Benchmark", "Compression", "Config", "Mix Precision", "Model", "Objective", "Quantization", "Strategy", "Tensorflow Quantization AutoTune", "Tensorflow Quantization Base API", "Tensorflow Quantization Config", "Pytorch Quantization AutoTune", "Pytorch Quantization Base API", "Pytorch Quantization Config", "Training", "Benchmarking", "Calibration Algorithms in Quantization", "INC Coding Conventions", "DataLoader", "Design", "Distillation for Quantization", "Distributed Training and Inference (Evaluation)", "Examples", "Export", "Frequently Asked Questions", "Framework YAML Configuration Files", "Getting Started", "Incompatible changes between v1.2 and v1.1", "Infrastructure of Intel\u00ae Neural Compressor", "Installation", "Legal Information", "LLMs Quantization Recipes", "Metrics", "Code Migration from Intel Neural Compressor 1.X to Intel Neural Compressor 2.X", "Mixed Precision", "Model", "Microscaling Quantization", "Objective", "Optimization Orchestration", "Pruning", "Full Publications/Events (82)", "Quantization", "Layer Wise Quantization (LWQ)", "Turn OFF Auto Mixed Precision during Quantization", "Weight Only Quantization (WOQ)", "Release", "SigOpt Strategy", "Smooth Quant", "Transform", "Tuning Strategies", "Validated Models", "Intel\u00ae Neural Compressor Documentation"], "terms": {"regist": [0, 6, 23, 30, 37, 46, 57, 71, 77, 95, 187, 191, 192, 193, 208, 234, 238, 242, 285, 312, 316, 327, 328, 332, 342, 344], "algorithm_registri": 0, "algorithm_typ": 0, "locat": [0, 37, 191, 208, 267, 272, 316, 336, 340, 343], "sourc": [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 183, 185, 186, 187, 188, 191, 192, 193, 194, 196, 198, 199, 200, 201, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 224, 225, 226, 227, 228, 230, 232, 233, 234, 236, 237, 238, 239, 240, 242, 243, 244, 246, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 282, 284, 325, 328, 335], "decor": [0, 6, 15, 37, 46, 57, 71, 120, 121, 123, 187, 208, 240, 242, 257, 282, 285, 344], "all": [0, 2, 5, 6, 8, 11, 16, 23, 30, 37, 39, 42, 44, 46, 48, 57, 71, 77, 78, 95, 98, 116, 149, 183, 185, 186, 187, 188, 191, 193, 208, 212, 215, 224, 233, 234, 236, 246, 250, 257, 260, 266, 269, 272, 273, 275, 279, 280, 281, 284, 285, 286, 287, 312, 313, 316, 320, 324, 328, 333, 334, 335, 336, 338, 339, 342, 343, 344], "subclass": [0, 23, 30, 37, 46, 57, 71, 208, 285], "paramet": [0, 5, 6, 7, 8, 10, 14, 15, 16, 19, 20, 21, 23, 30, 33, 37, 39, 40, 42, 43, 44, 46, 47, 51, 55, 57, 59, 63, 71, 75, 77, 79, 82, 97, 101, 120, 121, 123, 139, 168, 181, 186, 187, 191, 193, 199, 201, 203, 204, 206, 207, 208, 210, 212, 213, 215, 217, 220, 222, 226, 228, 230, 232, 233, 234, 236, 237, 238, 240, 242, 243, 246, 248, 249, 250, 253, 254, 256, 257, 264, 266, 267, 268, 271, 272, 274, 279, 282, 286, 313, 316, 323, 327, 328, 331, 334, 336, 337, 339, 341, 342, 343, 344], "cl": [0, 15, 23, 30, 37, 46, 57, 71, 187, 193, 242, 257, 312], "The": [0, 5, 6, 7, 9, 10, 12, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 29, 30, 37, 39, 40, 41, 43, 44, 46, 47, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 75, 77, 79, 80, 84, 88, 89, 90, 93, 94, 95, 97, 98, 101, 107, 127, 140, 157, 181, 182, 183, 184, 185, 186, 187, 188, 191, 200, 201, 202, 203, 204, 205, 207, 208, 209, 211, 212, 213, 217, 218, 220, 221, 222, 228, 230, 232, 233, 234, 236, 237, 238, 242, 243, 244, 246, 252, 253, 256, 257, 258, 260, 262, 263, 264, 265, 267, 268, 269, 271, 272, 273, 279, 280, 282, 285, 286, 287, 288, 290, 296, 299, 302, 310, 311, 312, 313, 316, 318, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345], "str": [0, 6, 8, 10, 14, 15, 16, 21, 22, 23, 30, 33, 37, 39, 40, 42, 44, 46, 74, 77, 79, 95, 98, 99, 101, 187, 191, 193, 194, 199, 201, 203, 204, 208, 210, 212, 213, 220, 222, 226, 228, 230, 232, 234, 236, 237, 238, 240, 242, 246, 249, 250, 253, 257, 258, 268, 269, 272, 312, 313, 327, 343], "registr": [0, 23, 30, 37], "name": [0, 5, 6, 7, 10, 14, 16, 21, 22, 23, 26, 30, 35, 37, 41, 46, 51, 55, 57, 59, 75, 77, 79, 88, 89, 93, 107, 120, 121, 123, 156, 181, 186, 187, 191, 193, 198, 207, 208, 212, 213, 215, 222, 228, 234, 237, 238, 240, 242, 244, 246, 248, 249, 250, 257, 260, 264, 267, 268, 269, 270, 281, 282, 287, 312, 316, 318, 320, 325, 327, 328, 330, 331, 334, 336, 340, 341, 344, 345], "call": [0, 15, 42, 191, 208, 240, 272, 275, 279, 282, 285, 313, 322, 334, 336, 342, 343], "return": [0, 5, 6, 8, 14, 15, 19, 20, 23, 30, 33, 37, 39, 40, 42, 43, 44, 46, 47, 51, 55, 57, 59, 63, 71, 75, 77, 95, 97, 99, 101, 107, 120, 121, 123, 127, 181, 186, 187, 191, 193, 199, 201, 203, 204, 206, 207, 208, 210, 212, 213, 215, 220, 222, 226, 228, 230, 232, 233, 234, 236, 237, 240, 242, 243, 246, 250, 256, 257, 265, 269, 270, 273, 279, 282, 286, 287, 313, 316, 327, 330, 332, 334, 336, 339, 342, 344], "type": [0, 6, 7, 8, 10, 14, 15, 16, 21, 23, 30, 37, 39, 40, 42, 46, 55, 57, 63, 64, 71, 75, 77, 79, 97, 101, 127, 148, 168, 181, 186, 187, 191, 193, 198, 199, 201, 203, 204, 206, 208, 212, 213, 215, 220, 221, 222, 226, 228, 230, 232, 233, 234, 237, 242, 250, 256, 257, 260, 262, 264, 265, 266, 267, 268, 269, 270, 272, 275, 285, 286, 316, 318, 320, 323, 328, 329, 331, 336, 337, 339, 341, 343, 344], "build": [0, 1, 3, 4, 8, 50, 52, 54, 55, 56, 186, 208, 272, 285, 286, 287, 324, 330, 335, 344], "dict": [0, 5, 8, 14, 16, 19, 20, 41, 42, 43, 44, 46, 47, 55, 59, 74, 77, 85, 95, 99, 101, 181, 186, 187, 191, 194, 199, 201, 206, 207, 208, 212, 213, 214, 215, 220, 222, 228, 230, 232, 233, 234, 237, 242, 243, 244, 246, 248, 250, 256, 257, 268, 269, 270, 275, 282, 286, 312, 318, 327, 334, 336, 342, 344], "algorithmschedul": 0, "conf": [0, 5, 16, 19, 20, 47, 57, 59, 60, 62, 63, 64, 68, 71, 75, 243, 282, 287, 310, 322, 328, 329, 330, 333, 336, 337, 338, 339, 341, 342, 344], "control": [0, 16, 282, 328, 334, 344], "differ": [0, 4, 6, 8, 10, 11, 16, 23, 37, 46, 55, 57, 176, 186, 239, 252, 260, 268, 269, 272, 275, 279, 280, 282, 286, 313, 316, 317, 321, 322, 323, 327, 328, 330, 332, 334, 336, 339, 342, 343, 344], "phase": [0, 242, 272, 279, 328, 334, 336, 338, 344], "base": [0, 6, 7, 8, 15, 16, 21, 23, 30, 37, 46, 48, 55, 56, 57, 68, 71, 75, 85, 101, 139, 168, 177, 183, 186, 188, 192, 204, 208, 212, 224, 234, 237, 238, 240, 242, 260, 263, 265, 266, 268, 269, 273, 275, 279, 285, 286, 287, 292, 312, 315, 316, 320, 328, 329, 334, 335, 336, 339, 341, 342, 344, 345], "fastbiascorrect": [1, 4], "threshold": [1, 244, 252, 327], "2": [1, 3, 5, 7, 8, 16, 22, 42, 44, 46, 57, 63, 93, 107, 127, 155, 191, 208, 228, 236, 257, 260, 263, 264, 266, 267, 268, 270, 271, 272, 273, 274, 275, 279, 282, 284, 285, 294, 311, 313, 320, 321, 323, 324, 325, 326, 327, 329, 331, 332, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344], "0": [1, 3, 6, 7, 8, 16, 21, 24, 25, 28, 33, 37, 46, 57, 59, 64, 99, 107, 181, 183, 191, 208, 212, 220, 228, 234, 238, 250, 253, 264, 265, 266, 268, 271, 273, 274, 277, 279, 282, 284, 294, 312, 313, 316, 318, 319, 320, 321, 324, 325, 326, 327, 328, 329, 331, 334, 336, 337, 339, 340, 341, 342, 343, 344], "channel_axi": [1, 4], "1": [1, 3, 4, 5, 7, 8, 16, 21, 22, 24, 25, 28, 29, 33, 37, 42, 43, 44, 46, 57, 59, 77, 80, 88, 90, 94, 108, 127, 142, 155, 179, 181, 183, 187, 191, 208, 212, 213, 215, 220, 224, 228, 234, 236, 246, 253, 257, 260, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 279, 280, 282, 284, 285, 287, 311, 313, 318, 320, 324, 326, 327, 329, 331, 332, 333, 334, 336, 337, 339, 340, 341, 342, 343, 344], "fetch": [2, 8, 114, 183, 286], "file": [2, 14, 16, 19, 20, 21, 22, 23, 26, 36, 37, 42, 47, 57, 59, 181, 187, 191, 192, 193, 206, 208, 212, 256, 257, 260, 268, 274, 281, 285, 286, 287, 316, 319, 322, 325, 327, 328, 330, 332, 336, 339, 343], "init": [2, 327, 344], "fast_bias_correct": [2, 16, 336], "smooth_quant": [2, 16, 189, 212, 312, 336, 342], "weight_correct": [2, 16, 336], "smoothquant": [3, 80, 205, 207, 208, 234, 262, 266, 268, 269, 271, 279, 326, 335, 339], "alpha": [3, 82, 99, 208, 212, 224, 234, 279, 312, 336, 344], "5": [3, 7, 16, 25, 33, 46, 59, 99, 208, 212, 234, 266, 268, 271, 279, 285, 318, 320, 324, 327, 328, 334, 336, 339, 342, 343, 344, 345], "fake": [3, 10, 77, 208, 224, 228, 268, 279, 328, 336, 339, 342], "input": [3, 8, 16, 19, 20, 21, 22, 23, 25, 33, 36, 37, 46, 47, 51, 55, 59, 82, 107, 113, 117, 120, 121, 123, 124, 125, 127, 135, 136, 138, 139, 155, 156, 181, 183, 186, 187, 203, 206, 208, 212, 220, 224, 228, 230, 237, 242, 243, 248, 249, 250, 253, 256, 257, 263, 267, 268, 269, 279, 285, 286, 310, 311, 313, 315, 316, 318, 320, 322, 327, 328, 329, 330, 334, 336, 339, 342, 343], "channel": [3, 4, 16, 33, 37, 176, 208, 228, 253, 260, 264, 266, 268, 284, 285, 287, 323, 324, 331, 334, 339, 343, 345], "quantiz": [3, 5, 7, 11, 13, 15, 16, 19, 20, 33, 38, 64, 66, 68, 77, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 188, 190, 193, 197, 198, 199, 200, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 242, 243, 244, 250, 252, 253, 256, 257, 262, 265, 271, 273, 276, 285, 291, 292, 312, 313, 316, 317, 320, 321, 322, 323, 327, 330, 333, 335, 340, 343, 344], "more": [3, 10, 37, 181, 208, 234, 260, 262, 264, 265, 266, 268, 269, 272, 279, 283, 284, 286, 311, 312, 316, 318, 323, 324, 326, 328, 329, 331, 332, 333, 334, 338, 339, 342, 344, 345], "detail": [3, 6, 37, 208, 234, 257, 258, 262, 265, 266, 268, 269, 270, 271, 272, 279, 280, 284, 286, 287, 311, 312, 320, 322, 326, 327, 328, 329, 334, 339, 340, 341, 342, 344], "pleas": [3, 16, 21, 22, 23, 26, 46, 59, 208, 215, 260, 262, 265, 266, 267, 268, 269, 270, 271, 279, 282, 283, 284, 285, 310, 311, 315, 316, 318, 324, 326, 327, 329, 334, 336, 338, 339, 340, 341, 342, 344], "refer": [3, 16, 21, 39, 40, 46, 59, 208, 215, 234, 260, 265, 266, 267, 269, 270, 271, 272, 282, 284, 285, 286, 310, 313, 315, 316, 318, 322, 324, 325, 327, 328, 329, 332, 337, 340, 343, 344], "accur": [3, 208, 215, 234, 267, 268, 279, 334, 339, 342], "effici": [3, 208, 267, 275, 279, 284, 311, 313, 333, 334, 335, 339, 342, 344], "post": [3, 16, 19, 20, 59, 149, 150, 208, 215, 234, 264, 266, 267, 268, 269, 271, 273, 279, 280, 284, 285, 286, 315, 316, 318, 323, 324, 331, 334, 335, 337, 339, 342, 344], "train": [3, 16, 19, 20, 21, 23, 37, 38, 59, 110, 133, 208, 215, 234, 246, 264, 265, 266, 267, 268, 269, 271, 273, 284, 285, 286, 291, 315, 318, 321, 323, 329, 331, 333, 335, 337, 339, 341, 342, 344], "larg": [3, 208, 260, 264, 266, 268, 269, 271, 272, 279, 313, 328, 331, 335, 337, 339, 342, 345], "languag": [3, 39, 208, 226, 236, 260, 264, 266, 268, 269, 271, 272, 279, 280, 318, 331, 335, 337, 339, 342], "model": [3, 5, 7, 10, 16, 19, 20, 21, 23, 37, 38, 46, 47, 57, 59, 60, 62, 63, 64, 68, 71, 77, 79, 82, 84, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 181, 184, 186, 187, 188, 191, 193, 201, 203, 206, 207, 208, 210, 212, 215, 226, 227, 228, 230, 232, 233, 236, 237, 242, 243, 248, 249, 250, 253, 256, 257, 259, 260, 262, 263, 264, 265, 268, 269, 270, 271, 272, 275, 279, 281, 282, 285, 287, 291, 310, 311, 312, 313, 315, 316, 317, 321, 322, 323, 325, 327, 329, 332, 333, 335, 336, 340, 341, 343, 344], "spiq": [3, 208, 279, 342], "data": [3, 15, 16, 19, 20, 38, 47, 59, 63, 75, 77, 79, 97, 101, 109, 181, 184, 187, 191, 198, 199, 204, 208, 213, 228, 243, 246, 250, 257, 260, 262, 263, 264, 265, 267, 268, 269, 272, 279, 284, 285, 311, 313, 316, 320, 324, 327, 328, 329, 331, 336, 338, 339, 340, 341, 342, 343, 344], "free": [3, 19, 20, 59, 208, 266, 271, 279, 280, 332, 341, 342], "per": [3, 5, 16, 193, 208, 228, 232, 252, 260, 264, 266, 268, 274, 285, 287, 313, 331, 334, 338, 339, 345], "static": [3, 16, 59, 75, 83, 84, 85, 95, 97, 99, 208, 211, 212, 232, 234, 237, 250, 269, 284, 285, 286, 287, 318, 321, 323, 328, 337, 342, 344, 345], "For": [3, 7, 10, 14, 16, 23, 37, 43, 44, 46, 47, 59, 208, 228, 234, 257, 260, 266, 268, 269, 270, 271, 275, 279, 280, 282, 283, 285, 287, 315, 316, 318, 320, 321, 323, 334, 338, 339, 342, 344, 345], "torch": [3, 7, 14, 16, 38, 47, 59, 250, 253, 256, 260, 263, 264, 265, 266, 267, 268, 273, 275, 279, 282, 287, 288, 316, 318, 319, 321, 328, 329, 330, 331, 336, 339, 342], "backend": [3, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 32, 34, 37, 47, 48, 49, 51, 69, 234, 265, 268, 269, 282, 287, 316, 322, 323, 328, 329, 339, 343, 344], "we": [3, 4, 5, 7, 16, 39, 42, 66, 120, 121, 123, 127, 139, 176, 191, 208, 262, 263, 266, 267, 268, 269, 271, 272, 273, 274, 275, 279, 280, 282, 284, 285, 286, 287, 312, 313, 316, 318, 320, 321, 326, 327, 328, 332, 333, 334, 336, 337, 339, 340, 341, 342, 344], "onli": [3, 4, 5, 16, 21, 59, 69, 77, 107, 116, 123, 139, 155, 176, 191, 208, 223, 224, 226, 227, 228, 234, 236, 250, 257, 260, 262, 265, 269, 273, 274, 285, 286, 287, 310, 311, 312, 313, 316, 319, 320, 321, 326, 328, 329, 334, 335, 336, 337, 342, 344], "handl": [3, 13, 114, 181, 208, 218, 254, 282, 283, 312, 313, 342], "layer": [3, 16, 84, 85, 87, 187, 190, 193, 208, 215, 224, 244, 246, 257, 262, 266, 267, 269, 279, 285, 286, 287, 315, 319, 323, 334, 339, 340], "whose": [3, 55, 186, 208, 322, 342, 344], "smooth": [3, 16, 79, 80, 81, 82, 97, 99, 207, 208, 232, 234, 269, 284, 312, 321, 334, 344], "scale": [3, 4, 33, 37, 82, 88, 89, 90, 93, 94, 151, 176, 208, 217, 220, 221, 224, 228, 260, 263, 264, 266, 267, 268, 272, 279, 331, 336, 339, 341, 342, 343, 344], "could": [3, 19, 20, 23, 47, 59, 191, 208, 243, 262, 265, 267, 268, 270, 272, 279, 280, 282, 315, 319, 328, 333, 334, 336, 339, 342], "absorb": [3, 208, 228, 268, 339], "support": [3, 6, 16, 19, 20, 21, 23, 30, 33, 37, 38, 46, 47, 51, 57, 59, 69, 75, 149, 208, 232, 242, 243, 246, 252, 253, 257, 259, 262, 263, 267, 270, 273, 279, 284, 286, 312, 321, 326, 328, 335, 338, 341, 344], "other": [3, 44, 55, 120, 121, 123, 186, 192, 208, 264, 269, 272, 279, 280, 282, 286, 287, 292, 312, 320, 321, 323, 325, 328, 330, 331, 332, 334, 336, 342, 343, 344, 345], "later": [3, 191, 208, 238, 263, 312], "onnx": [3, 16, 47, 54, 248, 249, 250, 255, 281, 284, 285, 286, 288, 313, 317, 318, 320, 323, 329, 330, 331, 335, 339, 342, 344], "insert": [3, 84, 130, 153, 155, 179, 208, 228, 237, 267, 268, 269, 271, 279, 282, 286, 313, 323, 328, 334, 336, 338, 339, 342], "mul": [3, 108, 118, 119, 122, 268, 318, 339, 342], "befor": [3, 16, 21, 84, 153, 155, 215, 226, 236, 240, 260, 268, 279, 281, 287, 313, 315, 316, 319, 320, 328, 336, 339, 341, 344], "conv": [3, 16, 111, 115, 119, 124, 125, 126, 144, 155, 282, 286, 287, 328, 334, 336, 344], "linear": [3, 16, 198, 208, 218, 222, 224, 228, 260, 266, 267, 268, 279, 282, 318, 328, 334, 339, 342, 344], "op": [3, 16, 64, 66, 68, 75, 76, 77, 82, 104, 106, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 134, 138, 141, 143, 144, 145, 146, 148, 153, 155, 159, 160, 161, 167, 169, 170, 171, 172, 176, 179, 181, 207, 208, 212, 228, 232, 242, 248, 250, 252, 257, 265, 266, 269, 279, 285, 286, 287, 320, 328, 329, 334, 336, 338, 340, 342, 344], "fuse": [3, 111, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 143, 144, 145, 146, 148, 167, 172, 212, 282, 342], "kernel": [3, 16, 268, 285, 286, 344], "futur": [3, 7, 19, 20, 262, 269, 323, 326, 328], "weightcorrect": 4, "ep": [4, 329], "1e": [4, 208, 279, 342], "05": [4, 16, 46, 208, 326, 327, 342, 345], "correct": [4, 16, 42, 43, 44, 46, 176, 280], "int8": [4, 5, 16, 33, 75, 77, 88, 89, 90, 93, 94, 95, 99, 140, 159, 160, 161, 167, 169, 170, 171, 172, 176, 204, 228, 234, 236, 248, 249, 250, 256, 257, 260, 264, 266, 268, 269, 270, 272, 279, 281, 282, 285, 286, 287, 310, 315, 320, 326, 328, 329, 331, 335, 336, 338, 339, 340, 341, 342, 343], "weight": [4, 7, 16, 46, 59, 66, 75, 77, 79, 82, 113, 114, 176, 193, 208, 217, 223, 224, 226, 227, 228, 234, 236, 250, 257, 258, 260, 262, 263, 266, 267, 269, 270, 271, 272, 273, 285, 286, 287, 311, 315, 320, 321, 322, 326, 328, 332, 334, 335, 336, 337, 342, 344], "distribut": [4, 16, 176, 183, 252, 260, 262, 268, 272, 279, 286, 313, 324, 335, 336, 339, 340, 342, 345], "close": [4, 176, 311], "fp32": [4, 16, 19, 20, 46, 64, 68, 75, 97, 101, 132, 167, 172, 176, 187, 201, 206, 207, 210, 226, 228, 232, 246, 249, 250, 253, 256, 257, 260, 265, 266, 267, 268, 269, 270, 272, 279, 281, 285, 287, 320, 326, 327, 328, 329, 336, 338, 339, 340, 341, 342, 344, 345], "r": [4, 176, 266, 267, 268, 270, 272, 274, 279, 324, 336, 345], "w_int8": [4, 176], "u": [4, 176], "w_fp32": [4, 176], "i": [4, 5, 7, 10, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28, 30, 33, 37, 39, 42, 44, 46, 47, 57, 59, 64, 69, 77, 102, 104, 107, 108, 113, 117, 123, 135, 138, 168, 176, 181, 183, 187, 191, 192, 201, 203, 204, 208, 212, 215, 221, 222, 226, 228, 230, 234, 236, 238, 240, 242, 243, 253, 256, 257, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 279, 280, 281, 282, 284, 285, 286, 287, 288, 290, 296, 299, 302, 310, 311, 312, 313, 315, 316, 318, 319, 320, 323, 324, 325, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345], "varianc": [4, 176], "ratio": [4, 16, 33, 37, 176, 326, 328, 334, 343, 345], "between": [4, 16, 37, 43, 46, 176, 201, 208, 257, 260, 264, 268, 269, 272, 279, 282, 284, 285, 286, 287, 311, 323, 327, 328, 331, 336, 339, 340, 341, 342, 343, 344], "wise": [4, 16, 63, 64, 68, 176, 190, 193, 199, 262, 286, 323, 334, 339, 342, 344], "": [4, 6, 16, 23, 36, 37, 44, 46, 47, 51, 59, 176, 181, 187, 191, 208, 226, 228, 236, 257, 260, 262, 263, 265, 266, 267, 268, 270, 272, 274, 279, 280, 281, 286, 287, 312, 316, 318, 319, 320, 321, 323, 328, 329, 333, 334, 335, 336, 339, 340, 341, 342, 344, 345], "equal": [4, 176, 187, 257, 264, 331, 334, 339], "minim": [4, 63, 176, 260, 267, 268, 272, 279, 286, 287, 311, 317, 327, 328, 334, 336, 344], "round": [4, 176, 199, 234, 260, 263, 268, 269, 279, 284, 335, 336, 339, 342], "scale_c": [4, 176], "shift": [4, 33, 176, 343], "notic": [4, 176, 265, 268, 325, 329, 340], "can": [4, 16, 19, 20, 23, 37, 42, 44, 46, 47, 57, 59, 176, 191, 208, 237, 243, 257, 260, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 279, 282, 284, 285, 286, 287, 310, 312, 313, 315, 316, 318, 320, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 338, 339, 341, 342, 343, 344, 345], "chang": [4, 16, 66, 148, 176, 208, 237, 257, 269, 281, 286, 313, 316, 319, 325, 328, 334, 343, 344], "first": [4, 6, 16, 21, 42, 64, 75, 176, 187, 191, 208, 228, 257, 264, 265, 268, 274, 279, 282, 284, 285, 286, 287, 324, 329, 331, 336, 338, 339, 341, 342, 344], "an": [4, 16, 23, 37, 38, 39, 43, 44, 47, 59, 82, 120, 121, 123, 176, 181, 191, 192, 204, 212, 228, 242, 243, 257, 259, 260, 264, 265, 266, 267, 268, 269, 271, 272, 273, 279, 280, 282, 284, 285, 287, 311, 313, 314, 318, 326, 327, 328, 329, 331, 332, 334, 335, 336, 339, 341, 342, 343, 344], "empir": [4, 176], "solut": [4, 176, 266, 268, 271, 279, 284, 285, 286, 319, 335, 339, 340, 342, 344], "make": [4, 176, 257, 265, 266, 268, 271, 279, 280, 284, 285, 286, 310, 312, 313, 320, 327, 328, 334, 336, 337, 338, 339, 341, 342, 344], "thi": [4, 6, 7, 8, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 37, 39, 42, 43, 44, 46, 47, 57, 59, 63, 68, 77, 139, 156, 168, 175, 176, 180, 183, 191, 192, 208, 212, 237, 243, 256, 257, 260, 262, 265, 266, 267, 268, 270, 271, 272, 273, 279, 280, 281, 282, 284, 285, 286, 287, 311, 312, 313, 315, 316, 318, 319, 320, 323, 324, 325, 326, 327, 328, 329, 330, 334, 336, 338, 339, 340, 341, 342, 343, 344], "don": [4, 16, 176, 266, 267, 282, 334, 344], "t": [4, 16, 37, 44, 120, 121, 123, 176, 191, 265, 266, 267, 272, 274, 282, 285, 312, 316, 328, 329, 334, 336, 339, 344], "min": [4, 16, 176, 228, 257, 264, 268, 272, 279, 331, 334, 336, 339, 342, 343, 344], "max": [4, 16, 37, 43, 44, 63, 176, 208, 228, 234, 257, 264, 268, 272, 279, 284, 324, 328, 331, 334, 336, 339, 342, 343, 344], "valu": [4, 5, 16, 19, 20, 21, 24, 25, 33, 37, 42, 46, 47, 59, 63, 68, 75, 77, 109, 120, 121, 123, 142, 176, 183, 191, 193, 208, 212, 220, 224, 243, 244, 246, 257, 260, 263, 264, 265, 266, 268, 271, 272, 279, 282, 286, 287, 311, 320, 327, 328, 329, 331, 332, 334, 336, 339, 342, 343, 344], "us": [5, 6, 8, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28, 36, 37, 39, 40, 42, 46, 57, 59, 63, 66, 68, 71, 75, 77, 82, 84, 85, 97, 101, 102, 123, 183, 187, 191, 199, 200, 201, 203, 204, 207, 208, 211, 212, 213, 220, 221, 222, 228, 233, 236, 237, 238, 242, 243, 244, 245, 246, 249, 250, 251, 253, 257, 260, 264, 265, 266, 267, 268, 269, 270, 272, 273, 275, 279, 280, 281, 282, 285, 286, 310, 311, 312, 315, 316, 318, 320, 321, 322, 325, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345], "evalu": [5, 7, 19, 20, 21, 39, 42, 43, 44, 46, 47, 57, 59, 233, 243, 246, 269, 271, 272, 273, 279, 285, 286, 312, 315, 322, 323, 326, 327, 328, 329, 332, 334, 336, 341, 342, 344], "perform": [5, 16, 21, 33, 46, 57, 59, 64, 68, 79, 80, 148, 208, 260, 263, 265, 267, 268, 270, 272, 273, 274, 275, 279, 281, 282, 284, 285, 286, 310, 314, 315, 317, 318, 321, 323, 324, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 342, 344, 345], "set_env_var": 5, "env_var": 5, "overwrite_exist": 5, "fals": [5, 16, 21, 23, 33, 37, 42, 46, 57, 59, 85, 88, 89, 90, 93, 94, 99, 102, 124, 125, 142, 144, 167, 172, 176, 179, 180, 181, 183, 191, 198, 199, 201, 204, 208, 212, 213, 215, 220, 222, 224, 228, 234, 237, 246, 253, 256, 257, 266, 268, 270, 272, 273, 274, 285, 286, 313, 320, 327, 328, 336, 339, 342, 343, 344], "set": [5, 6, 7, 8, 15, 16, 19, 20, 21, 23, 26, 37, 42, 46, 47, 55, 59, 84, 98, 104, 148, 181, 183, 185, 186, 191, 201, 204, 208, 226, 228, 233, 234, 236, 242, 243, 257, 260, 265, 266, 268, 269, 270, 271, 273, 274, 275, 279, 280, 284, 286, 310, 313, 316, 318, 319, 320, 322, 323, 327, 328, 329, 334, 336, 339, 341, 342, 344], "specifi": [5, 10, 16, 19, 20, 37, 42, 46, 47, 59, 156, 191, 199, 203, 208, 212, 213, 234, 236, 242, 243, 256, 257, 275, 279, 286, 287, 316, 320, 327, 328, 332, 334, 339, 343, 344], "environ": [5, 238, 241, 265, 269, 275, 280, 284, 310, 344], "variabl": [5, 16, 23, 63, 77, 192, 238, 265, 275, 334, 344], "new": [5, 23, 37, 57, 181, 183, 188, 208, 228, 238, 262, 265, 266, 267, 268, 279, 281, 286, 316, 328, 329, 334, 335, 336, 339, 340, 341, 343], "env": [5, 319], "two": [5, 23, 28, 42, 69, 191, 257, 260, 264, 265, 267, 268, 271, 273, 276, 279, 281, 282, 312, 313, 316, 318, 320, 328, 329, 331, 334, 336, 338, 339, 341, 342, 344], "case": [5, 8, 16, 36, 37, 57, 123, 127, 191, 236, 238, 262, 268, 272, 279, 287, 312, 313, 315, 316, 320, 322, 327, 332, 334, 335, 336, 339, 340, 342, 343, 345], "exist": [5, 55, 107, 186, 187, 240, 257, 265, 269, 318, 327, 344], "alreadi": [5, 23, 36, 191, 265, 269, 285, 319, 323, 344], "param": [5, 8, 10, 46, 63, 183, 257, 260, 285, 330, 344], "true": [5, 7, 16, 21, 23, 24, 36, 37, 40, 46, 57, 59, 74, 88, 89, 90, 94, 95, 99, 138, 179, 181, 183, 191, 193, 201, 207, 208, 213, 215, 218, 222, 224, 227, 228, 234, 237, 246, 250, 253, 256, 257, 263, 266, 267, 268, 269, 270, 272, 273, 274, 279, 286, 313, 316, 320, 327, 328, 336, 337, 339, 342, 343, 344], "set_all_env_var": 5, "configur": [5, 6, 7, 8, 15, 16, 19, 20, 23, 26, 46, 47, 57, 59, 68, 77, 97, 101, 201, 203, 204, 206, 208, 212, 217, 222, 232, 234, 237, 242, 243, 245, 246, 250, 255, 256, 269, 273, 275, 282, 285, 286, 328, 332, 334, 336, 339, 340, 342, 343, 344, 345], "neural": [5, 8, 16, 33, 34, 37, 38, 45, 46, 47, 51, 58, 59, 66, 67, 73, 86, 98, 99, 100, 101, 185, 188, 189, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 247, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 276, 279, 281, 285, 286, 287, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 325, 326, 329, 330, 331, 332, 333, 335, 336, 339, 340, 342, 343, 344, 345], "compressor": [5, 8, 16, 33, 34, 37, 38, 45, 46, 47, 51, 58, 59, 67, 73, 86, 98, 99, 100, 101, 185, 188, 189, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 247, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 276, 279, 281, 285, 286, 287, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 325, 326, 329, 330, 331, 332, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345], "physic": [5, 8, 280, 310], "core": [5, 8, 16, 81, 202, 219, 268, 274, 275, 281, 284, 310, 324, 325, 345], "get_architectur": 5, "get": [5, 8, 15, 16, 37, 46, 55, 59, 68, 75, 77, 95, 98, 120, 121, 123, 181, 183, 186, 187, 193, 208, 212, 215, 228, 234, 242, 246, 250, 253, 257, 262, 266, 269, 274, 279, 286, 311, 319, 323, 324, 326, 328, 335, 339, 342, 344, 346], "architectur": [5, 262, 265, 268, 275, 279, 284, 310, 321, 328, 334, 335, 339], "system": [5, 8, 191, 257, 264, 265, 275, 310, 331, 334, 345], "get_threads_per_cor": 5, "thread": [5, 16, 313, 319], "get_thread": 5, "list": [5, 6, 7, 8, 10, 16, 19, 20, 21, 33, 37, 39, 40, 42, 43, 44, 46, 47, 55, 59, 74, 79, 95, 98, 99, 101, 107, 181, 186, 193, 201, 208, 212, 213, 215, 228, 233, 234, 242, 243, 244, 249, 250, 257, 260, 266, 269, 271, 272, 282, 284, 285, 318, 320, 324, 326, 328, 332, 334, 336, 338, 342, 344], "get_physical_id": 5, "socket": [5, 8, 257, 345], "get_core_id": 5, "id": [5, 36, 39, 41, 42, 43, 44, 327, 341, 344], "get_bounded_thread": 5, "core_id": 5, "bind": [5, 275], "instanc": [5, 8, 16, 19, 20, 43, 44, 46, 47, 59, 63, 77, 204, 243, 257, 268, 274, 280, 281, 282, 285, 310, 321, 328, 339, 344, 345], "run_inst": 5, "b_dataload": [5, 16, 310, 328], "none": [5, 6, 7, 10, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 33, 37, 42, 46, 47, 57, 59, 60, 62, 63, 64, 68, 71, 75, 80, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 101, 102, 116, 142, 156, 181, 183, 187, 188, 191, 193, 198, 199, 200, 208, 212, 213, 215, 218, 221, 224, 226, 227, 228, 230, 233, 234, 236, 237, 242, 243, 244, 246, 249, 250, 253, 256, 257, 260, 264, 268, 269, 272, 274, 284, 285, 286, 313, 327, 331, 336, 339, 343, 344], "b_func": [5, 310], "run": [5, 16, 19, 20, 36, 47, 59, 63, 79, 181, 191, 208, 243, 260, 265, 268, 269, 272, 274, 275, 279, 284, 285, 310, 316, 319, 320, 328, 335, 336, 339, 340, 341, 344], "object": [5, 7, 14, 16, 19, 20, 21, 22, 23, 37, 38, 42, 46, 47, 55, 56, 59, 63, 77, 127, 139, 168, 181, 183, 186, 187, 191, 192, 194, 201, 204, 206, 208, 212, 228, 242, 243, 246, 256, 257, 262, 267, 269, 272, 282, 286, 291, 310, 312, 313, 319, 327, 328, 330, 333, 334, 336, 343, 344, 345], "benchmarkconfig": [5, 16, 310, 328], "contain": [5, 16, 19, 20, 21, 22, 23, 42, 43, 44, 47, 59, 120, 121, 123, 127, 175, 181, 191, 201, 204, 207, 208, 212, 220, 224, 243, 246, 250, 256, 262, 268, 272, 284, 311, 319, 323, 327, 334, 339, 344], "accuraci": [5, 7, 16, 19, 20, 46, 47, 57, 59, 64, 243, 264, 266, 267, 268, 272, 273, 275, 282, 284, 286, 287, 311, 313, 315, 316, 317, 318, 321, 327, 328, 331, 332, 333, 334, 335, 339, 340, 341, 342, 345], "goal": [5, 47, 59, 273, 279, 286, 313, 333, 336, 344], "tune": [5, 6, 7, 10, 13, 16, 19, 20, 21, 23, 47, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 98, 208, 233, 234, 243, 257, 265, 266, 267, 268, 269, 273, 276, 284, 285, 286, 311, 312, 313, 316, 321, 323, 325, 328, 329, 332, 334, 335, 338, 340, 341], "prefer": [5, 59, 268, 279, 334, 339], "calibr": [5, 16, 19, 20, 59, 81, 97, 101, 142, 207, 208, 213, 233, 237, 252, 260, 262, 267, 268, 269, 272, 279, 284, 285, 287, 322, 323, 334, 336, 339, 344], "space": [5, 16, 19, 20, 44, 47, 59, 63, 68, 75, 269, 273, 279, 280, 281, 285, 286, 287, 312, 334, 336, 342], "etc": [5, 36, 44, 47, 59, 188, 256, 284, 323, 334, 341, 344], "dataload": [5, 19, 20, 21, 32, 59, 79, 82, 183, 208, 213, 215, 228, 243, 246, 262, 272, 282, 285, 286, 315, 316, 322, 328, 329, 333, 334, 336, 337, 338, 339, 342, 343], "framework": [5, 6, 11, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 37, 46, 47, 48, 49, 51, 69, 75, 84, 95, 185, 246, 262, 265, 267, 272, 273, 279, 285, 287, 311, 312, 316, 317, 321, 322, 323, 327, 328, 329, 334, 335, 336, 343, 344, 345], "custom": [5, 46, 57, 88, 89, 90, 91, 93, 94, 192, 228, 256, 260, 269, 273, 279, 284, 310, 315, 334, 335, 339, 341], "If": [5, 7, 10, 16, 19, 20, 23, 37, 47, 59, 120, 121, 123, 127, 191, 208, 226, 228, 230, 236, 242, 243, 260, 269, 272, 279, 281, 282, 286, 310, 312, 313, 316, 319, 324, 325, 327, 328, 332, 334, 336, 339, 341, 342, 343, 344], "user": [5, 16, 19, 20, 23, 26, 30, 37, 46, 47, 57, 59, 64, 77, 191, 201, 208, 212, 234, 242, 243, 257, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 279, 282, 285, 286, 287, 291, 310, 312, 313, 315, 318, 320, 323, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 342, 343, 344], "pass": [5, 15, 46, 59, 130, 181, 187, 191, 192, 206, 208, 226, 236, 256, 257, 268, 279, 281, 282, 285, 310, 315, 316, 322, 327, 328, 334, 336, 338, 342], "need": [5, 10, 16, 19, 20, 23, 30, 37, 46, 47, 57, 59, 68, 155, 183, 199, 206, 208, 226, 236, 243, 250, 256, 257, 268, 271, 273, 275, 279, 282, 285, 312, 313, 316, 319, 323, 328, 334, 336, 337, 338, 339, 340, 342, 343, 344], "generate_prefix": [5, 8], "core_list": [5, 8], "gener": [5, 7, 8, 19, 20, 23, 24, 25, 26, 37, 39, 47, 59, 63, 95, 99, 102, 140, 181, 183, 208, 212, 213, 215, 233, 234, 237, 243, 260, 264, 265, 266, 268, 269, 270, 275, 279, 281, 282, 285, 287, 313, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 342, 343, 344], "command": [5, 8, 243, 274, 275, 316], "prefix": [5, 8, 181, 191, 193, 228, 260], "numactl": [5, 8, 319], "index": [5, 16, 23, 120, 121, 123, 183, 257, 279, 284, 324, 327, 339, 342], "bound": [5, 37, 42, 63, 127, 208, 327, 343], "specif": [5, 6, 8, 16, 21, 22, 23, 24, 28, 30, 46, 59, 183, 185, 204, 208, 242, 264, 265, 267, 268, 269, 272, 275, 280, 285, 286, 311, 312, 313, 320, 322, 326, 327, 328, 329, 330, 331, 332, 334, 339, 344], "call_on": 5, "cmd": [5, 324], "log_fil": 5, "execut": [5, 11, 16, 59, 60, 62, 107, 188, 191, 207, 215, 243, 246, 256, 257, 267, 268, 279, 315, 328, 329, 333, 334, 336, 339, 341, 344, 345], "one": [5, 37, 39, 42, 46, 155, 156, 191, 208, 212, 228, 265, 268, 269, 272, 273, 274, 279, 285, 311, 315, 316, 320, 323, 324, 327, 328, 329, 332, 333, 334, 336, 337, 339, 340, 342, 343, 344], "dump": [5, 8, 192, 208, 212, 242, 250, 257, 272, 279, 281, 336], "log": [5, 13, 15, 179, 208, 254, 274, 282, 341, 344], "window": [5, 8, 274, 275, 310, 324], "config_inst": 5, "raw_cmd": [5, 8], "multi": [5, 8, 42, 46, 59, 274, 313, 323, 328, 332, 334, 336, 344], "trigger": [5, 8, 274], "sub": [5, 119, 212, 312, 344], "process": [5, 7, 13, 15, 16, 19, 20, 21, 22, 23, 33, 37, 47, 59, 60, 62, 63, 79, 207, 208, 242, 243, 256, 257, 260, 263, 264, 267, 268, 271, 272, 273, 275, 279, 285, 286, 287, 311, 313, 315, 316, 318, 328, 331, 333, 334, 336, 337, 339, 342, 343], "raw": [5, 22, 26, 29, 68, 207, 210, 226, 232, 327, 344], "summary_benchmark": 5, "summari": [5, 8, 243, 345], "profil": [5, 16, 38], "benchmark_with_raw_cmd": 5, "string": [5, 15, 16, 23, 39, 42, 51, 55, 181, 186, 187, 191, 192, 215, 242, 246, 257, 260, 272, 327, 343], "exampl": [5, 6, 7, 10, 14, 16, 21, 22, 23, 33, 37, 42, 43, 44, 46, 47, 57, 59, 77, 187, 191, 203, 206, 221, 228, 230, 238, 242, 243, 256, 257, 262, 266, 272, 273, 275, 280, 284, 286, 287, 291, 321, 322, 323, 338, 340, 343, 344, 346], "accord": [5, 16, 21, 22, 23, 37, 66, 68, 188, 237, 242, 246, 260, 272, 273, 279, 285, 316, 334, 338, 342, 343, 344], "config": [5, 6, 7, 10, 14, 15, 19, 20, 21, 38, 47, 75, 76, 77, 80, 84, 85, 96, 97, 98, 100, 101, 185, 201, 204, 207, 208, 212, 219, 222, 226, 233, 235, 237, 242, 243, 246, 256, 257, 260, 263, 265, 267, 268, 269, 270, 286, 287, 291, 292, 310, 312, 313, 315, 316, 318, 323, 327, 328, 329, 330, 333, 334, 336, 338, 339, 341, 344], "from": [5, 6, 7, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 33, 39, 42, 43, 44, 47, 55, 57, 59, 75, 77, 84, 114, 120, 121, 123, 181, 183, 186, 188, 191, 193, 201, 203, 206, 207, 208, 210, 212, 226, 228, 232, 236, 242, 243, 246, 248, 249, 250, 253, 256, 257, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 279, 280, 281, 282, 285, 287, 310, 312, 313, 315, 316, 317, 318, 319, 321, 323, 326, 327, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344], "import": [5, 7, 15, 16, 47, 57, 59, 181, 226, 236, 240, 243, 257, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 279, 282, 284, 287, 310, 313, 315, 316, 318, 321, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 338, 340, 341, 342, 343, 344], "fit_with_raw_cmd": 5, "iter": [5, 16, 19, 20, 23, 24, 47, 59, 79, 97, 101, 181, 183, 208, 212, 213, 220, 228, 234, 243, 246, 268, 272, 273, 282, 285, 310, 313, 328, 334, 336, 342, 344], "100": [5, 6, 7, 16, 23, 97, 98, 101, 238, 272, 279, 310, 316, 322, 324, 328, 336, 343, 344, 345], "cores_per_inst": [5, 16, 310, 328], "4": [5, 8, 16, 30, 33, 37, 39, 40, 42, 77, 107, 213, 224, 228, 234, 263, 264, 266, 267, 268, 269, 274, 279, 280, 284, 285, 287, 310, 316, 317, 320, 323, 324, 327, 328, 331, 334, 336, 339, 342, 343, 344, 345], "num_of_inst": [5, 16, 310, 328], "7": [5, 8, 16, 57, 208, 220, 228, 266, 268, 271, 279, 287, 310, 319, 320, 328, 334, 336, 340, 342, 344, 345], "test": [5, 16, 37, 281, 284, 345], "py": [5, 8, 16, 40, 42, 43, 44, 181, 238, 270, 274, 275, 282, 285, 312, 316, 324, 328, 336, 340], "fit": [5, 16, 47, 59, 63, 243, 282, 310, 313, 316, 322, 327, 328, 329, 330, 334, 336, 337, 338, 339], "pb": [5, 16, 47, 55, 59, 186, 272, 310, 316, 328, 330, 345], "eval_dataload": [5, 16, 19, 20, 47, 59, 60, 62, 63, 64, 68, 71, 243, 310, 322, 327, 328, 336, 337, 344], "configregistri": [6, 14], "A": [6, 7, 13, 15, 16, 23, 37, 39, 42, 43, 44, 46, 47, 51, 55, 63, 79, 82, 108, 127, 128, 181, 185, 186, 187, 192, 199, 201, 204, 207, 208, 210, 220, 222, 228, 238, 243, 257, 266, 268, 269, 279, 281, 286, 312, 313, 317, 320, 326, 327, 328, 330, 334, 335, 336, 339, 342, 343, 344], "registri": [6, 238], "manag": [6, 243, 246, 328], "algorithm": [6, 10, 16, 38, 39, 46, 86, 95, 97, 101, 187, 231, 232, 234, 236, 237, 242, 246, 252, 268, 269, 272, 273, 275, 279, 284, 285, 286, 287, 312, 315, 320, 321, 323, 326, 334, 336], "within": [6, 7, 42, 55, 186, 265, 280, 282, 287, 311, 329, 334, 335, 339, 342, 344], "register_config": [6, 312], "framework_nam": [6, 312], "algo_nam": [6, 101, 237, 312], "prioriti": [6, 238, 240, 312], "float": [6, 16, 21, 33, 40, 42, 43, 44, 74, 79, 82, 99, 188, 208, 213, 228, 234, 237, 238, 257, 260, 263, 264, 265, 266, 267, 268, 270, 271, 273, 279, 312, 327, 331, 336, 342, 343], "int": [6, 10, 15, 16, 21, 22, 33, 37, 40, 42, 46, 77, 79, 80, 84, 97, 98, 101, 181, 199, 208, 212, 213, 218, 220, 221, 224, 228, 234, 249, 250, 253, 257, 268, 272, 312, 313, 327, 328, 339, 343], "usag": [6, 7, 10, 42, 187, 228, 238, 239, 242, 269, 270, 275, 279, 286, 316, 317, 332, 339, 343], "examplealgorithm": 6, "examplealgorithmconfig": 6, "larger": [6, 238, 268, 279, 286, 334, 339, 342], "number": [6, 7, 15, 16, 22, 33, 37, 43, 44, 46, 63, 79, 120, 121, 183, 208, 213, 221, 228, 238, 246, 257, 263, 268, 273, 274, 279, 310, 313, 316, 327, 334, 336, 339, 341, 342, 343, 344], "indic": [6, 16, 21, 42, 183, 191, 204, 221, 238, 272, 282, 313, 319], "higher": [6, 16, 19, 20, 47, 59, 238, 243, 260, 275, 279, 282, 318, 327, 334, 336, 339, 341], "which": [6, 16, 21, 22, 23, 33, 39, 44, 46, 51, 57, 59, 63, 109, 136, 156, 187, 191, 208, 215, 220, 221, 242, 257, 260, 262, 265, 267, 268, 269, 270, 272, 273, 279, 280, 282, 285, 286, 287, 311, 313, 316, 319, 320, 323, 327, 328, 329, 330, 333, 334, 336, 337, 338, 339, 340, 342, 343, 344], "tri": [6, 16, 312, 344], "auto": [6, 7, 16, 61, 67, 98, 208, 233, 234, 238, 240, 257, 260, 266, 269, 276, 282, 284, 311, 321, 334, 336, 339], "stage": [6, 15, 60, 62, 69, 334, 344], "default": [6, 10, 15, 16, 19, 20, 21, 22, 23, 33, 37, 39, 46, 55, 77, 95, 99, 149, 181, 186, 187, 191, 193, 203, 204, 207, 208, 213, 220, 226, 228, 230, 232, 233, 234, 236, 237, 242, 246, 249, 250, 253, 257, 260, 264, 265, 266, 268, 269, 272, 273, 274, 275, 282, 285, 312, 313, 320, 323, 327, 328, 329, 331, 332, 334, 336, 338, 339, 341, 342, 343, 344], "baseconfig": [6, 7, 10, 95, 97, 98, 101, 233, 234, 237, 269, 272, 312], "white_list": [6, 95, 99, 234], "util": [6, 7, 9, 16, 38, 40, 67, 86, 97, 98, 100, 101, 190, 197, 202, 205, 209, 213, 223, 231, 232, 234, 260, 262, 272, 275, 286, 287, 288, 311, 312, 316, 328, 334, 336, 344], "op_name_or_module_typ": [6, 95, 99, 234], "default_white_list": [6, 95, 99, 234], "params_list": [6, 10], "tunabl": [6, 10], "composableconfig": [6, 312], "repres": [6, 7, 10, 11, 23, 28, 42, 44, 46, 201, 221, 267, 268, 272, 279, 280, 287, 311, 318, 334, 336, 337, 344], "compos": [6, 37, 246, 343], "allow": [6, 63, 228, 265, 267, 268, 273, 316, 327, 328, 329, 334, 339, 342, 344], "multipl": [6, 17, 18, 21, 22, 24, 25, 26, 27, 28, 32, 34, 37, 47, 48, 49, 51, 57, 272, 310, 318, 321, 328, 333, 334, 341, 342, 344], "togeth": [6, 16, 37, 324, 335, 343], "oper": [6, 10, 16, 33, 79, 95, 156, 181, 201, 208, 260, 263, 265, 266, 267, 268, 269, 270, 271, 272, 279, 282, 310, 313, 318, 334, 336, 339, 342, 343, 344], "config_list": [6, 7], "get_all_config_set_from_config_registri": [6, 312], "fwk_name": [6, 312], "retriev": [6, 13, 183, 201, 208, 334], "given": [6, 37, 42, 59, 120, 121, 123, 188, 193, 201, 204, 208, 222, 228, 237, 242, 269, 273, 287, 334, 342, 343], "union": [6, 46, 230, 233, 234, 242, 243, 269, 272, 327], "register_supported_configs_for_fwk": 6, "evaluationfuncwrapp": 7, "eval_fn": [7, 98, 233, 265, 269, 270, 271, 272, 273], "callabl": [7, 16, 44, 80, 97, 98, 101, 191, 207, 232, 233, 234, 237, 238, 242, 243, 269, 272, 312, 313], "eval_arg": [7, 98, 233, 265, 269, 270, 272], "wrapper": [7, 37, 42, 46, 51, 55, 79, 128, 185, 186, 196, 224, 228, 272, 338], "collect": [7, 8, 35, 37, 44, 46, 187, 198, 207, 208, 211, 214, 216, 225, 244, 257, 272, 279, 286, 336, 344], "note": [7, 42, 69, 108, 188, 192, 260, 262, 263, 265, 266, 267, 268, 271, 274, 279, 284, 286, 287, 312, 313, 316, 318, 320, 321, 324, 326, 328, 334, 336, 339, 342, 344], "deprec": [7, 312, 340, 343], "def": [7, 19, 20, 59, 120, 121, 123, 187, 242, 243, 265, 266, 269, 270, 272, 273, 279, 282, 285, 312, 313, 315, 316, 327, 328, 336, 342, 344], "eval_acc": 7, "eval_perf": 7, "mold": 7, "user_eval_fns1": 7, "user_eval_fns2": 7, "user_eval_fns3": 7, "user_eval_fns4": 7, "configset": 7, "base_config": [7, 9, 95, 97, 98, 99, 101, 233, 234, 237], "sampler": [7, 74, 183, 213, 234, 268, 273, 313, 316], "config_sourc": 7, "sequentialsampl": [7, 183], "size": [7, 23, 29, 33, 37, 55, 57, 150, 183, 186, 213, 221, 228, 257, 264, 267, 268, 279, 280, 286, 313, 316, 319, 328, 331, 332, 334, 336, 337, 339, 342, 343, 345], "sampl": [7, 16, 21, 22, 23, 33, 37, 46, 63, 130, 183, 208, 213, 268, 272, 273, 274, 279, 313, 317, 323, 336, 339, 342, 343, 344, 345], "element": [7, 42, 183, 199, 228, 257, 264, 268, 279, 323, 327, 331, 334, 339, 342], "sequenti": [7, 60, 62, 183, 187, 215, 273, 344], "alwai": [7, 42, 46, 59, 260, 273, 327, 328, 339], "same": [7, 16, 21, 37, 42, 82, 136, 181, 208, 257, 260, 264, 268, 273, 274, 279, 285, 287, 310, 313, 316, 320, 328, 331, 334, 336, 339, 342, 343, 344], "order": [7, 39, 40, 63, 68, 77, 268, 273, 279, 282, 327, 339, 342, 344], "_configset": 7, "configload": 7, "config_set": [7, 265, 270, 271, 272, 273], "default_sampl": [7, 273], "skip_verified_config": 7, "bool": [7, 15, 16, 21, 23, 33, 37, 40, 46, 74, 82, 95, 99, 181, 191, 193, 201, 204, 207, 208, 213, 215, 218, 220, 221, 222, 228, 234, 237, 240, 250, 253, 256, 257, 268, 269, 313, 327, 343], "yield": [7, 19, 20, 47, 59, 63, 183, 243, 279, 313, 336, 344], "tuningconfig": [7, 98, 233, 265, 269, 270, 271, 272, 273], "tolerable_loss": [7, 16, 273, 328, 344], "01": [7, 16, 220, 234, 268, 326, 328, 339, 344, 345], "max_trial": [7, 16, 265, 273, 328, 344], "pipelin": [7, 281, 315, 328, 333], "tune_config": [7, 98, 233, 265, 269, 270, 271, 272, 273, 286], "config1": 7, "config2": 7, "3": [7, 8, 16, 23, 37, 42, 181, 191, 208, 236, 257, 264, 265, 267, 268, 270, 272, 273, 274, 279, 282, 284, 294, 311, 312, 313, 316, 318, 320, 321, 324, 327, 328, 329, 331, 332, 334, 336, 339, 340, 341, 342, 343, 344, 345], "stop": [7, 16, 262, 273, 328, 344], "when": [7, 16, 21, 22, 30, 37, 40, 59, 97, 101, 107, 117, 123, 181, 191, 192, 201, 243, 260, 267, 268, 272, 273, 274, 275, 279, 280, 286, 312, 313, 328, 334, 336, 339, 342, 343, 344], "either": [7, 16, 42, 191, 267, 272, 273, 275, 279, 333, 336], "follow": [7, 23, 39, 42, 141, 156, 188, 215, 264, 265, 266, 271, 274, 275, 279, 280, 281, 282, 284, 285, 286, 287, 312, 313, 315, 316, 319, 320, 324, 325, 327, 328, 329, 330, 331, 333, 334, 336, 339, 342, 344], "condit": [7, 21, 22, 23, 37, 60, 62, 138, 273, 325, 343, 344], "met": [7, 273, 279, 320, 336], "trial": [7, 273, 344], "reach": [7, 16, 281, 313, 334, 344], "maximum": [7, 16, 21, 37, 40, 55, 63, 108, 186, 208, 220, 268, 279, 287, 311, 328, 334, 336, 342, 343], "metric": [7, 16, 19, 20, 38, 47, 59, 243, 246, 262, 271, 285, 286, 316, 328, 329, 336, 341, 342, 344, 345], "loss": [7, 16, 46, 243, 265, 267, 268, 272, 279, 311, 315, 316, 317, 326, 327, 328, 329, 333, 334, 335, 336, 339, 342, 344], "toler": [7, 272], "calcul": [7, 16, 24, 25, 43, 44, 68, 113, 183, 208, 220, 244, 257, 260, 266, 268, 272, 279, 311, 327, 328, 332, 334, 336, 339, 341, 342, 344], "relative_loss": 7, "fp32_baselin": [7, 246, 285], "eval_result_of_q_model": 7, "99": [7, 99, 345], "so": [7, 37, 77, 237, 260, 262, 264, 268, 269, 272, 279, 282, 284, 285, 319, 323, 329, 331, 336, 338, 339, 342, 343], "tuningmonitor": 7, "tuning_config": 7, "monitor": [7, 237, 269], "init_tun": 7, "tupl": [7, 16, 19, 20, 33, 37, 47, 59, 74, 98, 101, 194, 201, 203, 206, 207, 208, 212, 213, 220, 221, 230, 232, 233, 234, 237, 242, 243, 250, 256, 269, 272, 286, 312, 327, 328, 336, 343], "tuninglogg": [7, 13], "initi": [7, 19, 20, 21, 59, 75, 78, 81, 83, 87, 88, 89, 90, 91, 92, 93, 94, 96, 181, 191, 195, 204, 242, 243, 269, 272, 279, 287, 327, 334, 336, 342, 344], "api": [8, 42, 46, 59, 74, 75, 86, 98, 99, 100, 101, 123, 128, 156, 185, 187, 188, 215, 231, 233, 234, 235, 237, 239, 257, 260, 266, 268, 273, 279, 282, 284, 288, 290, 296, 299, 302, 318, 319, 321, 323, 324, 328, 340, 341, 344, 346], "intel": [8, 38, 45, 46, 58, 59, 67, 73, 86, 98, 99, 100, 101, 187, 188, 189, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 247, 259, 260, 262, 265, 266, 267, 268, 269, 270, 272, 273, 274, 276, 279, 280, 281, 283, 285, 286, 287, 311, 314, 315, 317, 318, 319, 320, 321, 325, 326, 329, 330, 332, 333, 334, 335, 336, 338, 339, 340, 342, 344, 345], "get_linux_numa_info": 8, "numa": [8, 274], "inform": [8, 16, 19, 20, 46, 185, 221, 257, 260, 264, 266, 268, 272, 274, 275, 280, 281, 283, 284, 285, 286, 287, 288, 290, 296, 299, 302, 311, 312, 320, 328, 330, 331, 334, 338, 339, 340, 342, 345, 346], "linux": [8, 274, 275, 310, 319], "demo": [8, 269, 328], "numa_index": 8, "physical_cpu": 8, "xxx": [8, 23, 328], "logical_cpu": 8, "e": [8, 16, 191, 268, 275, 279, 280, 281, 284, 317, 334, 339, 342, 344], "g": [8, 16, 191, 268, 275, 279, 281, 317, 334, 339, 340, 342, 344], "numa_info": 8, "23": [8, 326, 345], "48": [8, 279, 342, 345], "71": [8, 326, 345], "24": [8, 274, 334, 344, 345], "47": [8, 274, 326, 345], "72": [8, 279, 326, 342, 345], "95": [8, 46, 327, 345], "get_windows_numa_info": 8, "due": [8, 279, 287, 318, 334, 336, 342], "avail": [8, 16, 51, 208, 240, 265, 268, 269, 275, 284, 288, 290, 296, 299, 302, 312, 317, 319, 321, 323, 334, 344, 345], "info": [8, 15, 35, 51, 187, 207, 208, 212, 237, 242, 253, 254, 257, 282, 312, 330], "dump_numa_info": 8, "stat": [8, 242], "shell": [8, 284], "numa_node_index": 8, "cpu": [8, 15, 16, 143, 144, 145, 146, 187, 191, 193, 196, 208, 215, 224, 226, 228, 236, 238, 253, 257, 265, 267, 272, 274, 286, 310, 311, 323, 328, 329, 335, 336, 337, 338, 339], "node": [8, 55, 79, 103, 107, 108, 109, 110, 113, 115, 117, 120, 121, 123, 127, 130, 133, 135, 136, 137, 150, 156, 168, 181, 186, 201, 208, 228, 238, 248, 250, 274, 285, 316, 337, 344, 345], "parse_str2list": 8, "cpu_rang": 8, "pars": [8, 21, 22, 33, 37, 181, 186, 207, 208, 212, 286, 287, 343], "8": [8, 16, 36, 191, 199, 208, 213, 228, 234, 260, 263, 264, 266, 268, 269, 279, 282, 286, 311, 312, 320, 324, 331, 334, 335, 339, 342, 344, 345], "machin": [8, 39, 268, 272, 275, 318, 324, 335, 342], "readabl": [8, 312], "format_list2str": 8, "format": [8, 16, 21, 22, 23, 42, 75, 84, 85, 107, 181, 185, 186, 199, 226, 236, 239, 250, 253, 264, 265, 267, 269, 272, 274, 279, 284, 286, 287, 312, 316, 318, 327, 328, 329, 330, 331, 335, 336, 339], "back": [8, 37, 191], "human": [8, 344], "get_reversed_numa_info": 8, "revers": 8, "get_numa_nod": 8, "reversed_numa_info": 8, "current": [8, 16, 63, 69, 123, 208, 228, 236, 242, 257, 267, 268, 269, 273, 282, 284, 285, 287, 311, 312, 316, 320, 321, 328, 332, 334, 336, 339, 342, 344], "set_cores_for_inst": 8, "arg": [8, 21, 22, 23, 63, 107, 194, 215, 228, 232, 242, 253, 254, 264, 269, 316, 328, 331, 334, 336, 339, 342, 343], "each": [8, 16, 23, 26, 33, 37, 40, 42, 43, 44, 68, 82, 183, 191, 207, 208, 212, 228, 257, 262, 268, 271, 274, 279, 281, 285, 286, 287, 312, 315, 320, 328, 332, 334, 337, 339, 341, 343, 344], "ar": [8, 16, 21, 37, 42, 46, 60, 62, 63, 77, 120, 121, 188, 191, 201, 204, 208, 212, 246, 256, 257, 260, 263, 264, 265, 267, 268, 269, 271, 272, 275, 279, 280, 281, 282, 285, 286, 312, 313, 315, 316, 317, 318, 320, 322, 323, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 344], "below": [8, 16, 46, 59, 108, 119, 127, 260, 262, 264, 266, 268, 269, 272, 273, 279, 281, 282, 284, 285, 286, 287, 313, 316, 321, 322, 327, 331, 332, 333, 334, 336, 339, 341, 342, 344], "num_inst": [8, 274], "b": [8, 21, 127, 213, 257, 268, 279, 281, 311, 327, 334, 339, 342, 344], "num_cores_per_inst": [8, 274], "c": [8, 23, 127, 257, 268, 274, 279, 319, 339, 344], "argpars": 8, "argument": [8, 16, 191, 201, 208, 226, 233, 236, 237, 269, 272, 273, 339], "instance_index": 8, "node_index": 8, "cpu_index": 8, "num_cpu": 8, "core_list_per_inst": 8, "start": [8, 16, 37, 42, 64, 262, 324, 335, 343, 344, 346], "command_prefix": 8, "run_multi_instance_command": 8, "subprocess": [8, 312, 313], "script": [8, 39, 40, 43, 44, 281, 284, 316, 323, 335], "summary_latency_throughput": 8, "logfile_dict": 8, "interfac": [8, 97, 139, 186, 188, 246, 265, 267, 269, 272, 279, 323, 328, 336, 340], "modul": [9, 12, 190, 202, 205, 209, 219, 223, 229, 241, 260, 262, 265, 268, 269, 273, 282, 284, 292, 312, 313, 321, 323, 327, 328, 330, 334, 338, 339], "base_tun": [9, 98, 233, 270, 272], "benchmark": [9, 16, 38, 57, 257, 262, 284, 291, 292, 321, 330, 344, 345], "tuning_param": 9, "paramlevel": 10, "enumer": [10, 11, 243, 264, 285, 315, 316, 328, 331, 333, 334], "level": [10, 64, 254, 260, 264, 279, 280, 331, 342, 344], "op_level": 10, "op_type_level": 10, "model_level": 10, "tuningparam": 10, "default_v": 10, "ani": [10, 42, 44, 74, 98, 188, 191, 217, 230, 237, 238, 257, 269, 272, 280, 284, 287, 312, 316, 334, 341, 344], "tunable_typ": 10, "option": [10, 15, 16, 19, 20, 21, 37, 42, 46, 47, 59, 75, 77, 187, 188, 191, 193, 203, 204, 208, 210, 213, 220, 226, 228, 230, 232, 233, 234, 236, 237, 242, 243, 249, 250, 251, 253, 257, 268, 269, 272, 279, 286, 287, 312, 313, 320, 324, 328, 334, 336, 339, 341, 342, 343, 344], "defin": [10, 16, 19, 20, 47, 59, 139, 243, 256, 260, 270, 272, 273, 279, 280, 284, 285, 286, 313, 315, 320, 323, 327, 328, 333, 334, 336, 339, 341, 342, 344], "fakealgoconfig": 10, "algo": [10, 84, 85, 204, 237, 246], "simpl": [10, 37, 260, 272, 279, 328, 334, 341, 342, 344], "like": [10, 16, 19, 20, 23, 46, 55, 59, 127, 148, 150, 181, 183, 186, 191, 243, 265, 268, 272, 279, 281, 282, 284, 285, 286, 315, 323, 333, 334, 336, 339, 340, 342, 344], "give": [10, 286, 344], "enough": [10, 208, 272, 279, 336], "creat": [10, 16, 21, 23, 42, 75, 77, 183, 192, 201, 204, 246, 260, 262, 279, 280, 285, 330, 334, 336, 341, 344], "implicitli": [10, 191], "simple_attr": 10, "complex": [10, 265, 312, 328, 329, 334], "develop": [10, 57, 264, 265, 281, 282, 312, 324, 328, 329, 331, 334, 335, 338, 341], "explicitli": [10, 16, 267, 275, 322, 334], "complex_attr": 10, "model_attr": 10, "todo": [10, 21, 24, 42, 75, 183, 215, 238], "explain": [10, 279, 287, 342], "agnost": [11, 269], "mode": [11, 15, 30, 42, 55, 75, 156, 186, 191, 199, 208, 232, 234, 237, 242, 256, 257, 260, 268, 269, 285, 286, 323, 336, 338, 339, 344], "constant": [12, 63, 73, 184, 241, 250, 251, 312, 313, 320, 343], "logger": [12, 15, 244, 251, 257], "save_load": [12, 202, 205, 209, 223], "function": [13, 16, 19, 20, 22, 79, 92, 175, 192, 216, 251, 262, 265, 267, 268, 269, 272, 279, 281, 282, 285, 286, 287, 310, 313, 315, 318, 322, 323, 326, 327, 328, 329, 334, 336, 339, 341, 342, 344], "unifi": [13, 188, 230, 285, 286, 287, 313, 322, 323, 327, 328, 330], "It": [13, 19, 20, 44, 46, 47, 59, 64, 68, 107, 191, 228, 237, 243, 264, 267, 268, 269, 270, 272, 273, 279, 285, 286, 287, 311, 319, 321, 328, 331, 334, 336, 339, 341, 344], "assist": [13, 340], "valid": [13, 16, 23, 42, 55, 88, 90, 93, 94, 108, 120, 121, 186, 204, 284, 285, 317, 320, 323, 325, 328, 334, 336, 339, 340], "team": [13, 44, 280, 338], "save": [14, 16, 23, 55, 59, 181, 186, 191, 193, 203, 206, 210, 226, 237, 243, 244, 249, 250, 253, 257, 260, 269, 270, 279, 282, 284, 285, 322, 328, 329, 330, 333, 336, 337, 339, 342], "load": [14, 21, 36, 37, 47, 55, 59, 181, 186, 190, 192, 193, 203, 206, 207, 208, 210, 212, 226, 236, 239, 242, 256, 257, 260, 272, 286, 313, 319, 336, 337, 342], "save_config_map": 14, "config_map": [14, 222], "qconfig_file_path": 14, "map": [14, 16, 37, 41, 43, 44, 46, 191, 222, 237, 248, 250, 268, 279, 284, 312, 316, 327, 328, 334, 336, 339], "json": [14, 22, 37, 206, 208, 212, 256, 268, 330, 339, 343], "path": [14, 21, 22, 23, 37, 47, 55, 59, 75, 79, 181, 186, 193, 200, 207, 208, 210, 211, 212, 226, 237, 249, 250, 253, 257, 260, 267, 268, 269, 275, 282, 285, 316, 322, 327, 328, 329, 330, 333, 339, 343], "load_config_map": 14, "config_name_map": 14, "reload": 14, "get_all_config": 14, "singleton": [15, 156, 187, 257], "lazyimport": [15, 257], "module_nam": [15, 193, 257], "lazi": [15, 257], "python": [15, 23, 38, 128, 181, 191, 192, 238, 257, 259, 275, 282, 284, 312, 316, 319, 324, 328, 334, 335, 343], "till": [15, 257, 344], "cpuinfo": [15, 187, 257], "dump_elapsed_tim": [15, 187, 257, 285], "customized_msg": [15, 187, 257], "elaps": [15, 187, 257], "time": [15, 16, 37, 46, 57, 63, 181, 187, 191, 257, 267, 268, 269, 271, 273, 275, 279, 284, 286, 313, 316, 319, 328, 332, 334, 335, 336, 339, 341, 342, 343, 344], "set_random_se": [15, 16, 257], "seed": [15, 16, 187, 213, 234, 257, 268, 328], "random": [15, 16, 33, 37, 63, 67, 109, 187, 213, 257, 268, 328, 334, 343], "set_workspac": [15, 16, 257], "workspac": [15, 16, 256, 257, 330], "get_workspac": 15, "set_resume_from": [15, 16, 257], "resume_from": [15, 16, 257], "set_tensorboard": [15, 16, 257], "tensorboard": [15, 16, 246, 257, 285, 328], "log_process": 15, "call_count": 15, "func": [15, 181, 257, 336], "keep": [15, 64, 191, 282, 285, 312, 340], "track": [15, 341], "processortyp": [15, 234, 242], "processor": [15, 234, 242, 265, 275, 279, 284, 326, 329, 335, 336, 338], "detect_processor_type_based_on_hw": 15, "detect": [15, 16, 42, 46, 51, 212, 238, 242, 269, 281, 282, 334, 344], "hardwar": [15, 242, 264, 267, 275, 284, 285, 323, 328, 331, 334, 335], "server": [15, 275], "client": [15, 284], "statist": [15, 257, 258, 260], "header": [15, 257, 319], "field_nam": [15, 257], "output_handl": [15, 257], "printer": [15, 257], "x": [16, 37, 63, 108, 127, 208, 273, 279, 284, 311, 312, 316, 321, 324, 329, 330, 336, 337, 342, 343], "dotdict": [16, 57, 257], "access": [16, 120, 121, 123, 253, 257], "yaml": [16, 19, 20, 21, 23, 84, 256, 257, 285, 287, 322, 327, 328, 332, 343], "attribut": [16, 136, 242, 257, 260, 285, 313, 320, 322, 328], "instead": [16, 257, 267, 334, 339], "dictionari": [16, 36, 42, 120, 121, 123, 187, 191, 199, 208, 212, 226, 236, 242, 257], "notat": [16, 257], "random_se": [16, 63, 328], "1978": 16, "default_workspac": 16, "global": [16, 77, 185, 257, 268, 269, 270, 282, 328, 334, 344], "you": [16, 21, 46, 59, 191, 208, 260, 262, 281, 282, 286, 312, 313, 316, 319, 324, 325, 327, 329, 334, 336, 339, 340, 341, 342], "want": [16, 21, 64, 120, 121, 123, 243, 282, 285, 313, 316, 328, 332, 336, 339, 341, 344], "should": [16, 19, 20, 21, 23, 37, 40, 46, 47, 59, 97, 101, 108, 191, 208, 222, 226, 236, 243, 250, 257, 267, 269, 270, 271, 272, 274, 279, 282, 285, 286, 287, 316, 327, 328, 332, 334, 336, 339, 343, 344], "directori": [16, 22, 23, 55, 186, 203, 226, 236, 253, 256, 257, 284, 316, 319], "where": [16, 42, 46, 77, 191, 203, 257, 279, 287, 311, 342], "intermedi": [16, 279, 282, 323, 336], "histori": [16, 256, 257, 344], "store": [16, 23, 79, 203, 208, 322], "nc_workspac": 16, "datetim": 16, "now": [16, 37, 282, 287, 316, 343, 344], "strftime": 16, "y": [16, 37, 63, 155, 279, 312, 319, 342, 343], "m": [16, 208, 228, 274, 281, 324, 334, 345], "d_": 16, "h": [16, 37, 316, 343], "resum": [16, 19, 20, 60, 62, 63, 64, 68, 71], "wa": [16, 191, 264, 266, 285, 328, 331, 335, 344], "automat": [16, 23, 26, 33, 238, 242, 260, 269, 272, 274, 275, 282, 284, 310, 323, 328, 329, 333, 334, 336, 342, 343, 344], "dure": [16, 57, 191, 192, 208, 237, 242, 257, 266, 267, 269, 272, 279, 284, 286, 321, 328, 330, 332, 333, 334, 336, 342], "last": [16, 208, 260, 265, 266, 268, 313, 329, 336, 339, 342], "flag": [16, 40], "whether": [16, 21, 33, 37, 40, 42, 46, 101, 181, 187, 191, 204, 207, 208, 215, 220, 221, 228, 237, 240, 246, 253, 256, 257, 268, 274, 285, 327, 336, 339, 342, 343], "visual": [16, 341, 344], "displai": [16, 74, 75, 187, 257], "2022": [16, 268, 279, 325, 334, 339, 342], "workspace_path": 16, "output": [16, 19, 20, 39, 46, 47, 55, 59, 104, 107, 112, 127, 150, 156, 181, 186, 187, 203, 208, 210, 212, 220, 226, 228, 234, 237, 243, 249, 250, 253, 254, 257, 260, 268, 269, 270, 279, 282, 285, 286, 315, 316, 318, 320, 322, 327, 328, 330, 333, 334, 336, 339, 342, 343, 344], "devic": [16, 132, 142, 143, 144, 145, 146, 149, 153, 167, 172, 180, 191, 193, 196, 208, 212, 213, 215, 218, 220, 224, 226, 228, 236, 240, 242, 253, 265, 268, 269, 275, 279, 284, 286, 313, 328, 329, 334, 337, 339], "warmup": [16, 310, 328], "model_nam": [16, 284], "inter_num_of_thread": [16, 328], "intra_num_of_thread": [16, 328], "ni_workload_nam": 16, "empti": [16, 193, 242, 260, 268, 269, 337], "includ": [16, 21, 23, 30, 37, 188, 192, 213, 226, 232, 236, 242, 257, 260, 268, 269, 272, 273, 275, 280, 285, 286, 287, 313, 324, 325, 326, 327, 328, 334, 336, 338, 339, 344], "itex": [16, 85, 155, 249, 272, 329, 336, 342], "ipex": [16, 206, 207, 208, 212, 232, 236, 240, 256, 265, 266, 323, 326, 328, 329, 342], "onnxrt_trt_ep": [16, 329, 336], "onnxrt_cuda_ep": [16, 329, 336], "onnxrt_dnnl_ep": [16, 329, 336], "onnxrt_dml_ep": [16, 336], "inter": 16, "intra": 16, "accuracycriterion": [16, 328, 344], "higher_is_bett": [16, 46, 59, 344], "criterion": [16, 315, 328, 334, 336, 342, 344], "rel": [16, 57, 328, 344, 345], "better": [16, 19, 20, 47, 59, 148, 243, 265, 268, 279, 312, 315, 327, 329, 334, 335, 336, 339, 341, 342, 344], "absolut": [16, 46, 208, 264, 279, 327, 328, 331, 334, 336, 344], "how": [16, 37, 191, 228, 242, 262, 265, 267, 268, 269, 270, 271, 272, 279, 281, 282, 283, 285, 313, 315, 316, 322, 327, 328, 334, 335, 336, 342, 343, 344], "much": [16, 37, 279, 342, 343], "accept": [16, 273, 280, 310, 312, 313, 339], "accuracy_criterion": [16, 57, 328, 332, 344], "tuningcriterion": [16, 328, 332, 341, 344], "strategi": [16, 17, 23, 38, 262, 273, 279, 284, 285, 286, 287, 291, 311, 312, 313, 316, 323, 328, 335, 336, 338, 339, 340], "basic": [16, 36, 67, 71, 74, 243, 264, 323, 328, 331, 341], "strategy_kwarg": [16, 341, 344], "timeout": [16, 328, 344], "doc": [16, 46, 59, 74, 75, 187, 238, 257, 284, 324, 327, 328], "tuning_strategi": 16, "md": [16, 46, 59], "constraint": [16, 328, 334, 341, 344], "guarante": [16, 328], "models": [16, 57, 328, 332], "footprint": [16, 57, 315, 328, 332, 334, 337], "second": [16, 21, 64, 117, 191, 257, 268, 275, 279, 328, 339, 342, 344], "mean": [16, 33, 37, 44, 46, 68, 208, 220, 226, 236, 260, 268, 270, 279, 282, 286, 287, 313, 316, 320, 327, 328, 334, 336, 337, 339, 342, 343, 344, 345], "earli": [16, 279, 328, 336, 344], "combin": [16, 19, 20, 33, 47, 59, 187, 212, 243, 257, 268, 271, 282, 284, 285, 323, 328, 333, 335, 336, 338, 339, 343, 344], "field": [16, 23, 42, 264, 282, 285, 287, 316, 328, 331, 341, 344], "decid": [16, 40, 272, 274, 285, 286, 328, 336, 340, 344], "exit": [16, 60, 62, 273, 328], "tuning_criterion": [16, 328, 332, 341, 344], "posttrainingquantconfig": [16, 59, 282, 287, 313, 318, 327, 328, 330, 336, 337, 338, 339, 341, 342, 344], "domain": [16, 334, 344], "recip": [16, 102, 264, 273, 284, 321, 328, 331, 337, 339, 342, 344], "quant_format": [16, 250, 318], "approach": [16, 267, 268, 279, 282, 311, 323, 328, 334, 335, 337, 339, 344], "calibration_sampling_s": [16, 328], "op_type_dict": [16, 267, 287, 336, 339, 344], "op_name_dict": [16, 267, 328, 336, 344], "reduce_rang": [16, 287], "example_input": [16, 203, 206, 207, 208, 212, 227, 228, 230, 233, 237, 250, 256, 263, 266, 267, 268, 269, 318], "excluded_precis": [16, 234, 338], "quant_level": [16, 339, 342, 344], "gpu": [16, 142, 149, 191, 208, 238, 268, 272, 310, 323, 328, 329, 336, 337], "npu": [16, 336], "xpu": [16, 212, 238, 272, 336], "cv": [16, 260, 267, 269, 272, 334], "object_detect": [16, 42], "nlp": [16, 265, 269, 272, 279, 334, 336], "recommendation_system": 16, "adaptor": [16, 77, 84, 85, 246, 262, 287, 323, 337, 338, 340, 342], "overrid": [16, 257, 312], "quantiztaion": [16, 212], "do": [16, 21, 39, 42, 206, 250, 256, 260, 269, 280, 286, 312, 316, 320, 323, 327, 328, 334, 338, 340, 342, 344], "quant": [16, 75, 81, 83, 84, 85, 95, 99, 208, 211, 228, 233, 234, 268, 279, 282, 312, 326, 328, 336], "smooth_quant_arg": [16, 336, 342], "layer_wise_qu": [16, 337], "fast": [16, 268, 272, 334, 335, 339], "bia": [16, 176, 198, 218, 224, 339], "gemm_to_matmul": [16, 336], "convert": [16, 21, 33, 36, 37, 42, 75, 79, 84, 85, 102, 103, 106, 107, 108, 109, 110, 119, 127, 139, 151, 167, 172, 188, 194, 201, 232, 237, 242, 249, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 275, 279, 282, 284, 286, 321, 328, 329, 336, 338, 339, 342, 343, 344], "gemm": 16, "matmul": [16, 99, 106, 112, 118, 126, 146, 155, 164, 173, 320, 339, 344], "add": [16, 21, 23, 75, 106, 117, 155, 181, 257, 262, 266, 281, 282, 284, 287, 313, 316, 318, 320, 327, 328, 341, 342, 344], "graph_optimization_level": [16, 336], "disable_al": 16, "enable_bas": 16, "enable_extend": 16, "enable_al": 16, "first_conv_or_matmul_quant": [16, 336], "last_conv_or_matmul_quant": [16, 336], "pre_post_process_quant": [16, 336], "preprocess": [16, 21, 37, 77, 228, 246, 316, 343], "postprocess": [16, 34, 37, 46, 59, 246, 285, 328, 343], "add_qdq_pair_to_weight": [16, 336], "qdq": [16, 84, 140, 158, 228, 248, 249, 250, 271, 285, 318, 323, 336, 342], "pair": [16, 153, 201, 265, 267, 286, 313, 328, 329], "optypes_to_exclude_output_qu": [16, 336], "optyp": [16, 248, 286], "dedicated_qdq_pair": [16, 336], "dedic": 16, "qoper": [16, 318], "requir": [16, 55, 186, 228, 260, 265, 267, 268, 272, 279, 282, 285, 286, 310, 311, 313, 315, 316, 319, 320, 328, 329, 330, 334, 336, 339, 340, 341, 342, 344], "onnxruntim": [16, 23, 30, 285, 311, 313, 323, 324, 329], "tensorflow": [16, 21, 22, 23, 26, 28, 30, 37, 38, 40, 42, 46, 47, 55, 59, 69, 249, 250, 257, 271, 281, 285, 286, 292, 311, 312, 313, 315, 317, 320, 321, 323, 328, 329, 330, 331, 334, 335, 341, 342, 344], "method": [16, 21, 23, 30, 37, 75, 77, 82, 176, 188, 191, 192, 212, 226, 236, 246, 251, 253, 254, 260, 268, 269, 270, 272, 279, 282, 284, 311, 312, 313, 315, 327, 328, 333, 334, 336, 338, 339, 342, 343, 344], "dynam": [16, 75, 183, 191, 204, 230, 232, 234, 250, 268, 269, 284, 285, 313, 318, 321, 323, 328, 335, 344, 345], "weight_onli": [16, 189, 234, 256, 264, 312, 331, 337, 339], "ptq": [16, 59, 266, 267, 271, 272, 282, 316, 323, 328, 336, 342, 344], "both": [16, 181, 238, 267, 268, 270, 275, 279, 280, 285, 315, 328, 334, 336, 339, 342, 344], "meet": [16, 60, 62, 268, 270, 272, 273, 279, 282, 286, 332, 335, 336, 339, 344], "criteria": [16, 273, 282, 342], "bayesian": [16, 67, 334], "mse": [16, 46, 59, 67, 257, 268, 279, 327, 339, 340], "mse_v2": [16, 67], "hawq_v2": [16, 67], "exhaust": [16, 67, 208], "els": [16, 57, 181, 228, 339], "advanc": [16, 264, 265, 268, 270, 272, 279, 280, 286, 291, 326, 331, 334, 336, 339], "reduc": [16, 234, 265, 266, 267, 268, 271, 272, 279, 285, 311, 315, 328, 329, 334, 335, 336, 337, 338, 339, 342, 344], "dtype": [16, 24, 25, 33, 37, 183, 196, 201, 204, 208, 218, 224, 228, 234, 253, 265, 268, 269, 279, 286, 287, 318, 320, 336, 339, 342, 343], "activ": [16, 75, 77, 82, 88, 89, 90, 94, 208, 212, 234, 260, 263, 266, 267, 268, 271, 272, 279, 285, 286, 287, 311, 315, 320, 328, 336, 339, 342], "layer1": [16, 328, 334, 336], "conv1": [16, 270, 336], "bit": [16, 77, 208, 216, 221, 224, 228, 234, 260, 263, 264, 265, 268, 269, 279, 287, 311, 315, 329, 331, 335, 336, 339, 342], "precis": [16, 19, 20, 44, 46, 47, 57, 61, 64, 75, 85, 194, 195, 196, 201, 232, 234, 257, 260, 262, 264, 267, 268, 269, 273, 279, 284, 285, 286, 291, 310, 311, 315, 316, 320, 321, 323, 331, 335, 336, 339, 342, 344], "exclud": [16, 260, 285, 311, 338], "enabl": [16, 155, 204, 265, 267, 268, 272, 286, 287, 316, 329, 334, 335, 342, 344], "mix": [16, 47, 61, 75, 195, 232, 234, 262, 269, 284, 285, 291, 321, 323], "bf16": [16, 75, 140, 194, 196, 201, 234, 260, 272, 285, 286, 320, 328, 338, 344, 345], "disabl": [16, 187, 280, 338, 339, 342], "conserv": [16, 67], "In": [16, 42, 57, 242, 262, 268, 269, 272, 279, 280, 282, 284, 285, 286, 313, 315, 316, 327, 328, 332, 333, 334, 336, 338, 339, 341, 342, 343, 344], "docstr": 16, "quantizationawaretrainingconfig": [16, 243, 282, 315, 318, 328, 336, 338, 344], "awar": [16, 66, 234, 243, 268, 269, 273, 285, 286, 287, 311, 315, 316, 318, 323, 333, 335, 339, 344], "qat": [16, 55, 284, 315, 316, 321, 323, 328, 336], "copi": [16, 257, 313], "deepcopi": 16, "model_origin": [16, 59, 338], "qat_op_name_dict": 16, "compression_manag": [16, 243, 282, 315, 328, 333, 334, 336], "prepare_compress": [16, 243, 282, 315, 328, 333, 334, 336], "weightpruningconfig": [16, 328, 333, 334], "pruning_config": [16, 328, 334], "target_spars": [16, 328, 334], "9": [16, 266, 274, 282, 324, 328, 334, 342, 344, 345], "pruning_typ": [16, 328, 334], "snip_momentum": [16, 328, 334], "pattern": [16, 23, 75, 111, 112, 114, 131, 148, 153, 154, 155, 167, 172, 201, 263, 267, 271, 274, 285, 312, 320, 323, 328, 333, 342, 344, 345], "4x1": [16, 328, 334, 345], "op_nam": [16, 76, 208, 212, 228, 242, 257, 258, 267, 286, 328, 334], "excluded_op_nam": [16, 124, 125, 328, 334], "start_step": [16, 328, 334], "end_step": [16, 328, 334], "pruning_scop": [16, 328, 334], "pruning_frequ": [16, 328, 334], "min_sparsity_ratio_per_op": [16, 328, 334], "max_sparsity_ratio_per_op": [16, 328, 334], "98": [16, 328, 334, 345], "sparsity_decay_typ": [16, 328, 334], "exp": [16, 264, 328, 331, 334], "pruning_op_typ": [16, 328, 334], "low_memory_usag": 16, "kwarg": [16, 23, 35, 37, 46, 47, 48, 50, 52, 54, 55, 56, 59, 74, 76, 88, 89, 90, 93, 94, 159, 160, 161, 162, 163, 164, 165, 168, 169, 171, 173, 174, 186, 193, 194, 213, 215, 224, 226, 228, 232, 234, 236, 242, 243, 253, 254, 256, 257, 313], "prune": [16, 257, 262, 284, 316, 317, 320, 321, 323, 333, 335], "singl": [16, 21, 37, 42, 46, 59, 101, 183, 201, 208, 268, 282, 284, 324, 334, 337, 342], "sequenc": [16, 21, 36, 37, 40, 44, 116, 213, 268, 279, 285, 320, 334, 339, 343], "local": [16, 226, 236, 257, 268, 270, 284, 319, 324, 334, 341], "link": [16, 21, 46, 59, 260, 269, 311, 318, 339, 345], "out": [16, 21, 22, 23, 207, 208, 268, 270, 272, 279, 281, 282, 284, 334, 336, 339], "By": [16, 39, 191, 268, 275, 286, 287, 327, 330, 334, 335, 339, 344], "correspond": [16, 21, 39, 42, 46, 207, 208, 212, 222, 246, 257, 260, 269, 279, 285, 320, 328, 334, 336, 341, 344], "sparsiti": [16, 257, 262, 268, 284, 323, 328, 345], "after": [16, 21, 33, 37, 64, 131, 181, 201, 208, 240, 253, 257, 260, 263, 267, 268, 271, 279, 284, 286, 315, 318, 323, 327, 328, 332, 333, 334, 336, 338, 339, 341, 342, 343, 344], "90": [16, 326, 337, 345], "magnitud": [16, 46, 208, 323, 334], "snip": [16, 323, 334, 345], "magnitude_progress": 16, "snip_progress": 16, "snip_momentum_progress": 16, "pattern_lock": 16, "most": [16, 46, 260, 265, 268, 272, 279, 328, 329, 334, 336, 339, 342, 344, 345], "feasibl": 16, "under": [16, 23, 156, 187, 242, 253, 256, 273, 281, 284, 325, 327, 328, 333, 334, 335, 337, 339, 344], "situat": [16, 316, 334], "structur": [16, 76, 215, 257, 262, 269, 279, 323, 334, 335, 336, 345], "unstructur": [16, 323, 334, 345], "nxm": [16, 334], "8x1": 16, "channelx1": [16, 334], "1xchannel": [16, 334], "n": [16, 22, 37, 40, 279, 287, 312, 326, 334, 336, 342, 343], "directli": [16, 42, 46, 270, 327, 328, 334, 336], "our": [16, 176, 208, 264, 284, 318, 328, 331, 341], "itrex": [16, 266, 342], "some": [16, 21, 268, 279, 284, 286, 287, 312, 318, 321, 324, 327, 328, 332, 334, 336, 338, 339, 342, 344], "step": [16, 243, 263, 266, 267, 268, 279, 286, 287, 315, 316, 328, 333, 334, 338, 339, 341, 342, 344], "integ": [16, 42, 46, 266, 268, 271, 279, 285, 287, 311, 336, 339, 342, 344], "end": [16, 21, 36, 37, 60, 62, 181, 285, 286, 287, 315, 320, 324, 328, 332, 334, 339, 343, 344], "determin": [16, 222, 252, 263, 267, 273, 275, 280, 282, 311, 334, 336], "score": [16, 39, 40, 42, 43, 44, 46, 66, 246, 282, 327, 332, 334, 341, 344], "gather": 16, "sort": [16, 68, 268, 339, 344], "sinc": [16, 39, 260, 268, 279, 318, 327, 333, 339], "lead": [16, 265, 268, 272, 279, 312, 328, 329, 334, 339, 342], "less": [16, 108, 187, 228, 257, 310, 328, 334], "frequenc": [16, 328, 334], "minimum": [16, 208, 220, 264, 287, 311, 328, 331, 334, 342, 344], "restrict": [16, 123, 191, 334, 341], "everi": [16, 120, 121, 123, 268, 285, 313, 337, 339, 344], "schedul": [16, 268, 328, 333], "increas": [16, 264, 268, 314, 323, 331, 339, 344], "cube": [16, 334], "local_config": 16, "6": [16, 264, 266, 268, 271, 279, 320, 331, 336, 342, 344, 345], "queri": [16, 84, 85, 212, 242, 279, 286, 287, 336], "kei": [16, 55, 186, 187, 191, 193, 208, 228, 244, 246, 257, 268, 279, 284, 286, 335, 339, 344], "self": [16, 57, 116, 228, 269, 285, 286, 313, 323, 327, 341, 344], "attent": [16, 21, 212, 280, 334], "dens": [16, 91, 334, 345], "update_config": 16, "10": [16, 23, 63, 220, 273, 274, 284, 310, 318, 324, 328, 334, 343, 344, 345], "hpoconfig": 16, "search_spac": 16, "searcher": 16, "xgb": 16, "loss_typ": [16, 328], "reg": 16, "min_train_sampl": 16, "42": [16, 213, 234, 268, 345], "hyperparamet": [16, 279, 341, 342, 344], "optim": [16, 63, 107, 127, 128, 132, 133, 181, 219, 234, 243, 244, 257, 262, 267, 268, 271, 272, 273, 275, 279, 284, 310, 312, 315, 316, 320, 323, 324, 326, 328, 330, 335, 336, 338, 339, 341, 342, 344], "search": [16, 19, 20, 39, 63, 201, 215, 228, 257, 262, 268, 269, 271, 284, 312, 323, 327, 334, 335, 339, 342, 344], "grid": [16, 334], "bo": 16, "knowledgedistillationlossconfig": [16, 315, 328, 333], "temperatur": [16, 328], "ce": [16, 328], "loss_weight": [16, 328], "knowledg": [16, 271, 315, 317, 323, 328, 330], "distil": [16, 262, 284, 317, 321, 323, 333], "entropi": [16, 311, 344], "probabl": [16, 252, 268, 279, 339], "length": [16, 21, 37, 42, 213, 268, 279, 327, 335, 336, 339, 343], "item": [16, 36, 75, 187, 257, 279, 311, 316, 334, 342, 344], "student": [16, 21, 315, 345], "groundtruth": [16, 42], "label": [16, 19, 20, 21, 23, 24, 25, 26, 29, 33, 37, 39, 41, 46, 47, 59, 183, 208, 243, 272, 282, 313, 327, 328, 336, 343], "teacher": [16, 315, 328, 345], "kl": [16, 204, 208, 234, 244, 252, 286, 287, 311, 320, 328, 344], "sum": [16, 46], "multipli": [16, 263, 264, 268, 331, 339], "distillationconfig": [16, 243, 315, 328, 333], "criterion_conf": 16, "d_conf": [16, 315, 328, 333], "teacher_model": [16, 315, 328], "intermediatelayersknowledgedistillationlossconfig": 16, "layer_map": 16, "add_origin_loss": 16, "relationship": 16, "student_layer_nam": 16, "student_layer_output_process": 16, "teacher_layer_nam": 16, "teacher_layer_output_process": 16, "bert": [16, 21, 37, 284, 327, 329, 334, 343, 345], "desir": [16, 33, 37, 204, 266, 286, 287, 334, 342, 343], "its": [16, 23, 37, 40, 41, 63, 113, 148, 201, 203, 248, 265, 268, 273, 279, 280, 325, 327, 329, 334, 339, 341, 343, 344], "take": [16, 19, 20, 37, 46, 47, 59, 63, 183, 243, 265, 268, 272, 275, 280, 282, 284, 313, 320, 328, 334, 336, 338, 339, 343, 344], "serv": [16, 55, 186, 279], "numer": [16, 46, 264, 265, 268, 272, 287, 329, 331, 335, 336, 339], "abbrevi": 16, "further": [16, 123, 265, 279, 280, 284, 329, 330, 336], "layer_nam": [16, 208, 334], "student_model": [16, 328], "l1": 16, "len": [16, 37, 316, 343], "origin": [16, 21, 37, 64, 77, 79, 181, 193, 208, 222, 226, 228, 236, 237, 253, 257, 268, 269, 270, 272, 279, 281, 334, 336, 339, 343, 344], "selfknowledgedistillationlossconfig": [16, 328], "student1_layer_name1": 16, "teacher_layer_name1": 16, "student2_layer_name1": 16, "student1_layer_name2": 16, "teacher_layer_name2": 16, "student2_layer_name2": 16, "soft": 16, "l2": [16, 334], "hard": [16, 313], "resblock": 16, "featur": [16, 21, 22, 33, 37, 208, 265, 270, 279, 281, 284, 310, 313, 314, 328, 329, 330, 334, 335, 340, 343], "deepst": 16, "fc": [16, 334], "02": [16, 345], "nn": [16, 47, 59, 193, 203, 207, 208, 212, 215, 222, 224, 226, 228, 230, 232, 233, 236, 237, 242, 250, 253, 256, 260, 268, 269, 279, 282, 328, 330, 339, 342], "crossentropyloss": [16, 328], "sgd": [16, 328], "lr": [16, 213, 234, 268, 316, 328], "0001": [16, 328], "learning_r": [16, 328], "altern": [16, 59, 191], "distil_loss": [16, 328], "mixedprecisionconfig": [16, 47, 232, 234, 265, 328, 329], "mixedprecis": [16, 328], "target": [16, 63, 84, 201, 215, 253, 260, 269, 316, 328, 334, 343, 344], "convers": [16, 107, 108, 201, 265, 266, 279, 281, 285, 286, 328, 329, 336, 338, 342], "fp16": [16, 75, 194, 196, 201, 213, 234, 279, 336], "fallback": [16, 66, 68, 69, 265, 266, 267, 318, 329, 338, 344], "won": [16, 336, 339], "work": [16, 97, 101, 269, 272, 274, 275, 279, 283, 286, 312, 313, 338, 339, 340, 342], "tensor": [16, 37, 55, 68, 79, 123, 181, 186, 187, 191, 193, 199, 201, 203, 206, 207, 208, 212, 217, 218, 220, 221, 228, 233, 237, 248, 250, 253, 256, 257, 260, 263, 264, 269, 272, 282, 287, 312, 313, 331, 334, 336, 340, 343, 344], "trace": [16, 66, 203, 207, 208, 212, 233, 237, 250, 267, 269, 282, 344], "mix_precis": [16, 38, 328, 329], "converted_model": [16, 47, 328, 329], "exportconfig": 16, "opset_vers": [16, 249, 250, 318], "14": [16, 249, 250, 318, 324, 345], "input_nam": [16, 55, 120, 121, 186, 249, 250, 318], "output_nam": [16, 55, 186, 249, 250, 318], "dynamic_ax": [16, 250, 318], "common": [16, 35, 38, 95, 97, 98, 99, 101, 175, 191, 192, 232, 233, 234, 237, 242, 246, 266, 270, 271, 272, 280, 312, 315, 316, 318, 321, 322, 324, 328, 336, 342], "export": [16, 42, 231, 251, 262, 263, 265, 267, 319], "select": [16, 21, 228, 232, 238, 253, 260, 268, 279, 282, 311, 323, 324, 334, 336, 339, 344], "opset": [16, 249, 250, 318], "version": [16, 38, 107, 224, 240, 249, 250, 262, 266, 280, 282, 284, 285, 312, 320, 324, 325, 328, 335, 342, 344], "qlinear": [16, 23, 30, 46, 248, 285], "ax": [16, 199, 250], "onnxqlinear2qdqconfig": 16, "onnxqlinear2qdq": 16, "torch2onnxconfig": [16, 318], "torch2onnx": [16, 247], "qdq_op_fp32_bia": 16, "qdq_op_int32_bia": 16, "qdq_op_fp32_bias_qdq": 16, "resnet50": [16, 270, 284, 316, 318, 329, 334, 336, 341, 345], "int8_onnx_config": [16, 318], "randn": [16, 318], "224": [16, 33, 316, 318, 328, 343], "batch_siz": [16, 21, 22, 183, 213, 234, 250, 268, 313, 316, 318, 322, 328, 336], "q_model": [16, 59, 97, 101, 212, 263, 266, 267, 271, 273, 282, 313, 316, 318, 322, 327, 328, 330, 336, 337, 338, 339], "tf2onnxconfig": [16, 318], "tf2onnx": [16, 247], "axi": [16, 220, 221], "addit": [16, 243, 268, 286, 287, 339, 340, 344], "keyword": [16, 191, 208, 226, 236], "output_graph": 16, "nasconfig": 16, "search_algorithm": 16, "dyna": 16, "na": [16, 51, 272, 323, 345], "mxnet": [16, 23, 26, 30, 37, 46, 47, 52, 59, 285, 286, 311, 313, 317, 320, 323, 328, 329, 330, 344], "kera": [16, 23, 30, 50, 55, 83, 86, 98, 101, 123, 186, 187, 270, 272, 286, 313, 316, 330], "pytorch": [16, 21, 23, 26, 30, 37, 46, 47, 56, 59, 69, 188, 189, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 250, 251, 257, 264, 269, 281, 282, 284, 285, 286, 287, 292, 311, 312, 313, 315, 317, 320, 321, 323, 324, 326, 328, 329, 330, 331, 334, 335, 339, 340, 342, 344], "built": [17, 18, 21, 22, 27, 29, 31, 32, 33, 34, 37, 46, 49, 57, 59, 97, 101, 128, 243, 272, 273, 285, 316, 328, 332, 336, 341, 343, 344], "sigopt": [18, 335], "tpe": 18, "provid": [19, 20, 37, 42, 47, 59, 156, 204, 208, 243, 251, 253, 260, 262, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 279, 284, 285, 286, 287, 310, 313, 315, 316, 317, 321, 323, 324, 326, 327, 328, 329, 330, 334, 336, 339, 342, 344, 345], "sigopttunestrategi": 19, "q_dataload": [19, 20, 60, 62, 63, 64, 68, 71, 322, 344], "q_func": [19, 20, 60, 62, 63, 64, 68, 71, 208, 285, 286, 328, 344], "eval_func": [19, 20, 47, 59, 60, 62, 63, 64, 68, 71, 79, 243, 282, 313, 315, 316, 328, 336, 337, 338, 339, 344], "eval_metr": [19, 20, 47, 59, 60, 62, 63, 64, 68, 71, 243, 327, 336], "q_hook": [19, 20, 60, 62, 63, 64, 68, 71], "hpo": [19, 334], "low": [19, 20, 24, 25, 47, 183, 260, 265, 268, 273, 279, 285, 286, 310, 311, 316, 328, 329, 335, 336, 339, 342, 344], "loader": [19, 20, 47, 59, 79, 97, 101, 226, 243, 253, 313, 336], "mandatori": [19, 20, 59, 328], "dataset": [19, 20, 32, 42, 43, 44, 46, 47, 59, 79, 82, 183, 213, 243, 246, 266, 268, 270, 271, 272, 279, 285, 286, 313, 316, 327, 328, 334, 336, 339, 340, 342, 344, 345], "_": [19, 20, 59, 265, 266, 268, 269, 272, 274, 279, 282, 284, 285, 286, 311, 316, 318, 320, 324, 328, 329, 330, 332, 334, 336, 339, 340, 341, 342, 344], "depend": [19, 20, 47, 59, 243, 281, 284, 319, 320, 324, 336, 344], "implement": [19, 20, 21, 23, 39, 47, 57, 59, 66, 156, 176, 180, 188, 191, 243, 268, 287, 313, 327, 328, 334, 336, 339, 340, 344], "well": [19, 20, 47, 59, 243, 264, 279, 284, 312, 331, 334, 336, 340, 342], "taken": [19, 20, 47, 59, 243, 336], "reserv": [19, 20], "abl": [19, 20, 47, 59, 243, 272, 279, 336], "pre": [19, 20, 21, 47, 59, 132, 193, 234, 243, 267, 268, 273, 279, 312, 315, 328, 334, 335, 336, 339, 344], "through": [19, 20, 46, 47, 59, 267, 268, 269, 279, 284, 310, 320, 322, 323, 327, 332, 333, 334, 336, 339], "tuner": [19, 20, 47, 59, 243, 336], "encapsul": [19, 20, 47, 59, 156, 243, 330], "scalar": [19, 20, 47, 59, 243, 327, 336, 344], "pseudo": [19, 20, 59, 243, 268, 339], "code": [19, 20, 59, 191, 234, 243, 262, 265, 268, 270, 282, 284, 285, 286, 287, 315, 316, 322, 323, 325, 327, 332, 333, 334, 335, 336, 341, 342, 343], "someth": [19, 20, 23, 59, 243], "fefin": 20, "tpetunestrategi": 20, "pytorchbertdataset": 21, "task": [21, 28, 46, 176, 260, 266, 268, 275, 279, 315, 318, 323, 327, 328, 334, 337, 339, 342, 345], "model_typ": [21, 257], "transform": [21, 22, 23, 24, 25, 26, 28, 30, 32, 103, 176, 178, 179, 180, 183, 201, 207, 208, 212, 215, 227, 234, 240, 266, 267, 268, 271, 279, 282, 284, 311, 315, 316, 317, 321, 326, 328, 334, 335, 338, 339, 342, 344], "filter": [21, 22, 23, 24, 25, 26, 28, 32, 88, 94, 183, 201, 222, 257, 287, 323, 334], "construct": [21, 24, 25, 28, 35, 46, 51, 55, 77, 183, 185, 186, 191, 246, 273, 280, 286, 287, 316, 334, 344], "tensordataset": 21, "full": [21, 22, 23, 253, 257, 260, 268, 284, 311, 319, 325, 334, 339, 340], "repo": [21, 261, 281, 317, 346], "http": [21, 23, 39, 40, 42, 43, 44, 46, 59, 215, 234, 268, 282, 284, 324, 325, 328, 334, 340], "github": [21, 39, 40, 43, 44, 46, 59, 234, 268, 281, 284, 317, 324, 325, 328, 340], "com": [21, 39, 40, 43, 44, 46, 59, 234, 280, 312, 324, 325, 328, 340, 341, 345], "huggingfac": [21, 226, 236, 253, 264, 284, 317, 331, 342, 345], "your": [21, 262, 267, 281, 284, 312, 313, 316, 325, 328, 334, 335, 341, 344], "easi": [21, 267, 269, 272, 318, 328, 335, 336, 339, 341], "ad": [21, 39, 63, 263, 265, 268, 286, 287, 329, 334, 339], "classifi": [21, 46], "squad": [21, 37, 43, 44, 46, 327, 334, 343, 345], "distilbert": [21, 329, 335, 345], "xlnet": 21, "xlm": [21, 345], "101": [21, 46, 279, 327, 342, 345], "2043": 21, "2001": 21, "onnxrtbertdataset": 21, "data_dir": 21, "model_name_or_path": [21, 226, 236, 284, 328, 337], "max_seq_length": [21, 37, 215, 343], "128": [21, 24, 25, 37, 183, 213, 215, 234, 268, 273, 279, 328, 336, 339, 343, 345], "do_lower_cas": [21, 36, 37, 343], "mrpc": [21, 46, 327, 334, 344, 345], "dynamic_length": 21, "onnxrt": [21, 23, 30, 37, 46, 255, 285, 329, 336, 345], "dir": [21, 253, 256, 319, 322], "shortcut": 21, "token": [21, 34, 37, 39, 40, 213, 253, 266, 268, 279, 327, 328, 339, 341, 342, 343, 344], "longer": [21, 37, 213, 275, 343], "than": [21, 37, 108, 187, 213, 238, 257, 264, 268, 279, 284, 310, 322, 331, 332, 333, 334, 336, 339, 341, 343, 344], "truncat": [21, 37, 213, 343], "shorter": [21, 37, 343], "pad": [21, 37, 88, 90, 93, 94, 124, 125, 343], "lowercas": 21, "fine": [21, 269, 312, 334, 335, 336], "choic": [21, 268, 272, 279, 285, 327, 342], "qqp": [21, 327, 345], "qnli": [21, 327, 345], "rte": [21, 327, 345], "st": [21, 327], "cola": [21, 327, 345], "mnli": [21, 327, 345], "wnli": [21, 327], "mobilebert": 21, "roberta": [21, 345], "fix": [21, 181, 268, 313, 334, 336, 339, 344], "uncas": [21, 37, 343, 345], "load_and_cache_exampl": 21, "cach": [21, 268, 279, 284, 319, 336, 339], "helper": [21, 22, 23, 36, 55, 156, 181, 186, 212, 248, 249, 250, 255], "convert_examples_to_featur": [21, 37], "max_length": 21, "label_list": [21, 46], "output_mod": 21, "classif": [21, 37, 46, 318, 327, 334, 335], "pad_token": 21, "pad_token_segment_id": 21, "mask_padding_with_zero": 21, "inputfeatur": [21, 37], "properti": [21, 77, 325], "input_id": [21, 37, 328], "vocabulari": [21, 36, 37, 343], "attention_mask": [21, 328], "mask": [21, 42, 334, 345], "avoid": [21, 191, 208, 228, 242, 274, 282, 312], "usual": [21, 272, 279, 286, 333, 334, 336, 337, 342], "NOT": [21, 320], "token_type_id": [21, 328], "segment": [21, 40, 42, 281], "portion": 21, "them": [21, 191, 268, 269, 279, 282, 287, 313, 318, 320, 322, 324, 333, 334, 339, 344], "problem": [21, 46, 192, 265, 327, 329], "regress": [21, 281], "seq_length": 21, "tensorflowbertdataset": 21, "root": [21, 22, 23, 26, 46, 316, 327, 328], "label_fil": [21, 37, 343], "tfrecord": [21, 22, 23], "guid": [21, 265, 272, 282, 284, 312, 324], "parsedecodebert": 21, "tensorflowmodelzoobertdataset": [21, 22], "num_cor": [21, 22, 26], "28": [21, 22, 26, 345], "three": [21, 60, 62, 127, 265, 269, 273, 279, 282, 285, 286, 311, 324, 329, 333, 336, 338, 341, 342], "tf": [21, 22, 23, 37, 53, 55, 82, 99, 101, 157, 181, 183, 185, 186, 187, 270, 272, 284, 312, 316, 324, 330, 335, 338, 343], "record": [21, 22, 23, 29, 228, 257, 273, 339, 341, 344], "resiz": [21, 22, 33, 37, 343], "coco": [22, 29, 42, 46, 327, 334], "parsedecodecoco": 22, "cocorecorddataset": 22, "interleav": 22, "parallel": [22, 328, 344], "cocoraw": 22, "img_dir": 22, "val2017": 22, "anno_dir": 22, "annot": [22, 42, 286, 287, 327, 334, 344], "instances_val2017": 22, "arrang": [22, 23, 26, 334], "wai": [22, 23, 26, 55, 186, 268, 271, 279, 287, 313, 327, 328, 333, 334, 336, 339, 342, 344], "jpg": [22, 26, 28, 284], "imag": [22, 23, 26, 28, 33, 37, 42, 265, 279, 316, 318, 334, 342, 343, 345], "coconpi": 22, "npy_dir": 22, "npy": 22, "tensorflowdataset": 23, "pytorchdataset": 23, "mxnetdataset": 23, "onnxrtqldataset": 23, "onnxrtitdataset": 23, "IT": [23, 30, 335], "pytorchmxnetwrapdataset": 23, "datafunc": 23, "pytorchmxnetwrapfunct": [23, 37], "framework_dataset": 23, "convent": [23, 42, 264, 281, 331], "imageclassifi": 23, "choos": [23, 228, 253, 269, 279, 323, 335, 340, 342, 344], "tensorflow_itex": [23, 26, 28, 30, 313], "onnxrt_qdq": [23, 30], "onnxrt_qlinearop": [23, 30, 37], "onnxrt_integerop": [23, 30, 37], "pytorch_ipex": [23, 30, 328], "pytorch_fx": [23, 30, 328], "dataset_registri": 23, "dataset_typ": 23, "dataset_format": 23, "data_format": [23, 33, 88, 90, 93, 94], "eg": [23, 228], "raw_imag": 23, "overwrit": 23, "__getitem__": [23, 37, 313, 328], "__len__": 23, "iterabledataset": 23, "also": [23, 37, 39, 46, 57, 59, 192, 260, 265, 268, 269, 270, 271, 279, 281, 285, 286, 287, 313, 317, 321, 323, 327, 328, 332, 334, 335, 336, 338, 339, 342, 344], "__iter__": [23, 313, 328], "over": [23, 46, 191, 286, 317, 323, 327, 334, 342, 344], "download_url": 23, "url": [23, 215, 281, 284, 324, 325, 334], "filenam": [23, 257], "md5": 23, "download": [23, 193, 242, 284, 324, 340], "address": [23, 265, 268, 273, 280, 312, 329, 335], "gen_bar_updat": 23, "progress": [23, 334, 336], "bar": [23, 335], "check_integr": 23, "fpath": 23, "check": [23, 120, 121, 181, 187, 201, 208, 212, 222, 237, 240, 248, 256, 257, 272, 274, 284, 316, 324, 340], "checksum": 23, "calculate_md5": 23, "chunk_siz": 23, "1024": [23, 179], "cifar10": 23, "cifar100": 23, "databas": 23, "extract": [23, 77, 120, 121, 123], "otherwis": [23, 37, 191, 201, 208, 222, 257, 268, 280, 286, 339, 343], "www": [23, 345], "toronto": 23, "edu": 23, "kriz": 23, "cifar": [23, 345], "tar": 23, "gz": 23, "manual": [23, 334], "subset": [23, 26], "internet": 23, "put": [23, 191], "again": [23, 338], "pytorchcifar10": 23, "mxnetcifar10": 23, "tensorflowcifar10": 23, "pytorchcifar100": 23, "mxnetcifar100": 23, "tensorflowcifar100": 23, "mnist": [23, 316], "modifi": [23, 77, 260, 282, 287, 316, 320, 334], "nation": [23, 280], "institut": 23, "standard": [23, 37, 281, 286, 312, 318, 327, 343, 344], "technologi": [23, 264, 326, 328, 331], "fashionmnist": 23, "npz": 23, "idx1": 23, "ubyt": 23, "idx3": 23, "t10k": 23, "pytorchmnist": 23, "mxnetmnist": 23, "tensorflowmnist": 23, "pytorchfashionmnist": 23, "mxnetfashionmnist": 23, "tensorflowfashionmnist": 23, "imagefold": [23, 316, 328], "expect": [23, 268, 270, 279, 280, 281, 319, 326, 336, 339, 344], "folder": [23, 28, 47, 59, 181, 256, 268, 269, 339], "subfold": 23, "belong": [23, 51, 336], "class_1": 23, "png": 23, "xxy": 23, "xxz": 23, "class_n": 23, "123": [23, 343], "nsdf3": 23, "asd932_": 23, "categori": [23, 41, 310], "mxnetimagefold": 23, "tensorflowtfrecorddataset": 23, "tensorflowimagerecord": 23, "imagenet": [23, 26, 33, 270, 328, 334, 343, 345], "000": [23, 284], "001": [23, 279, 316, 342], "099": 23, "tensorflowvocrecord": 23, "pascal": 23, "voc": [23, 46], "2012": 23, "val": [23, 26, 221, 328], "00000": 23, "00004": 23, "00001": 23, "00003": 23, "dummi": [24, 25, 46, 112, 183, 272, 327, 328], "dummydataset": [24, 25, 183, 272], "shape": [24, 25, 33, 37, 42, 181, 183, 215, 221, 230, 268, 272, 279, 320, 328, 339, 342, 343], "high": [24, 25, 183, 260, 272, 324, 335, 344], "127": [24, 25, 183, 279, 336, 342], "float32": [24, 25, 37, 42, 183, 224, 253, 260, 268, 279, 285, 310, 328, 336, 339, 342, 343], "rang": [24, 25, 37, 183, 228, 243, 253, 263, 264, 265, 268, 269, 272, 274, 279, 284, 285, 287, 311, 315, 316, 328, 331, 333, 334, 336, 339, 342, 343], "stand_norm": [24, 25, 183], "real": [24, 183, 279, 286, 311, 316, 335, 336], "dummy_v2": [25, 183], "sparse_dummy_v2": 25, "input_shap": [25, 183], "label_shap": [25, 183], "sparsedummydataset": 25, "dense_shap": 25, "sparse_ratio": 25, "imagenetraw": 26, "data_path": 26, "image_list": 26, "img1": 26, "img2": 26, "imgx": 26, "read": [26, 37, 181, 191, 338, 341], "val_map": 26, "txt": [26, 319, 324], "pytorchimagenetraw": 26, "mxnetimagenetraw": 26, "tensorflowimagenetraw": 26, "inteltensorflow": [26, 28], "tensorflowimagenetdataset": 26, "onnxrtimagenetdataset": 26, "class": [27, 47, 59, 81, 83, 87, 101, 192, 195, 242, 268, 269, 270, 272, 273, 282, 286, 312, 313, 327, 328, 332, 333, 336, 340, 344], "bert_dataset": 27, "coco_dataset": 27, "dummy_dataset": 27, "dummy_dataset_v2": 27, "imagenet_dataset": 27, "style_transfer_dataset": 27, "style": [28, 312, 322], "transfer": [28, 279, 315, 328, 342], "styletransferdataset": 28, "content_fold": 28, "style_fold": 28, "crop_ratio": 28, "resize_shap": 28, "256": [28, 33, 234, 316, 328, 343], "image_format": 28, "holder": 28, "labelbalancecocorecordfilt": 29, "balanc": [29, 208, 264, 266, 268, 272, 279, 331, 339, 342], "labelbalancecocorawfilt": 29, "tensorflowfilt": 30, "onnxrtqlfilt": 30, "onnxrtitfilt": 30, "pytorchfilt": 30, "mxnetfilt": 30, "filter_registri": 30, "filter_typ": 30, "__call__": 30, "write": [30, 181, 257, 316, 322, 328], "coco_filt": 31, "quantizedinput": [33, 343], "uint8": [33, 42, 77, 204, 228, 234, 272, 279, 285, 320, 336, 343], "point": [33, 43, 44, 63, 220, 228, 257, 260, 263, 264, 265, 266, 267, 268, 271, 279, 327, 331, 336, 339, 342, 343, 344], "labelshift": [33, 343], "label_shift": [33, 343], "parsedecodeimagenet": [33, 343], "proto": [33, 37, 343], "parsedecodeimagenettransform": 33, "decod": [33, 39, 191, 327, 343], "v1": [33, 43, 44, 46, 55, 181, 186, 266, 277, 316, 318, 319, 327, 330, 334, 340, 341, 342, 345], "tensorflowtransposelastchannel": 33, "transpos": [33, 37, 126, 249, 339, 343], "nhwc": [33, 107], "nchw": [33, 107], "tensorflowshiftrescal": 33, "rescal": [33, 37, 343], "tensorflowresizecropimagenettransform": 33, "height": [33, 37, 316, 343], "width": [33, 37, 279, 311, 316, 334, 336, 343], "random_crop": [33, 343], "resize_sid": [33, 343], "resize_method": 33, "bilinear": [33, 37, 343], "random_flip_left_right": [33, 343], "mean_valu": [33, 343], "channels_last": 33, "subpixel": 33, "rgb": 33, "seri": [33, 284, 324, 328, 343], "applic": [33, 268, 270, 279, 287, 318, 335, 339, 342, 343], "result": [33, 37, 39, 42, 43, 44, 46, 59, 66, 181, 201, 203, 212, 243, 256, 257, 260, 262, 263, 266, 268, 271, 273, 274, 279, 280, 284, 313, 316, 323, 325, 327, 328, 332, 334, 335, 336, 339, 341, 342, 343, 344, 345], "crop": [33, 37, 343], "flip": [33, 37, 343], "left": [33, 37, 279, 342, 343], "right": [33, 42, 191, 279, 280, 281, 282, 342, 343], "std": [33, 37, 328, 343], "bilinearimagenettransform": 33, "central_fract": [33, 343], "875": [33, 343], "fraction": [33, 343], "onnxbilinearimagenettransform": 33, "onnxresizecropimagenettransform": 33, "std_valu": 33, "229": [33, 328], "225": [33, 328, 345], "resizewithaspectratio": 33, "87": [33, 326, 345], "inter_pol": 33, "cv2": 33, "inter_area": 33, "aspect": [33, 37, 343], "imagenet_transform": 34, "postprocess_cl": [35, 328], "user_postprocess": 35, "just": [35, 37, 57, 149, 183, 208, 267, 272, 279, 319, 328, 333, 336, 342, 343, 344], "convert_to_unicod": 36, "text": [36, 37, 39, 44, 264, 266, 268, 279, 318, 325, 331, 334, 335, 339, 342, 343, 345], "unicod": 36, "assum": [36, 42, 285, 320], "utf": [36, 191], "load_vocab": 36, "vocab_fil": [36, 37, 343], "convert_by_vocab": 36, "vocab": 36, "whitespace_token": 36, "whitespac": [36, 44], "clean": [36, 193, 328], "split": [36, 37, 135, 213, 279, 282, 337, 339, 342, 343], "piec": [36, 39, 268, 279, 327, 339], "fulltoken": 36, "tokenzi": 36, "basictoken": 36, "punctuat": [36, 39, 44], "lower": [36, 37, 44, 64, 208, 260, 263, 264, 267, 272, 279, 315, 331, 334, 335, 336, 342, 343, 344], "wordpiecetoken": 36, "unk_token": 36, "unk": 36, "max_input_chars_per_word": 36, "200": [36, 213, 234, 268, 282, 344], "wordpiec": [36, 37, 343], "concat_gener": 37, "inc": [37, 97, 101, 224, 226, 236, 269, 272, 273, 280, 286, 326, 335, 340, 344], "abstract": [37, 139, 285, 287, 322], "own": [37, 57, 127, 191, 262, 279, 286, 313, 323, 327, 332, 339, 341], "inherit": [37, 188, 285, 286], "tensorflowtransform": 37, "mxnettransform": 37, "pytorchtransform": 37, "onnxrtqltransform": 37, "onnxrtittransform": 37, "transform_registri": 37, "transform_typ": 37, "basetransform": 37, "tensorflowwrapfunct": 37, "transform_func": 37, "pytorchmxnettransform": 37, "get_torchvision_map": 37, "interpol": [37, 327, 334, 343], "torchvis": [37, 260, 284, 317], "composetransform": 37, "transform_list": [37, 343], "sever": [37, 175, 264, 265, 275, 279, 315, 323, 328, 329, 331, 334, 337, 342, 343, 344], "croptoboundingbox": [37, 343], "offset_height": [37, 343], "offset_width": [37, 343], "target_height": [37, 343], "target_width": [37, 343], "box": [37, 42, 46, 282, 327, 343, 344], "vertic": [37, 343], "coordin": [37, 63, 343, 344], "top": [37, 46, 281, 327, 343], "corner": [37, 281, 285, 287, 343], "horizont": [37, 343], "mxnetcroptoboundingbox": 37, "onnxrtcroptoboundingbox": 37, "tensorflowcroptoboundingbox": 37, "resizewithratio": [37, 343], "min_dim": [37, 343], "800": [37, 343], "max_dim": [37, 343], "1365": [37, 343], "constant_valu": 37, "np": [37, 63, 316, 342, 343, 344], "arrai": [37, 42, 191, 257, 343], "smaller": [37, 123, 264, 328, 331, 334, 343], "dimens": [37, 120, 121, 183, 208, 268, 339, 343], "ensur": [37, 63, 267, 270, 316, 336, 343], "longest": [37, 343], "side": [37, 284, 343], "doesn": [37, 191, 265, 272, 285, 316, 328, 329], "exce": [37, 339, 343], "zero": [37, 88, 89, 90, 94, 208, 217, 220, 221, 228, 257, 264, 267, 268, 279, 331, 334, 336, 339, 342, 343, 344], "tensorflowresizewithratio": 37, "perm": [37, 343], "permut": [37, 343], "tensorflowtranspos": 37, "mxnettranspos": 37, "pytorchtranspos": 37, "randomverticalflip": [37, 343], "randomli": [37, 63, 279, 342, 343, 344], "tensorflowrandomverticalflip": 37, "randomhorizontalflip": [37, 328, 343], "tensorflowrandomhorizontalflip": 37, "toarrai": [37, 343], "pil": [37, 343], "ndarrai": [37, 120, 121, 123, 244, 319, 343], "numpi": [37, 42, 120, 121, 123, 319, 342, 343], "casttftransform": 37, "castonnxtransform": 37, "castpytorchtransform": 37, "centercroptftransform": 37, "center": [37, 283, 284, 324, 343, 344], "paddedcentercroptransform": 37, "crop_pad": 37, "resizetftransform": 37, "nearest": [37, 234, 268, 269, 279, 339, 343], "bicub": [37, 343], "resizepytorchtransform": 37, "randomcroptftransform": 37, "randomresizedcroppytorchtransform": 37, "08": [37, 326, 343, 345], "randomresizedcropmxnettransform": 37, "randomresizedcroptftransform": 37, "normalizetftransform": 37, "normal": [37, 44, 268, 279, 328, 332, 339, 342, 343], "deviat": [37, 343], "broadcast": [37, 316, 343], "rescalekeraspretraintransform": 37, "rescaletftransform": 37, "rescaletransform": 37, "alignimagechanneltransform": 37, "dim": [37, 279, 342, 343], "align": [37, 260, 280, 339, 343], "w": [37, 215, 266, 279, 334, 342, 343], "must": [37, 42, 281, 282, 286, 310, 313, 324, 336, 343], "pytorchalignimagechannel": 37, "tondarraytransform": 37, "resizemxnettransform": 37, "resizetransform": 37, "cropresizetftransform": 37, "boundari": [37, 343], "area": [37, 42, 264, 327, 331, 343], "pytorchcropresizetransform": 37, "mxnetcropresizetransform": 37, "cropresizetransform": 37, "centercroptransform": 37, "mxnetnormalizetransform": 37, "pytorchnormalizetransform": 37, "normalizetransform": 37, "randomcroptransform": 37, "randomresizedcroptransform": 37, "get_final_text": 37, "pred_text": 37, "orig_text": 37, "project": [37, 261, 280, 281, 335, 341, 344, 346], "predict": [37, 39, 43, 44, 46, 59, 181, 268, 279, 327, 339, 342, 343], "squadexampl": 37, "qas_id": 37, "question_text": 37, "doc_token": 37, "orig_answer_text": 37, "start_posit": 37, "end_posit": 37, "is_imposs": 37, "without": [37, 77, 181, 240, 260, 264, 279, 280, 316, 328, 331, 334, 335, 336, 344], "answer": [37, 43, 44, 280, 334, 343, 345], "posit": [37, 237, 280, 327], "unique_id": 37, "example_index": 37, "doc_span_index": 37, "token_to_orig_map": 37, "token_is_max_context": 37, "input_mask": [37, 328], "segment_id": [37, 328], "read_squad_exampl": 37, "input_fil": 37, "doc_strid": [37, 343], "max_query_length": [37, 343], "output_fn": 37, "inputbatch": 37, "collecttransform": 37, "10833": 37, "tfsquadv1posttransform": 37, "n_best_siz": [37, 343], "20": [37, 220, 334, 343, 345], "384": [37, 343], "64": [37, 234, 265, 273, 279, 326, 339, 342, 343, 345], "max_answer_length": [37, 343], "30": [37, 317, 323, 343, 345], "total": [37, 46, 213, 268, 334, 339, 343, 345], "best": [37, 68, 228, 268, 269, 270, 271, 273, 280, 312, 324, 332, 336, 339, 342, 343, 344], "nbest_predict": [37, 343], "question": [37, 43, 44, 279, 280, 281, 284, 285, 324, 334, 342, 343, 345], "becaus": [37, 191, 271, 279, 282, 336, 342, 343, 344], "anoth": [37, 39, 257, 343, 344], "up": [37, 151, 212, 260, 279, 284, 316, 317, 319, 320, 323, 334, 335, 336, 341, 343, 344], "long": [37, 268, 312, 319, 339, 343], "document": [37, 262, 265, 270, 271, 279, 286, 287, 291, 316, 326, 329, 334, 340, 343], "chunk": [37, 343], "stride": [37, 88, 90, 93, 94, 343], "tfmodelzoocollecttransform": 37, "zoo": [37, 284, 317, 345], "tfsquadv1modelzooposttransform": 37, "squadv1": [37, 343], "see": [37, 39, 192, 260, 268, 279, 280, 281, 282, 283, 312, 325, 328, 339, 342, 344], "parsedecodevoctransform": 37, "open": [38, 191, 246, 259, 280, 284, 318, 319, 328, 335], "librari": [38, 259, 265, 272, 284, 324, 328, 329, 335, 336], "popular": [38, 259, 262, 269, 273, 279, 284, 285, 286, 311, 317, 318, 326, 328, 334, 336, 339, 344], "compress": [38, 57, 215, 234, 243, 253, 259, 260, 262, 266, 268, 269, 271, 273, 279, 284, 291, 321, 323, 328, 332, 333, 334, 335, 336, 342, 345], "techniqu": [38, 259, 262, 267, 272, 273, 279, 284, 321, 323, 328, 333, 334, 335, 336, 345], "contrib": 38, "unicoderegex": 39, "hoc": 39, "hack": 39, "recogn": [39, 242, 344], "symbol": [39, 47, 59, 282, 330], "nondigit_punct_r": 39, "compil": [39, 263, 267, 328], "regular": 39, "express": [39, 280], "preced": [39, 279, 342, 344], "digit": [39, 257, 335], "punct_nondigit_r": 39, "symbol_r": 39, "bleu_token": 39, "offici": [39, 43, 44, 181, 280, 342], "mose": 39, "smt": 39, "mosesdecod": 39, "blob": [39, 40, 43, 44, 46, 59, 328], "master": [39, 40, 43, 44, 46, 59, 328, 344], "mteval": 39, "v14": 39, "pl": 39, "l954": 39, "l983": 39, "comput": [39, 40, 43, 44, 46, 208, 212, 220, 243, 257, 260, 264, 265, 267, 268, 279, 311, 313, 315, 318, 327, 328, 329, 331, 334, 335, 336, 339, 342, 344], "bilingu": 39, "understudi": 39, "qualiti": [39, 312], "ha": [39, 120, 121, 123, 127, 187, 191, 199, 215, 238, 265, 270, 272, 279, 281, 285, 286, 287, 313, 318, 323, 328, 329, 334, 336, 338, 341, 342, 344], "been": [39, 187, 191, 199, 207, 208, 212, 265, 268, 272, 279, 287, 312, 328, 329, 339, 342], "translat": [39, 40, 264, 331, 334, 344], "natur": [39, 268, 318], "approxim": [39, 40, 268, 286, 327, 339], "glue": [39, 46, 327, 328], "word": [39, 268, 279, 312, 327, 334, 339, 345], "ngram": [39, 327], "breviti": [39, 40, 327], "penalti": [39, 40, 327], "doe": [39, 77, 97, 101, 267, 268, 272, 312, 313, 327, 328, 339, 340, 343], "have": [39, 42, 46, 59, 77, 82, 127, 136, 181, 191, 207, 208, 212, 264, 265, 266, 268, 273, 279, 280, 281, 286, 287, 312, 313, 316, 320, 325, 327, 328, 329, 331, 332, 334, 336, 337, 339, 342, 344], "beam": [39, 327], "bleu": [40, 45, 327, 334], "tensor2tensor": 40, "bleu_hook": 40, "compute_bleu": 40, "reference_corpu": 40, "translation_corpu": 40, "max_ord": 40, "use_bp": 40, "against": [40, 201], "gram": 40, "appli": [40, 97, 101, 162, 163, 164, 167, 169, 173, 181, 188, 201, 208, 224, 232, 237, 242, 262, 264, 267, 271, 272, 273, 279, 280, 286, 287, 328, 331, 333, 334, 336, 338, 341, 342, 344], "bleu_scor": 40, "third": [42, 281, 325], "parti": [42, 279, 281, 325, 336], "pycocotool": [42, 319], "noth": [42, 344], "relat": [42, 77, 202, 205, 209, 219, 241, 246, 287, 321, 334, 339], "thu": [42, 279, 328, 334, 336], "cannot": [42, 268, 282, 312, 319, 339], "slim": [42, 53, 55, 186, 187, 330, 334], "jonathanhuang": 42, "wrap": [42, 101, 185, 282, 316], "image_id": [42, 327], "encod": [42, 191, 343], "invok": [42, 286], "groundtruth_dict": 42, "exportgroundtruthtococo": 42, "groundtruth_boxes_list": 42, "groundtruth_classes_list": 42, "max_num_class": 42, "output_path": 42, "detections_list": 42, "exportdetectionstococo": 42, "detection_boxes_list": 42, "detection_scores_list": 42, "detection_classes_list": 42, "cocowrapp": 42, "loadannot": 42, "cocoevalwrapp": 42, "agnostic_mod": 42, "computemetr": 42, "detection_typ": 42, "bbox": [42, 282, 327], "hold": [42, 63], "being": [42, 287], "iou_typ": 42, "iou_thr": [42, 46, 327], "map_point": [42, 46, 327], "cocoev": 42, "To": [42, 57, 188, 264, 265, 266, 267, 268, 271, 273, 274, 279, 281, 284, 286, 287, 312, 316, 329, 331, 334, 338, 339, 340, 342, 344], "mscoco": 42, "org": [42, 215, 234, 282, 284, 324, 334], "Then": [42, 279, 286, 342, 344], "exportsingleimagegroundtruthtococo": 42, "next_annotation_id": 42, "category_id_set": 42, "groundtruth_box": 42, "groundtruth_class": 42, "groundtruth_mask": 42, "groundtruth_is_crowd": 42, "ingest": 42, "here": [42, 260, 266, 267, 268, 271, 272, 275, 279, 286, 316, 317, 318, 320, 326, 327, 336, 340, 341, 342, 345], "match": [42, 43, 131, 191, 201, 267, 272, 274, 284, 339], "ones": [42, 191, 334], "exportsingleimagedetectionstococo": 42, "associ": [42, 191, 201], "uniqu": [42, 279, 336], "identifi": [42, 55, 120, 121, 123, 186, 191, 273, 334, 339], "assign": [42, 257, 316, 344], "continu": [42, 268, 326, 328, 334], "drop": [42, 213, 265, 266, 268, 279, 281, 328, 329, 334, 339, 342, 345], "num_gt_box": 42, "num_detect": [42, 46, 327, 328], "image_height": 42, "image_width": 42, "detection_mask": 42, "crowd": 42, "rais": [42, 47, 120, 121, 123, 191, 192, 208, 228, 230, 242, 284, 312, 334, 335], "valueerror": [42, 120, 121, 123, 228, 319], "insid": [42, 268, 315, 319, 334, 337, 344], "exportsingleimagedetectionboxestococo": 42, "detection_box": [42, 328], "detection_scor": [42, 328], "detection_class": [42, 328], "exporsingleimagedetectionboxestococo": 42, "exportsingleimagedetectionmaskstococo": 42, "allenai": [43, 44], "bi": [43, 44], "att": [43, 44], "flow": [43, 44, 279, 282, 328], "f1_score": [43, 44], "ground_truth": [43, 44], "f1": [43, 45, 46, 316, 327, 328, 341, 345], "ground": [43, 44], "truth": [43, 44], "metric_max_over_ground_truth": [43, 44], "metric_fn": [43, 44], "exact_match_scor": 43, "exact": [43, 213], "averag": [43, 44, 46, 268, 327, 328, 339, 344, 345], "articl": [43, 44], "paragraph": [43, 44], "qa": [43, 44, 284], "normalize_answ": 44, "remov": [44, 79, 104, 110, 113, 127, 133, 136, 137, 138, 148, 150, 242, 280, 328, 334], "extra": [44, 191, 268, 328, 339], "replac": [44, 193, 201, 208, 222, 228, 263, 264, 267, 312, 316, 328, 331, 340], "newlin": [44, 257], "tab": 44, "abc": [44, 285, 344], "harmon": [44, 46], "recal": [44, 46], "equat": [44, 46, 279, 336, 342], "answer_start": 44, "177": [44, 345], "denver": 44, "bronco": 44, "nfl": 44, "afc": 44, "super": 44, "bowl": 44, "50": [44, 279, 286, 334, 342, 345], "56be4db0acb8001400a502ec": 44, "form": 44, "percentag": [44, 268, 311, 339], "bleu_util": 45, "coco_label_map": 45, "coco_tool": 45, "evaluate_squad": 45, "user_metr": [46, 59], "metric_cl": [46, 59, 328], "recommend": [46, 240, 260, 265, 275, 284, 285, 320, 321, 334, 344], "design": [46, 64, 262, 267, 269, 272, 284, 328, 334, 336], "sub_class": [46, 59], "basemetr": [46, 59], "tensorflowmetr": 46, "maintain": [46, 267, 268, 272, 279, 280, 281, 312, 330, 334, 339, 340], "pytorchmetr": 46, "mxnetmetr": 46, "onnxrtqlmetr": 46, "onnxrtitmetr": 46, "metric_registri": 46, "metric_typ": 46, "cross": [46, 274, 322, 344], "decorator_metr": 46, "single_output": 46, "hvd": [46, 316], "wrappytorchmetr": 46, "wrapmxnetmetr": 46, "wraponnxrtmetr": 46, "binari": [46, 181, 319, 327, 340], "proport": 46, "were": [46, 191, 334], "pred_list": 46, "pytorchloss": 46, "print": [46, 130, 215, 220, 257, 274, 279, 316, 327, 328, 334, 342, 344], "mae": [46, 327], "compare_label": [46, 59, 327], "error": [46, 68, 191, 208, 254, 260, 268, 279, 319, 327, 339, 342, 344], "actual": [46, 267, 316, 319], "compar": [46, 257, 264, 267, 268, 273, 279, 315, 327, 331, 334, 336, 339, 341, 344], "pred": [46, 181, 327], "rmse": [46, 327, 344], "squar": [46, 68, 260, 268, 327, 344], "estim": [46, 55, 186, 344], "tensorflowtopk": 46, "k": [46, 59, 327, 334], "among": [46, 264, 279, 331, 342], "outcom": 46, "consid": [46, 181, 280, 311, 312, 344], "find": [46, 63, 120, 121, 123, 181, 257, 273, 285, 326, 334, 339, 341, 342, 344], "num_correct": 46, "num_sampl": 46, "generaltopk": 46, "cocomapv2": [46, 327], "anno_path": [46, 327], "map_kei": 46, "detectionboxes_precis": 46, "output_index_map": [46, 327], "tensorflowmap": 46, "tensorflowcocomap": 46, "tensorflowvocmap": 46, "squadf1": [46, 327], "miou": 46, "num_class": 46, "21": [46, 279, 326, 335, 342, 345], "iou": 46, "intersect": [46, 201, 285, 327], "onnxrtglu": 46, "roc": 46, "dlrm": 46, "register_customer_metr": 46, "mani": [46, 59, 228, 268, 272, 279, 312, 313, 324, 339, 344], "tell": [46, 59, 191], "what": [46, 59, 212, 243, 272, 280, 335], "topk": [46, 59, 316, 327, 328, 336], "matrix": [46, 59, 271, 279], "updat": [46, 59, 127, 193, 208, 212, 262, 268, 319, 326, 327, 328, 334, 339, 342, 344], "across": [47, 188, 264, 273, 314, 321, 328, 331, 334, 337, 342, 344], "frozen": [47, 55, 59, 186, 330], "graph_def": [47, 55, 59, 79, 82, 107, 181, 186, 249], "ckpt": [47, 55, 59, 181, 186, 345], "savedmodel": [47, 55, 59, 186], "onnx_ml_pb2": [47, 330], "modelproto": [47, 248, 330], "gluon": [47, 59, 330], "hybirdblock": [47, 59], "mixed_precis": [47, 189, 328], "obj": [47, 57, 59, 243, 246, 257], "measur": [47, 181, 234, 252, 260, 268, 272, 279, 285, 310, 321, 327, 328, 339, 344], "variou": [47, 188, 264, 267, 269, 272, 287, 323, 331, 334, 337], "dl": [47, 265, 322, 335, 345], "assertionerror": [47, 230, 242], "basemodel": [48, 97, 98, 101, 186, 272], "plai": [48, 186, 268, 279, 335, 339, 342], "graph": [48, 55, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 166, 168, 172, 175, 176, 178, 179, 180, 181, 186, 201, 236, 263, 267, 279, 282, 285, 316, 322, 330, 336, 337, 338], "role": [48, 186, 268, 279, 339, 342], "base_model": 49, "keras_model": 49, "mxnet_model": 49, "nets_factori": 49, "onnx_model": 49, "tensorflow_model": 49, "torch_model": 49, "kerasmodel": [50, 186], "get_model_fwk_nam": 51, "fwk": 51, "mxnetmodel": 52, "net": [53, 187, 284], "factori": [53, 187], "tfslimnetsfactori": [53, 187], "onnxmodel": 54, "get_model_typ": [55, 186], "validate_graph_nod": [55, 186], "node_nam": [55, 120, 121, 123, 186, 286], "compat": [55, 181, 186, 281, 316, 330, 334, 340], "graphdef": [55, 127, 181, 186, 330], "validate_and_inference_input_output": [55, 186], "input_tensor_nam": [55, 181, 186], "output_tensor_nam": [55, 181, 186], "infer": [55, 57, 59, 79, 97, 101, 186, 212, 228, 243, 265, 266, 267, 268, 271, 272, 279, 285, 286, 311, 315, 321, 328, 329, 332, 334, 335, 336, 339, 342, 344], "graph_sess": [55, 186], "session": [55, 181, 186, 328], "sess": [55, 181, 186], "graph_def_sess": [55, 186], "frozen_pb_sess": [55, 186], "load_saved_model": [55, 186], "saved_model_tag": [55, 186], "signatur": [55, 186], "tag": [55, 186, 191, 279, 342], "metagraphdef": [55, 186], "analyz": [55, 156, 186, 341, 342], "input_tensor": [55, 181, 186], "output_tensor": [55, 181, 186], "try_loading_kera": [55, 186], "try": [55, 186, 272, 279, 282, 284, 319, 334, 336, 342, 344], "keras_sess": [55, 186], "slim_sess": [55, 186], "checkpoint_sess": [55, 186], "estimator_sess": [55, 186], "input_fn": [55, 186], "saved_model_sess": [55, 186], "tensorflowbasemodel": [55, 186], "tensorflowsavedmodelmodel": [55, 186], "tensorflowllmmodel": [55, 186], "exceed": [55, 186], "protobuf": [55, 186], "2gb": [55, 186], "tensorflowqatmodel": 55, "tensorflowcheckpointmodel": [55, 186], "checkpoint": [55, 186, 191, 226, 236, 256, 330], "tensorflowmodel": [55, 186], "pytorchbasemodel": 56, "pytorchmodel": 56, "pytorchfxmodel": 56, "ipexmodel": 56, "driven": [57, 284, 321, 328, 332], "objective_registri": 57, "objective_custom_registri": 57, "obj_cl": 57, "eural_compressor": 57, "objective_cl": 57, "user_object": 57, "__class__": 57, "__name__": 57, "objective_cfg": 57, "deep_get": [57, 187, 257], "usr_cfg": 57, "deep_set": [57, 257], "user_obj_cfg": 57, "With": [57, 148, 272, 279, 282, 285, 287, 313, 324, 328, 332, 334, 335, 336, 341, 342, 344, 345], "easili": [57, 273, 279, 285, 332, 342], "special": [57, 191, 269, 282, 313, 327, 328, 332, 334, 339], "peak": [57, 274, 332], "memori": [57, 127, 208, 228, 257, 260, 264, 265, 266, 268, 271, 274, 279, 311, 313, 315, 328, 329, 331, 332, 334, 336, 337, 339, 342, 344, 345], "block": [57, 212, 228, 264, 268, 323, 331, 332, 334, 339, 344], "multiobject": 57, "metric_criterion": 57, "metric_weight": 57, "obj_criterion": 57, "obj_weight": 57, "is_measur": 57, "calib_dataload": [59, 80, 97, 98, 101, 270, 271, 272, 273, 282, 313, 322, 327, 328, 336, 337, 338, 339], "calib_func": [59, 80, 97, 98, 101, 102, 228, 260, 272, 284, 338], "entir": [59, 243, 266, 268, 271, 282, 286, 287, 311, 334], "autotunestrategi": 60, "There": [60, 62, 263, 267, 271, 279, 284, 312, 320, 323, 328, 339, 342, 344], "onc": [60, 62, 181, 191, 272, 286, 287, 313, 334, 335, 344, 345], "polici": [60, 62, 68, 273, 280, 284, 346], "automixedprecisiontunestrategi": 61, "basictunestrategi": 62, "bayesiantunestrategi": 63, "acq_max": 63, "ac": 63, "gp": 63, "y_max": 63, "n_warmup": 63, "10000": [63, 334], "n_iter": 63, "acquisit": 63, "gaussian": [63, 344], "relev": [63, 286, 287, 312, 334], "known": [63, 191, 260, 264, 328, 331, 334, 336, 344], "limit": [63, 192, 257, 264, 268, 269, 272, 284, 326, 331, 336, 339], "acq": 63, "randomst": 63, "scipi": 63, "x_max": 63, "targetspac": 63, "pbound": 63, "9527": [63, 328], "append": [63, 282, 315, 328, 333], "while": [63, 265, 267, 268, 272, 279, 284, 285, 286, 317, 323, 329, 334, 336, 339, 342], "duplic": [63, 150, 154], "bayesianoptim": 63, "verbos": [63, 220, 250], "conservativetunestrategi": 64, "o0": [64, 344], "who": [64, 280], "exhaustivetunestrategi": 65, "hawq_v2tunestrategi": 66, "hawq": [66, 344], "v2": [66, 266, 313, 316, 318, 319, 326, 340, 342, 344, 345], "hessian": [66, 268, 339, 344], "network": [66, 234, 264, 265, 279, 311, 315, 318, 328, 331, 335, 336, 342, 344], "made": [66, 279, 285, 336, 340, 344], "small": [66, 120, 121, 122, 123, 268, 279, 334, 339, 344, 345], "impact": [66, 334, 340, 344], "auto_mixed_precis": 67, "msetunestrategi": 68, "those": [68, 127, 191, 257, 267, 272, 279, 315, 322, 328, 329, 333, 334, 336, 344], "mse_v2tunestrategi": 69, "revert": [69, 77, 344], "fx": [69, 201, 230, 236, 263, 265, 267, 323, 329, 335, 336, 338], "randomtunestrategi": 70, "strategy_registri": [71, 344], "tunestrategi": [71, 344], "tunestrategymeta": 71, "metaclass": 71, "tuning_sampl": 73, "tuning_spac": [73, 74, 76], "tuning_struct": [73, 74, 75], "tuningord": 74, "Not": [74, 75, 187, 257, 260, 312], "tuningsampl": 74, "tuningspac": [74, 75], "tuning_order_lst": 74, "initial_op_tuning_cfg": 74, "modelwisetuningsampl": 74, "tuning_items_prior": 74, "op_dtype_dict": 74, "optuningconfig": [74, 75, 76], "optypewisetuningsampl": 74, "opwisetuningsampl": 74, "fallbacktuningsampl": 74, "op_dtyp": 74, "accumul": [74, 264, 268, 331, 344], "skip_first": 74, "lowerbitssampl": 74, "blockfallbacktuningsampl": 74, "op_block_lst": 74, "target_dtyp": [74, 201], "smoothquantsampl": 74, "alpha_list": 74, "weightonlyquantsampl": 74, "tuningitem": 75, "item_typ": 75, "capabl": [75, 85, 260, 265, 268, 279, 286, 287, 310, 320, 328, 329, 334, 336, 344], "intern": [75, 183, 260, 313, 327, 334], "merg": [75, 154, 183, 274, 344], "tree": 75, "pattern_to_intern": 75, "default_dtyp": 75, "pattern_to_path": 75, "quant_mode_from_pattern": 75, "internal_pattern": 75, "initial_tuning_cfg_with_quant_mod": 75, "op_name_typ": 75, "quant_mod": [75, 85, 88, 89, 90, 93, 94, 286, 287], "cfg": [75, 124, 125, 207, 208, 212, 246, 286, 287], "step1": 75, "step2": 75, "complet": [75, 260, 285, 286, 334, 336, 344, 345], "step3": 75, "step4": 75, "step5": 75, "op_typ": [76, 79, 82, 99, 208, 212, 266, 267], "op_quant_mod": 76, "quanttyp": 77, "quantopt": 77, "quant_typ": 77, "quant_opt": 77, "preprocess_user_cfg": 77, "op_user_cfg": 77, "op_user_cfg_modifi": 77, "group_siz": [77, 221, 224, 228, 234, 268, 273, 339], "32": [77, 208, 213, 224, 228, 234, 264, 265, 272, 273, 316, 322, 331, 339, 345], "ordereddefaultdict": 77, "extract_data_typ": 77, "data_typ": [77, 213], "sign": [77, 234, 268, 279, 281, 284, 287, 311, 335, 336, 339, 341], "unsign": [77, 287, 339], "reverted_data_typ": 77, "signed_flag": 77, "get_adaptor_nam": 77, "build_slave_faker_model": 77, "slave": [77, 344], "virtual": [77, 335], "classregist": 77, "smoother": 78, "static_qu": [78, 189, 270, 312], "smoothquantcalibr": 79, "percentil": [79, 99, 228, 311], "outlier": [79, 266, 268, 271, 279, 286, 311, 339, 342], "smoothquantcalibrationllm": 79, "model_path": [79, 181, 215, 234, 268], "temp_path": 79, "weight_name_map": 79, "llm": [79, 82, 215, 234, 260, 264, 266, 267, 268, 271, 279, 321, 331, 334, 335, 337, 339, 342], "temporari": [79, 208, 257, 280], "median": 79, "autotrack": [79, 181], "compon": [80, 273, 282, 312, 316, 324, 325, 333, 334], "sq": [80, 207, 272, 326, 342], "smoothquantconfig": [80, 97, 99, 232, 234, 266, 271, 272], "calib_iter": [80, 84, 97, 98, 101, 272, 286], "scaler": 81, "smoothquantscal": 82, "scales_per_op": [82, 99], "factor": [82, 208, 220, 263, 266, 268, 272, 279, 339, 342, 345], "individu": [82, 279, 280, 334, 342], "share": [82, 135, 150, 155, 228, 268, 279, 319, 320, 339, 342, 344], "smoothquantscalerllm": 82, "kerasadaptor": 84, "framework_specific_info": [84, 85, 285], "kerasqueri": 84, "local_config_fil": [84, 85], "kerasconfigconvert": 84, "quant_config": [84, 85, 97, 101, 187, 188, 198, 200, 207, 211, 213, 214, 215, 222, 225, 227, 237, 242, 263, 264, 266, 267, 268, 269, 270, 271, 272, 275, 321, 331], "staticquantconfig": [84, 85, 95, 99, 187, 232, 234, 267, 270, 271, 272, 273], "kerassurgeri": 84, "fakequ": [84, 141], "tensorflowadaptor": 85, "stock": [85, 342], "spr": 85, "tensorflow_itexadaptor": 85, "tensorflowconfig": 85, "tensorflowqueri": [85, 285], "performance_onli": [85, 102, 153, 167, 172, 180, 328], "itex_mod": [85, 102, 142, 153, 167, 172], "tensorflowconfigconvert": 85, "qconv2d": 88, "kernel_s": [88, 90, 94], "dilation_r": [88, 90, 94], "group": [88, 221, 228, 268, 279, 284, 323, 334, 339, 343, 344, 345], "use_bia": [88, 89, 90, 94], "kernel_initi": [88, 89], "glorot_uniform": [88, 89, 90, 94], "bias_initi": [88, 89, 90, 94], "kernel_regular": [88, 89], "bias_regular": [88, 89, 90, 94], "activity_regular": [88, 89, 90, 94], "kernel_constraint": [88, 89], "bias_constraint": [88, 89, 90, 94], "act_min_valu": [88, 89, 90, 93, 94], "act_max_valu": [88, 89, 90, 93, 94], "weight_min_valu": [88, 89, 90, 93, 94], "weight_max_valu": [88, 89, 90, 93, 94], "granular": [88, 89, 90, 93, 94, 204, 264, 279, 285, 286, 287, 320, 323, 331, 336, 342], "per_tensor": [88, 89, 90, 93, 94, 95, 99, 204, 234, 270, 286, 287, 320, 336], "quant_statu": [88, 89, 90, 93, 94], "calib": [88, 89, 90, 93, 94, 286], "quant_t": [88, 89, 90, 93, 94], "s8": [88, 89, 90, 93, 94, 250], "quant_round_mod": [88, 89, 90, 93, 94], "half_away_from_zero": [88, 89, 90, 93, 94], "quant_narrow_rang": [88, 89, 90, 93, 94], "quant_axi": [88, 89, 90, 93, 94], "initialize_int8_conv2d": 88, "fp32_layer": [88, 89, 90, 93, 94], "q_config": [88, 89, 90, 93, 94, 250, 285], "qdens": 89, "unit": [89, 281, 334], "initialize_int8_dens": 89, "depthwis": [90, 208], "conv2d": [90, 91, 94, 99, 106, 112, 113, 114, 118, 119, 124, 161, 171, 176, 208, 260, 286, 287, 318, 320, 342, 344], "qdepthwiseconv2d": 90, "depth_multipli": [90, 94], "depthwise_initi": [90, 94], "depthwise_regular": [90, 94], "depthwise_constraint": [90, 94], "depthwiseconv2d": 90, "initialize_int8_depthwise_conv2d": 90, "depthwise_conv2d": 91, "layer_initi": 91, "pool2d": 91, "separable_conv2d": 91, "qavgpool2d": 93, "pool_siz": 93, "averagepooling2d": 93, "qmaxpool2d": 93, "maxpooling2d": 93, "initialize_int8_avgpool": 93, "avgpool": [93, 165, 174, 320], "initialize_int8_maxpool": 93, "maxpool": [93, 165, 174, 320], "separ": [94, 213, 280, 312, 322, 324, 325, 333], "qseparableconv2d": 94, "pointwise_initi": 94, "pointwise_regular": 94, "pointwise_constraint": 94, "separableconv2d": 94, "initialize_int8_separable_conv2d": 94, "operatorconfig": [95, 234], "weight_dtyp": [95, 99, 270], "weight_sym": [95, 99, 270, 272, 273], "weight_granular": [95, 99, 270], "act_dtyp": [95, 99, 234, 264, 266, 267, 270, 331], "act_sym": [95, 99, 213, 234, 267, 270, 272, 273], "act_granular": [95, 99, 234, 270], "get_all_registered_config": [95, 234], "get_default_static_quant_config": [95, 99], "entri": [97, 98, 101, 120, 121, 123, 232, 233, 236, 237, 257, 269, 312, 325], "static_quant_entri": [97, 232], "main": [97, 98, 101, 215, 232, 233, 237, 238, 268, 269, 270, 272, 274, 275, 279, 282, 313, 316, 328, 334, 336, 339], "substitut": [97, 101, 272], "smooth_quant_entri": [97, 232, 312], "smooth_quant_config": 97, "get_all_config_set": [98, 233], "weight_algorithm": 99, "minmax": [99, 204, 208, 234, 267, 286, 287, 311, 320, 336], "act_algorithm": 99, "fold": [99, 115, 116, 208, 227, 228, 234, 250, 266, 268, 320, 339, 342], "999": 99, "record_max_info": [99, 208], "weight_clip": [99, 208], "auto_alpha_arg": [99, 234, 342], "default_sq_alpha_arg": 99, "get_default_sq_config": [99, 234], "rtn": [99, 188, 223, 232, 233, 234, 269, 275, 279, 312, 337, 339], "algorithm_entri": [100, 235, 312], "autotun": [100, 235, 270, 271, 272, 279, 292, 312], "need_appli": [101, 237], "configs_map": [101, 194, 232, 237], "quantize_model": [101, 270, 271, 272, 279], "quantize_model_with_single_config": 101, "graphconvert": 102, "qt_config": 102, "int8_sequ": 102, "fp32_op": [102, 103, 153], "bf16_op": [102, 103, 153, 286, 338], "data_load": [102, 285], "fake_qu": [102, 141, 153, 167, 172], "qdq_enabl": 102, "new_api": [102, 124, 125, 130, 132, 144, 167, 172, 176], "use_bf16": 102, "rewrit": [103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 201], "bf16convert": [103, 338], "dequant": [104, 141, 143, 144, 145, 146, 148, 193, 208, 218, 224, 228, 257, 279, 282, 286, 342], "cast": [104, 338, 343], "rerewrit": 104, "dequantizecastoptim": 104, "b16": 104, "bf16_convert": 105, "dequantize_cast_optim": 105, "biasadd": [106, 112, 117, 119, 155, 320], "convertaddtobiasaddoptim": 106, "addv2": [106, 122, 320], "layout": 107, "convertlayoutoptim": 107, "abov": [107, 266, 267, 268, 270, 279, 285, 286, 287, 334, 336, 342, 344], "leakyrelu": [108, 342], "convertleakyreluoptim": 108, "subgraph": [108, 119, 337, 344], "coeffici": [108, 334], "nan": 109, "convertnantorandom": 109, "const": [109, 110, 116, 117, 120, 121, 123, 135, 150], "consist": [109, 116, 268, 281, 282, 312, 342, 344], "placehold": [110, 183, 204, 312], "convertplaceholdertoconst": 110, "dilat": 111, "contract": 111, "dilatedcontract": 111, "spacetobatchnd": 111, "batchtospacend": 111, "inject": [112, 328], "injectdummybiasaddoptim": 112, "fusion": [112, 114, 123, 131, 155, 162, 163, 164, 167, 168, 169, 173, 271, 282, 285, 320], "expanddim": 113, "expanddimsoptim": 113, "next": [113, 183, 268, 279, 284, 286, 287, 313, 339, 344], "reshap": [114, 120, 121, 126, 208, 279, 342], "fetchweightfromreshapeoptim": 114, "pack": [114, 216, 221], "batchnorm": [115, 120, 282, 342], "foldbatchnormnodesoptim": 115, "graphfoldconstantoptim": 116, "supported_op_typ": 116, "fusebiasaddandaddoptim": 117, "columnwis": 118, "fusecolumnwisemuloptim": 118, "depthwiseconv2dn": [118, 124, 161, 171, 320], "math": [119, 279, 336], "fuseconvwithmathoptim": 119, "elimin": 119, "realdiv": [119, 122], "decompos": [120, 121], "fusedecomposedbnoptim": 120, "input_graph_def": [120, 121, 123], "node_name_from_input": [120, 121, 123], "strip": [120, 121, 123, 136, 137, 181], "off": [120, 121, 123, 268, 279, 281, 339], "port": [120, 121, 123], "underli": [120, 121, 123, 191], "node_from_map": [120, 121, 123], "node_map": [120, 121, 123], "pull": [120, 121, 123], "nodedef": [120, 121, 123], "isn": [120, 121, 123], "present": [120, 121, 123, 279, 335, 342], "values_from_const": [120, 121, 123], "node_def": [120, 121, 123], "valid_reshape_input": [120, 121], "reshape_in0_ndef": [120, 121], "reshape_in1_ndef": [120, 121], "bypass_reshap": [120, 121], "input_node_map": [120, 121], "get_const_dim_count": [120, 121], "instancenorm": [121, 342], "fusedecomposedinoptim": 121, "gelu": 122, "fusegeluoptim": 122, "sqrt": 122, "erf": 122, "layernorm": [123, 279, 342], "fuselayernormoptim": 123, "remap": [123, 191], "fusedbatcnormv3": 123, "And": [123, 272, 279, 281, 282, 310, 312, 328, 342], "2d": [123, 279, 342], "3d": [123, 279, 335, 342], "fusepadwithconv2doptim": 124, "itex_qdq_mod": [124, 125], "conv3d": [124, 161], "fusepadwithfp32conv2doptim": 125, "fusetransposereshapeoptim": 126, "cse": [127, 150], "graphcseoptim": 127, "introduc": [127, 262, 268, 279, 285, 286, 287, 320, 328, 336, 339, 340, 342], "ident": [127, 133, 280], "d": [127, 212, 322, 334], "child": [127, 193, 215], "b1": 127, "c1c2": 127, "d1": [127, 257], "c1": 127, "c2": 127, "relu": [127, 131, 155, 282, 320, 342], "relu6": [127, 320], "grappler": [128, 320], "grappleroptim": 128, "input_output_nam": 128, "opt_cfg": 128, "leverag": [128, 253, 260, 263, 267, 270, 273, 279, 318, 333, 336, 339, 344], "convert_add_to_biasadd": 129, "convert_layout": 129, "convert_leakyrelu": 129, "convert_nan_to_random": 129, "convert_placeholder_to_const": 129, "dilated_contract": 129, "dummy_biasadd": 129, "expanddims_optim": 129, "fetch_weight_from_reshap": 129, "fold_batch_norm": 129, "fold_const": 129, "fuse_biasadd_add": 129, "fuse_column_wise_mul": 129, "fuse_conv_with_math": 129, "fuse_decomposed_bn": 129, "fuse_decomposed_in": 129, "fuse_gelu": 129, "fuse_layer_norm": 129, "fuse_pad_with_conv": 129, "fuse_pad_with_fp32_conv": 129, "fuse_reshape_transpos": 129, "graph_cse_optim": 129, "grappler_pass": 129, "insert_print_nod": 129, "move_squeeze_after_relu": 129, "pre_optim": 129, "remove_training_nod": 129, "rename_batch_norm": 129, "split_shared_input": 129, "strip_equivalent_nod": [129, 181], "strip_unused_nod": [129, 181], "switch_optim": 129, "insertprintminmaxnod": 130, "pre_node_nam": 130, "post_node_nam": 130, "move": [131, 191, 208, 228, 268, 279, 282, 339, 340], "squeez": [131, 282], "movesqueezeafterreluoptim": 131, "entranc": 132, "preoptim": 132, "removetrainingnodesoptim": 133, "protected_nod": 133, "types_to_splic": 133, "checknumer": 133, "stopgradi": 133, "renam": [134, 269, 340], "fusedbatchnorm": 134, "fusedbatchnormv2": 134, "renamebatchnormoptim": 134, "splitsharedinputoptim": 135, "equival": [136, 227, 264, 266, 268, 271, 279, 284, 331, 335, 339, 342], "stripequivalentnodesoptim": 136, "output_node_nam": [136, 137, 167, 168, 172, 181], "unus": [137, 181, 242], "stripunusednodesoptim": 137, "input_node_nam": [137, 167, 172, 181], "switch": 138, "switchoptim": 138, "graphrewriterbas": 139, "graph_bas": 140, "freez": [141, 142, 181, 263, 267, 334], "freezefakequantopoptim": 141, "prior": [141, 344], "freezevaluetransform": 142, "max_min_data": 142, "postfix": 142, "tensor_data": [142, 187, 257, 258], "th": 142, "quantizedconv": [143, 144], "quantizeddeconv": 143, "redund": [143, 145, 242], "fuseconvredundantdequantizetransform": 143, "_quantizedconv": 143, "_quantizeddeconv": 143, "successor": [143, 144, 145, 146], "requant": [144, 146], "fuseconvrequantizetransform": 144, "quantizedmatmul": [145, 146], "fusematmulredundantdequantizetransform": 145, "_quantizedmatmul": [145, 146], "fusematmulrequantizedequantizetransform": 146, "quantizedmatmulwithbiasanddequant": 146, "fusematmulrequantizetransform": 146, "fusematmulrequantizedequantizenewapitransform": 146, "fusematmulrequantizenewapitransform": 146, "newapi": 146, "freeze_fake_qu": 147, "freeze_valu": 147, "fuse_conv_redundant_dequant": 147, "fuse_conv_requant": 147, "fuse_matmul_redundant_dequant": 147, "fuse_matmul_requant": 147, "meta_op_optim": 147, "post_hostconst_convert": 147, "post_quantized_op_cs": 147, "scale_propag": 147, "meta": [148, 221, 275, 284, 326, 335, 345], "metainfochangingmemopoptim": 148, "metaop": 148, "hostconst": 149, "posthostconstconvert": 149, "postcseoptim": 150, "quantizev2": 150, "decreas": [150, 334], "propag": 151, "scalepropagationtransform": 151, "direct": [151, 269, 334], "insert_qdq_pattern": 152, "merge_duplicated_qdq": 152, "share_qdq_y_pattern": 152, "generategraphwithqdqpattern": 153, "calibration_data": 153, "op_wise_config": [153, 167, 172, 286], "quantized_nod": 153, "llm_weight_minmax": 153, "q": [153, 155, 167, 263, 267, 269, 279, 339, 342], "dq": [153, 155, 167, 263, 267, 269, 279, 342], "mergeduplicatedqdqoptim": 154, "shareqdqforitexypatternoptim": 155, "break": [155, 316, 328], "graphanalyz": 156, "extend_engin": 156, "graphrewriterhelp": 156, "graph_rewrit": 157, "quantize_graph": 157, "transform_graph": 157, "graph_convert": 157, "graph_util": 157, "quantize_graph_common": 157, "quantize_graph_bas": 158, "quantize_graph_bn": 158, "quantize_graph_concatv2": 158, "quantize_graph_conv": 158, "quantize_graph_for_intel_cpu": 158, "quantize_graph_matmul": 158, "quantize_graph_pool": 158, "fusedbatchnormv3": [159, 169], "fusenodestartwithfusedbatchnormv3": [159, 169], "_quantizedfusedbatchnorm": 159, "concatv2": [160, 170, 180, 320], "fusenodestartwithconcatv2": [160, 170], "quantizedconcatv2": [160, 170], "fusenodestartwithconv2d": [161, 171], "conv2dbackpropinput": 162, "conv3dbackpropinputv2": 162, "fusenodestartwithdeconv2d": 162, "fusedinstancenorm": 163, "fusenodestartwithfusedinstancenorm": 163, "batchmatmul": 164, "batchmatmulv2": 164, "fusenodestartwithmatmul": [164, 173], "fusenodestartwithpool": [165, 174], "fuse_qdq_bn": 166, "fuse_qdq_concatv2": 166, "fuse_qdq_conv": 166, "fuse_qdq_deconv": 166, "fuse_qdq_in": 166, "fuse_qdq_matmul": 166, "fuse_qdq_pool": 166, "optimize_qdq": 166, "optimizeqdqgraph": 167, "input_graph": [167, 172, 176, 285], "op_wise_sequ": [167, 172], "quantizegraph": 168, "quantizegraphbas": 168, "quantizenodebas": 168, "descript": [168, 260, 266, 282, 286, 287, 313, 342], "quantizegraphforintel": 172, "herlper": 175, "quantizegraphhelp": 175, "staticmethod": 175, "biascorrect": 176, "fp32_graph": 176, "weight_empir": 176, "Will": [176, 236, 323], "graphtransform": 177, "graphtransformbas": 177, "input_pb": [177, 179, 180], "bias_correct": 178, "graph_transform_bas": 178, "insert_log": 178, "rerange_quantized_concat": 178, "insertlog": 179, "node_name_list": 179, "show_nam": 179, "show_op": 179, "first_n": 179, "summar": [179, 312], "messag": [179, 274, 281, 344], "dump_fp32": 179, "rerang": 180, "rerangequantizedconcat": 180, "rerange_quant": 180, "concat": 180, "read_graph": 181, "in_graph": 181, "in_graph_is_binari": 181, "write_graph": 181, "out_graph_def": 181, "out_graph_fil": 181, "is_ckpt_format": 181, "is_saved_model_format": 181, "saved_model": [181, 272, 337], "get_tensor_by_nam": 181, "try_cnt": 181, "scope": [181, 269, 281, 286, 328], "mai": [181, 191, 192, 260, 265, 268, 271, 279, 280, 281, 284, 286, 311, 312, 318, 319, 325, 329, 335, 336, 339, 342, 344], "tensor_nam": [181, 191, 193], "suffix": 181, "got": [181, 286, 319], "iterator_sess_run": 181, "iter_op": 181, "feed_dict": 181, "integr": [181, 265, 269, 272, 279, 285, 328, 339], "makeiter": 181, "feed": [181, 334], "collate_tf_pr": 181, "collat": 181, "get_input_output_node_nam": 181, "fix_ref_type_of_graph_def": 181, "ref": 181, "tool": [181, 249, 257, 279, 284, 285, 328, 334, 335, 336], "strip_unused_lib": 181, "r1": 181, "15": [181, 320, 324, 326], "branch": [181, 281], "attr": 181, "get_graph_def": 181, "auto_input_output": 181, "get_model_input_shap": 181, "generate_feed_dict": 181, "apply_inlin": 181, "inlin": 181, "definit": [181, 224], "concret": [181, 186, 344], "new_graph_def": 181, "construct_function_from_graph_def": 181, "frozen_func": 181, "rebuild": 181, "reconstruct": [181, 335], "new_func": 181, "parse_saved_model": 181, "_saved_model": 181, "reconstruct_saved_model": 181, "trackabl": 181, "destin": [181, 248], "basedatalod": 183, "default_col": 183, "batch": [183, 213, 243, 268, 313, 315, 328, 333, 334, 336, 342, 343, 344, 345], "outer": 183, "iterablefetch": 183, "collate_fn": [183, 313], "drop_last": 183, "indexfetch": 183, "iterablesampl": 183, "act": [183, 280], "batchsampl": 183, "basedataload": 183, "last_batch": [183, 313], "rollov": [183, 313], "batch_sampl": [183, 313], "num_work": [183, 313, 328, 336], "pin_memori": [183, 313], "shuffl": [183, 313, 328, 336], "_generate_dataload": 183, "dummydatasetv2": 183, "model_wrapp": 184, "tensorflowglobalconfig": 185, "get_tf_model_typ": 186, "version1_lt_version2": [187, 257], "version1": [187, 257], "version2": [187, 257], "version1_gt_version2": [187, 257], "greater": [187, 257, 272, 334, 344], "version1_eq_version2": [187, 257], "version1_gte_version2": [187, 257], "version1_lte_version2": [187, 257], "register_algo": [187, 242, 312], "algos_map": [187, 242], "example_algo": [187, 242], "dot": [187, 257, 265, 279, 329, 336], "nest": [187, 212, 257], "person": [187, 257, 280, 335], "john": [187, 257], "deep": [187, 257, 262, 264, 265, 269, 272, 279, 284, 285, 286, 313, 323, 324, 328, 329, 331, 335, 336, 344], "itex_instal": 187, "extens": [187, 191, 192, 257, 265, 266, 267, 269, 279, 284, 285, 292, 312, 319, 320, 321, 323, 324, 326, 328, 329, 330, 334, 335, 336, 339, 342, 344], "instal": [187, 272, 316, 319, 321, 346], "combine_histogram": [187, 257], "old_hist": [187, 257], "arr": [187, 257], "histogram": [187, 244, 257], "old": [187, 257, 266, 328, 340], "get_all_fp32_data": [187, 257], "get_tensor_histogram": [187, 257], "bin": [187, 191, 193, 257, 319], "2048": [187, 213, 215, 234, 257, 268, 339], "disable_random": 187, "valid_keras_format": 187, "captureoutputtofil": [187, 257], "tmp_file_path": [187, 257], "stream": [187, 257, 345], "sy": [187, 257, 312], "stderr": [187, 257], "captur": [187, 208, 257, 267, 268], "gptq": [188, 223, 226, 232, 234, 236, 269, 275, 279, 284, 312, 326, 337, 339], "prepar": [188, 207, 210, 226, 232, 237, 242, 260, 263, 264, 266, 267, 268, 269, 272, 275, 279, 282, 284, 316, 321, 334, 336], "layer_wis": [189, 256, 337], "mx_quant": 189, "pt2e_quant": 189, "base_algorithm": 189, "modified_pickl": 190, "f": [191, 268, 279, 312, 316, 336, 339, 342], "file_lik": 191, "map_loc": 191, "pickle_modul": 191, "weights_onli": 191, "pickle_load_arg": 191, "pickl": [191, 192], "unpickl": [191, 192], "facil": 191, "treat": [191, 313], "storag": [191, 268, 279, 327, 339, 342], "thei": [191, 265, 280, 312, 320, 328, 332], "deseri": 191, "fail": [191, 282, 313, 318], "certain": [191, 273, 341], "except": [191, 208, 257, 268, 312, 336, 337], "howev": [191, 268, 275, 279, 334, 339, 342], "serial": [191, 192], "resid": 191, "builtin": [191, 316], "cuda": [191, 208, 220, 238, 329, 334, 336], "device_id": 191, "final": [191, 267, 279, 286, 328, 332, 334, 336, 340, 344], "fall": [191, 264, 331], "behavior": [191, 280, 285, 286, 287, 320, 330, 339, 344], "wasn": 191, "appear": [191, 280], "register_packag": 191, "readlin": 191, "seek": [191, 339], "o": [191, 284, 312, 324], "pathlik": 191, "metadata": 191, "primit": 191, "unless": [191, 320], "insecur": 191, "possibl": [191, 201, 260, 333, 334, 337, 338, 344], "malici": 191, "arbitrari": [191, 269, 328, 333], "never": [191, 344], "come": [191, 264, 326, 331, 344], "untrust": 191, "unsaf": 191, "tamper": 191, "trust": 191, "load_state_dict": 191, "ram": [191, 268, 275], "surg": 191, "byte": [191, 208], "unicodedecodeerror": 191, "ascii": 191, "codec": 191, "0x": 191, "incorrect": 191, "latin1": 191, "byte_arrai": 191, "xdoctest": 191, "skip": [191, 344], "undefin": 191, "filepath": [191, 257, 312], "pt": [191, 256, 268, 284, 321, 324, 330, 335, 336, 338, 339], "onto": 191, "lambda": [191, 337], "loc": 191, "io": [191, 234, 268, 284, 324], "bytesio": 191, "rb": 191, "buffer": 191, "portabl": 192, "represent": [192, 264, 268, 279, 280, 282, 311, 315, 331, 334, 336], "copyreg": 192, "mechan": [192, 262, 334, 341], "pickler": 192, "pickletool": 192, "comment": [192, 268, 274, 280, 286, 327, 328, 339, 343], "misc": [192, 325], "__version__": [192, 312], "format_vers": 192, "compatible_format": 192, "pickleerror": 192, "picklingerror": 192, "unpicklingerror": 192, "secur": [192, 284, 335, 346], "violat": 192, "necessarili": 192, "attributeerror": 192, "eoferror": 192, "importerror": [192, 319], "indexerror": 192, "qdqlayer": [193, 224], "input_scal": [193, 208, 224], "get_modul": [193, 208, 228], "get_children": 193, "children": 193, "get_named_children": 193, "dowload_hf_model": [193, 242], "repo_id": [193, 242], "cache_dir": [193, 242], "repo_typ": [193, 242], "revis": [193, 226, 236, 242], "hug": [193, 242, 284, 335], "face": [193, 242, 280, 284, 291, 335, 340, 345], "hf": [193, 226, 236, 242, 275, 326, 342, 345], "hub": [193, 226, 236, 242, 284, 317], "load_empty_model": [193, 242, 268, 275, 337], "pretrained_model_name_or_path": [193, 242], "automodelforcausallm": [193, 321], "get_super_module_by_nam": 193, "father": 193, "update_modul": 193, "new_modul": [193, 208, 228, 242], "load_layer_wise_quantized_model": 193, "load_tensor_from_shard": 193, "shard": 193, "load_tensor": 193, "load_valu": 193, "param_nam": [193, 257], "state_dict": [193, 268, 316, 339], "load_modul": 193, "register_weight_hook": 193, "clean_weight": 193, "saved_path": 193, "hook": [193, 246, 315, 328, 334, 342], "handler": [193, 257, 344], "clean_module_weight": 193, "half": [194, 196, 201, 234, 265, 268, 329], "halfprecisionconvert": 194, "half_precision_convert": 195, "module_wrapp": 195, "halfprecisionmodulewrapp": 196, "float16": [196, 201, 253, 260, 268, 339], "mx": [197, 199, 234, 264, 269, 284, 321, 331], "mxlinear": 198, "in_featur": [198, 218, 224], "out_featur": [198, 218, 224], "mx_spec": [198, 199], "mxquantiz": 198, "ordereddict": [198, 207, 211, 214, 225, 312], "elemformat": 199, "roundingmod": 199, "quantize_elemwise_op": 199, "quantize_mx_op": 199, "elem_format": 199, "block_siz": [199, 234, 268, 339], "scale_bit": 199, "expand_and_reshap": 199, "pt2e": [200, 202, 204, 230, 232, 236], "w8a8pt2equant": 200, "w8a8": [200, 263, 267, 268, 279, 337, 339], "patternpair": 201, "fn": 201, "torchfunctyp": 201, "search_pattern": 201, "graphmodul": [201, 230, 282, 338], "replace_pattern": 201, "found": [201, 208, 265, 284, 312, 326, 329, 342, 344, 345], "pattern_factori": 201, "fn_arg": 201, "ellipsi": [201, 238], "get_filter_fn": 201, "node_list": 201, "apply_single_pattern_pair": 201, "gm": 201, "pattern_pair": 201, "get_unquantized_node_set": 201, "unquant": 201, "node_candidate_list": 201, "get_half_precision_node_set": 201, "candid": 201, "unquantized_node_set": 201, "node_set_from_user_config": 201, "graphmodel": 201, "half_precision_rewrit": 202, "output_dir": [203, 210, 226, 253, 269, 328], "saved_result": [203, 210, 226, 236, 268, 269, 330, 339], "create_quant_spec_from_config": 204, "sym": [204, 208, 228, 286, 287, 320, 336, 339], "is_dynam": 204, "ao": 204, "quantizationspec": 204, "symmetr": [204, 208, 253, 272, 287, 336, 339, 343, 344], "per_channel": [204, 234, 286, 287, 320, 336], "create_xiq_quantizer_from_pt2e_config": 204, "x86_inductor_quant": 204, "x86inductorquant": [204, 263], "boolean": 204, "recover_model_from_json": [206, 256], "json_file_path": [206, 256], "recov": [206, 208, 228, 256, 257, 285, 315], "smoothquantquant": 207, "qdq_quantiz": 207, "tune_cfg": [207, 208, 212, 242, 285, 287, 344], "run_fn": [207, 208, 233, 237, 266, 267, 268, 269], "inplac": [207, 208, 237, 269], "op_infos_from_cfg": [207, 208, 212], "output_tensor_id_op_nam": [207, 208, 212], "carri": [207, 208, 334], "place": [207, 208, 228, 237, 269, 315, 324, 334, 344], "torchsmoothqu": [207, 208, 342], "get_quantizable_ops_recurs": [208, 212], "act_algo": [208, 234, 267], "output_tensor_ids_op_nam": [208, 212], "quantizable_op": [208, 212], "check_cfg_and_qconfig": [208, 212], "cfg_to_qconfig": [208, 212], "user_cfg": [208, 212], "dump_model_op_stat": [208, 212, 242], "get_par": [208, 228], "all_par": [208, 228], "parent": [208, 228], "set_modul": [208, 228, 242], "update_sq_scal": 208, "ipex_config_path": [208, 212], "smoothquant_scale_info": 208, "ipex_config": 208, "enough_memo_store_scal": 208, "need_spac": 208, "amount": [208, 271, 342], "move_input_to_devic": [208, 228], "forward_wrapp": [208, 228], "zip": [208, 282], "fed": [208, 344], "warn": [208, 254, 312], "issu": [208, 279, 280, 281, 283, 284, 324, 336], "model_forward": [208, 228], "forward": [208, 228, 268, 279, 286, 328, 334, 336, 339, 342], "until": [208, 260, 286, 344], "retri": 208, "build_captured_dataload": 208, "calib_num": 208, "inputcapturemodul": 208, "captureddataload": 208, "cal_scal": 208, "input_max_ab": 208, "weight_max_lb": 208, "concaten": 208, "divis": 208, "model_forward_per_sampl": 208, "quant_dequant_w_v1": 208, "num_bit": [208, 224, 279, 342], "scheme": [208, 212, 224, 228, 285, 286, 287, 313, 320, 339, 344], "asym": [208, 224, 228, 287, 320, 339], "asymmetr": [208, 272, 287, 336, 339, 344], "quant_dequant_x_v1": 208, "min_x": 208, "max_x": 208, "No": [208, 281, 312, 319, 328, 335], "clip": [208, 228, 268, 279, 339, 342], "invalid": 208, "reshape_scale_as_weight": 208, "reshape_in_channel_to_last": 208, "reshape_scale_as_input": 208, "register_autotun": 208, "datalod": 208, "graphtrac": [208, 228], "autoalpha": 208, "absorb_to_lay": [208, 227, 228, 234], "alpha_min": [208, 234, 342], "alpha_max": [208, 234, 342], "alpha_step": [208, 234, 342], "shared_criterion": [208, 234, 342], "init_alpha": [208, 234], "do_blockwis": [208, 234, 342], "n_sampl": [208, 268], "traced_model": 208, "scale_shar": [208, 234], "sqlinearwrapp": 208, "input_minmax": 208, "quint8": 208, "wrapperlay": 208, "input_min": 208, "input_max": 208, "save_q_input": 208, "staticqu": [209, 211], "recursivescriptmodul": 210, "staticquantquant": 211, "generate_xpu_qconfig": 212, "qconfig": [212, 256, 260, 268, 284, 339], "generate_activation_observ": 212, "smooth_quant_en": 212, "observ": [212, 234, 237, 260, 263, 267, 268, 269, 287, 339, 341, 344], "simple_infer": 212, "warm": 212, "get_depth": 212, "depth": [212, 338], "get_dict_at_depth": 212, "target_depth": 212, "get_element_under_depth": 212, "ops_lst": 212, "parse_cfg": 212, "ops_nam": 212, "get_quantizable_ops_from_cfg": 212, "input_tensor_ids_op_nam": 212, "transformerbasedmodelblockpatterndetector": 212, "pattern_lst": 212, "block_pattern": 212, "ffn": 212, "autoroundquant": 213, "enable_full_rang": [213, 228, 234, 253, 268, 337, 339], "amp": [213, 339], "lr_schedul": [213, 234, 268, 328, 334], "neelnanda": 213, "pile": 213, "10k": [213, 317], "enable_quanted_input": [213, 234, 268], "enable_minmax_tun": [213, 234, 268], "minmax_lr": [213, 234, 268], "low_gpu_mem_usag": [213, 234, 268], "seqlen": [213, 234, 268], "nsampl": [213, 215, 234, 339], "rand": [213, 234, 268, 279, 342], "nblock": [213, 234], "gradient_accumulate_step": [213, 234, 268], "not_use_best_ms": [213, 234, 268], "dynamic_max_gap": [213, 234, 268], "scale_dtyp": [213, 224, 234, 253, 268, 339], "quant_block_list": [213, 234], "act_bit": [213, 234], "act_group_s": [213, 234], "act_dynam": [213, 234], "low_cpu_mem_usag": 213, "get_dataload": 213, "dataset_nam": 213, "comma": 213, "reproduc": 213, "awqquant": 214, "absorb_layer_dict": [214, 234], "is_leaf": 215, "judg": 215, "trace_gptq_target_block": 215, "module_typ": 215, "modulelist": 215, "stack": [215, 284], "critic": [215, 272, 280], "gptq_related_block": 215, "embed": [215, 311, 334], "transformers_pr": 215, "transformers_nam": 215, "find_lay": 215, "supported_lay": [215, 228], "find_layers_nam": 215, "log_quantizable_layers_per_transform": 215, "transformer_block": 215, "rawgptquant": 215, "weight_config": [215, 227], "use_max_length": [215, 339], "use_layer_wis": [215, 234, 268], "pretrain": [215, 253], "arxiv": [215, 234, 264, 268, 279, 284, 311, 331, 334, 335, 339, 342], "ab": [215, 228, 234, 272, 279, 334, 336, 342], "2210": [215, 234, 268, 279, 339], "17323": [215, 234, 268, 279, 339], "gptquantiz": 215, "logic": [216, 220, 238, 269], "packer": 216, "unpack": [216, 224], "qtensorconfig": 217, "hqqmoduleconfig": 217, "hqqmodul": 217, "hqqtensorhandl": 218, "hqqlinear": [218, 222], "q_weight": 218, "qtensor": [218, 219], "bitpack": 219, "optimize_weights_proximal_legaci": 220, "min_max": 220, "opt_param": 220, "lp_norm": 220, "beta": 220, "kappa": 220, "along": [220, 221, 268, 324, 334, 339], "1e1": 220, "qtensormetainfo": 221, "nbit": 221, "meta_info": 221, "patch_hqq_moduil": 222, "mod": 222, "patch": 222, "filter_fn": 222, "configmappingtyp": 222, "replacement_fn": 222, "hqquantiz": 222, "hqq": [223, 234, 269, 284], "autoround": [223, 232, 234, 269, 279, 284, 326], "awq": [223, 228, 232, 234, 269, 279, 337, 339], "teq": [223, 232, 234, 269, 284, 335, 337, 339], "unpackedweightonlylinearparam": 224, "unpack_weight": 224, "unpack_zp": 224, "weightonlylinear": [224, 268, 339], "incweightonlylinear": 224, "zp": [224, 228, 279, 342], "compression_dtyp": [224, 253, 339], "int32": [224, 253, 268, 339], "compression_dim": [224, 253, 339], "g_idx": 224, "use_optimum_format": [224, 253, 339], "hpuweightonlylinear": 224, "bfloat16": [224, 234, 265, 284, 329, 338], "hpu": [224, 236, 238, 260], "fakeaffinetensorquantfunct": 224, "affin": [224, 336], "teqlinearfakequ": 224, "orig_lay": 224, "mullinear": 224, "rtnquantiz": 225, "woq": [226, 234, 236, 264, 284, 326, 331], "original_model": [226, 236, 268], "loadformat": [226, 239], "fp32_model": [226, 236, 250, 257, 266, 267, 271, 272, 337, 339], "upstream": [226, 236], "hugginfac": [226, 236], "checkpoint_dir": [226, 236, 256], "cowork": [226, 236], "defult": [226, 236], "causal": [226, 236, 334], "remain": [226, 236], "__init__": [226, 236, 285, 312, 313, 327, 344], "trust_remote_cod": [226, 236], "woqmodelload": 226, "trainableequivalenttransform": 227, "trainabl": [227, 268, 284, 335, 339], "tequant": 227, "quantize_4bit": 228, "quantil": [228, 344], "nf4": [228, 268, 339], "return_int": [228, 339], "fp4": [228, 264, 268, 331, 339], "q_tensor": 228, "qdq_weight_asym": 228, "schema": 228, "qdq_weight_sym": 228, "full_rang": 228, "amax": [228, 264, 331], "qdq_weight_actor": 228, "quant_tensor": 228, "search_clip": 228, "num": [228, 257], "best_clip_ratio": 228, "quant_weight_w_scal": 228, "spevif": 228, "fetch_modul": [228, 242], "get_absorb_lay": 228, "no_absorb_lay": 228, "absorpt": 228, "absorbed_1": 228, "xx": 228, "get_block_prefix": 228, "block_list": 228, "block_num": 228, "block_prefix": 228, "replace_forward": 228, "rest": 228, "part": [228, 262, 265, 279, 282, 324, 329, 334, 337, 342], "recover_forward": 228, "get_module_input_output": 228, "module_hook_config": 228, "input_func": 228, "output_func": 228, "help": [228, 262, 273, 279, 312, 326, 330, 339, 344], "module_name_list": 228, "fc1": [228, 267], "fc2": 228, "input_valu": 228, "output_valu": 228, "total_valu": 228, "pt2e_export": 229, "export_model_for_pt2e_qu": 230, "dynamic_shap": 230, "graph_modul": 230, "eager": [230, 263, 267, 268, 269, 316, 323, 336, 338], "rtn_entri": 232, "rtnconfig": [232, 233, 234, 242, 268, 269, 273, 321], "gptq_entri": 232, "gptqconfig": [232, 234, 268, 273], "pt2e_dynamic_quant_entri": 232, "pt2e_static_quant_entri": 232, "awq_quantize_entri": 232, "awqconfig": [232, 234, 268], "teq_quantize_entri": 232, "teqconfig": [232, 234, 268], "autoround_quantize_entri": 232, "autoroundconfig": [232, 234, 268], "hqq_entri": 232, "hqqconfig": [232, 234, 268], "fp8_entri": 232, "fp8config": [232, 234, 260, 284], "fp8": [232, 234, 236, 264, 269, 331, 335], "mx_quant_entri": 232, "mxquantconfig": [232, 234, 264, 331], "mixed_precision_entri": 232, "mixprecisionconfig": 232, "get_rtn_double_quant_config_set": 233, "doubl": [233, 234, 268, 335], "run_arg": [233, 237, 269], "_description_": [233, 269], "torchbaseconfig": 234, "use_sym": [234, 268, 273], "group_dim": [234, 268, 339], "use_full_rang": [234, 268], "use_mse_search": [234, 268], "use_double_qu": [234, 268], "double_quant_dtyp": [234, 268], "double_quant_bit": [234, 268], "double_quant_use_sym": [234, 268], "double_quant_group_s": [234, 268], "quant_lm_head": [234, 268], "get_default_rtn_config": [234, 275], "processor_typ": [234, 275], "torch_util": [234, 337, 342], "get_default_double_quant_config": 234, "bnb_nf4": [234, 242], "act_ord": [234, 268], "percdamp": [234, 268, 339], "static_group": [234, 268, 339], "get_default_gptq_config": 234, "use_auto_scal": [234, 268], "use_auto_clip": [234, 268], "acceler": [234, 238, 240, 260, 265, 266, 268, 271, 279, 284, 324, 328, 334, 335, 338, 339, 342, 344], "2306": [234, 268, 279, 339], "00978": [234, 268, 279, 339], "get_default_awq_config": 234, "get_default_teq_config": 234, "via": [234, 268, 279, 280, 284, 316, 323, 328, 334, 335], "gradient": [234, 268, 279, 284, 323, 328, 334, 335, 345], "descent": [234, 268, 279, 284, 335], "2309": [234, 268, 279], "05516": [234, 268, 279], "get_default_autoround_config": 234, "w_dtype": [234, 264, 266, 267, 331], "out_dtyp": 234, "blocksiz": [234, 264, 331], "round_method": 234, "get_default_mx_config": 234, "dynamicquantconfig": [234, 263], "w_sym": 234, "w_granular": 234, "w_algo": 234, "get_default_dynamic_config": 234, "model_info": 234, "get_default_static_config": 234, "quant_zero": [234, 268], "quant_scal": [234, 268], "scale_quant_group_s": [234, 268], "quadrat": [234, 268], "blog": [234, 284, 335], "mobiusml": [234, 268], "hqq_blog": [234, 268], "get_default_hqq_config": 234, "dump_stats_path": [234, 260], "hqt_output": [234, 260], "fp8_config": [234, 260, 284], "e4m3": [234, 260, 264, 284, 331], "hp_dtype": [234, 260], "blocklist": [234, 260], "allowlist": [234, 260], "fp8_white_list": [234, 260], "scale_method": [234, 260], "maxabs_hw": [234, 260], "scale_param": 234, "maxab": [234, 260], "mod_dict": 234, "measure_exclud": [234, 260], "get_default_fp8_config": 234, "get_default_fp8_config_set": 234, "get_default_mixed_precision_config": 234, "get_default_mixed_precision_config_set": 234, "get_woq_tuning_config": [234, 273], "load_entri": 235, "torchscript": [236, 318, 337, 342], "finalize_calibr": 237, "acceleratorregistri": 238, "register_acceler": 238, "cuda_acceler": 238, "cpu_acceler": 238, "xpu_acceler": 238, "hpu_acceler": 238, "auto_detect_acceler": 238, "device_nam": [238, 240], "appropri": [238, 267, 273, 275, 279, 280, 311, 342], "forc": [238, 338], "force_devic": 238, "insensit": 238, "refin": [238, 272, 322, 334], "is_ipex_import": 240, "intel_extension_for_pytorch": [240, 267], "is_transformers_import": 240, "is_package_avail": 240, "package_nam": 240, "packag": [240, 284, 285, 312, 319, 324, 335, 340, 344], "is_hpex_avail": 240, "hpex": 240, "is_ipex_avail": 240, "get_ipex_vers": 240, "get_torch_vers": 240, "get_acceler": 240, "device_synchron": 240, "raw_func": 240, "synchron": [240, 344], "auto_acceler": 241, "get_model_info": 242, "white_module_list": 242, "get_double_quant_config_dict": 242, "double_quant_typ": 242, "double_qu": 242, "get_quant": 242, "quantizer_cl": 242, "postprocess_model": 242, "get_model_devic": 242, "get_processor_type_from_user_config": 242, "user_processor_typ": 242, "notimplementederror": 242, "loop": [243, 282, 286, 287, 320, 341, 344], "compressionmanag": 243, "deal": 243, "pruningconfig": 243, "orchestr": [243, 262, 323], "callback": [243, 246, 282, 328, 333, 334, 336], "on_train_begin": [243, 282, 315, 328, 333, 334, 336], "train_loop": [243, 328, 333], "epoch": [243, 313, 315, 316, 328, 333, 334], "on_epoch_begin": [243, 246, 315, 328, 333], "on_step_begin": [243, 246, 315, 328, 333, 334], "on_after_compute_loss": [243, 315, 328, 333], "backward": [243, 279, 315, 316, 328, 333, 334, 336, 340], "on_before_optimizer_step": [243, 315, 328, 333, 334], "on_step_end": [243, 246, 315, 328, 333], "on_epoch_end": [243, 246, 315, 328, 333], "on_train_end": [243, 315, 328, 333, 334, 336], "path_to_sav": 243, "train_func": [243, 316, 328, 336], "top1": [243, 327, 334, 336, 345], "callbacks_list": 243, "layerhistogramcollector": 244, "num_bin": 244, "8001": 244, "layer_tensor": 244, "include_lay": 244, "collector": 244, "diverg": [244, 252, 287, 311, 344], "get_func_from_config": 246, "func_dict": 246, "get_preprocess": 246, "get_metr": 246, "get_postprocess": 246, "get_algorithm": 246, "create_dataset": 246, "data_sourc": 246, "cfg_preprocess": 246, "cfg_filter": 246, "create_dataload": 246, "dataloader_cfg": 246, "create_eval_func": 246, "postprocess_cfg": 246, "baselin": [246, 273, 341, 342], "create_train_func": 246, "train_cfg": 246, "Their": 246, "qlinear2qdq": 247, "check_model": 248, "onnx_qlinear_to_qdq": 248, "input_name_to_nod": 248, "qlinearop": [248, 323, 336, 345], "tf_to_fp32_onnx": 249, "save_path": [249, 250, 285, 330], "inputs_as_nchw": 249, "tf_to_int8_onnx": 249, "int8_model": [249, 250], "get_node_map": 250, "fp32_onnx_path": 250, "module_node_map": 250, "get_quantizable_onnx_op": 250, "quantize_nod": 250, "dynamic_quant_export": 250, "pt_fp32_model": 250, "pt_int8_model": 250, "weight_typ": 250, "static_quant_export": 250, "_quantiz": 250, "torch_to_fp32_onnx": 250, "do_constant_fold": 250, "torch_to_int8_onnx": 250, "auxiliari": 251, "collect_layer_histogram": 251, "create_obj_from_config": 251, "kl_diverg": 251, "load_huggingfac": [251, 328], "weights_detail": 251, "optimizedmodel": 253, "from_pretrain": [253, 321, 328], "save_for_huggingface_upstream": [253, 328], "export_compressed_model": [253, 339], "saved_dir": [253, 339], "_type_": 253, "comoress": 253, "msg": 254, "debug": [254, 344], "fatal": 254, "alia": [254, 257], "is_int8_model": 256, "load_weight_onli": 256, "best_model": [256, 265, 270, 271, 272, 273, 339], "history_cfg": 256, "best_configur": 256, "best_model_weight": 256, "snapshot": 256, "cfg_from_fil": 257, "yaml_fil": [257, 316], "time_limit": 257, "context": [257, 268, 279, 339], "get_siz": 257, "seen": [257, 285], "recurs": 257, "compute_spars": 257, "non": [257, 260, 265, 268, 282, 339, 344], "fault_tolerant_fil": 257, "equal_dict": 257, "d2": 257, "compare_kei": 257, "ignore_kei": 257, "ignor": [257, 268, 279, 311, 339, 342, 344], "get_tuning_histori": 257, "tuning_history_path": 257, "offlin": [257, 266, 271, 272, 279, 280, 328, 336, 342], "str2arrai": 257, "dequantize_weight": 257, "weight_tensor": 257, "min_filter_tensor": 257, "max_filter_tensor": 257, "scale_info": 257, "global_st": 257, "load_data_from_pkl": 257, "pkl": 257, "dump_data_to_loc": 257, "show_memory_info": 257, "hint": [257, 319], "show": [257, 264, 279, 280, 316, 328, 331, 342, 344], "dump_class_attr": 257, "sex": [257, 280], "male": 257, "compare_object": 257, "obj1": 257, "obj2": 257, "ignore_attr": 257, "comparison": [257, 339, 340], "alias_param": 257, "param_alia": 257, "alias": [257, 312], "print_tabl": 257, "column_map": 257, "table_entri": 257, "titl": [257, 325, 344], "insert_newlin": 257, "tabl": [257, 264, 284, 287, 318, 321, 331, 345], "prettyt": 257, "column": [257, 268, 279, 339, 342], "row": [257, 279, 342], "decim": 257, "get_tensors_info": 257, "workload_loc": 257, "about": [257, 260, 262, 280, 312, 313, 328, 334, 338, 344, 345], "workload": [257, 265, 335], "get_weights_detail": 257, "weightdetail": 257, "dump_tabl": 257, "file_typ": 257, "csv": 257, "dump_table_to_csv": 257, "get_number_of_socket": 257, "platform": [257, 274, 279, 323, 335, 336], "opentri": 257, "activation_min": 257, "activation_max": 257, "print_op_list": 257, "get_op_list": 257, "minmax_file_path": 257, "input_model_tensor": 257, "optimized_model_tensor": 257, "activation_min_max": 257, "calculate_ms": 257, "mse_metric_gap": 257, "fp32_tensor": 257, "dequantize_tensor": 257, "euclidean": 257, "distanc": 257, "check_key_exist": 257, "weightsdetail": 258, "input_tensor_data": 258, "optimized_tensor_data": 258, "weightsstatist": 258, "promis": [260, 315, 328, 334], "shown": [260, 264, 266, 279, 313, 327, 328, 331, 332, 333, 334, 337, 342, 344], "gaudi2": [260, 284, 324], "e5m2": [260, 264, 331], "cost": [260, 264, 268, 279, 331, 336, 339], "As": [260, 268, 279, 282, 286, 313, 327, 328, 334, 339, 344], "fig": 260, "2e5m2": 260, "bfloat16fp16": 260, "bmm": [260, 268, 279, 339], "omit": [260, 339], "hqt": 260, "emit": 260, "without_scal": 260, "unit_scal": 260, "stretch": 260, "hw": 260, "maxabs_pow2": 260, "power": [260, 264, 272, 328, 331, 335], "maxabs_hw_opt_weight": 260, "chosen": [260, 286, 311], "act_maxabs_pow2_weights_pcs_opt_pow2": 260, "act_maxabs_hw_weights_pcs_maxabs_pow2": 260, "speed": [260, 279, 311, 328, 334, 335, 336, 344], "neural_compressor": [260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 282, 284, 287, 310, 312, 313, 315, 316, 318, 321, 322, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 338, 340, 341, 342, 343, 344], "resnet18": [260, 284, 329, 345], "vision": [260, 279, 284, 318, 342], "optimum": [260, 339], "habana": [260, 284, 324], "goe": 260, "welcom": [261, 280, 281, 284, 346], "aim": [262, 273, 284, 321, 326, 334, 342, 344], "familiar": 262, "concept": [262, 322, 341], "learn": [262, 264, 265, 268, 269, 272, 279, 284, 285, 286, 313, 318, 322, 323, 324, 328, 329, 331, 334, 335, 336, 342, 344], "conduct": [262, 282, 328, 344], "mainstream": [262, 284], "quick": [262, 275, 320, 329, 334], "understand": [262, 279, 336], "workflow": [262, 264, 284, 286, 287, 318, 321, 324, 329, 331], "broad": [262, 284, 323], "notebook": 262, "oneapi": [262, 265, 324, 335], "ai": [262, 264, 265, 284, 331, 335, 338], "analyt": [262, 324, 335], "toolkit": [262, 282, 324, 335], "tutori": [262, 282, 335], "comprehens": [262, 269, 272, 328], "migrat": [262, 266, 271, 279, 342], "previou": [262, 269, 279, 286, 287, 328, 334, 340, 342, 344, 345], "veri": [262, 268, 279, 328, 336, 339, 344], "introduct": 262, "dive": [262, 320], "bitwidth": 263, "whole": [263, 279, 287, 336, 345], "runtim": [263, 279, 281, 284, 285, 286, 288, 313, 317, 320, 323, 329, 331, 339, 344], "four": [263, 267, 273, 345], "userfloatmodel": [263, 267], "exported_model": [263, 267], "prepared_model": [263, 266, 267, 268, 275, 321], "_inductor": [263, 267], "opt_model": [263, 267, 328], "set_loc": [263, 266, 267, 268, 269, 270], "releas": [263, 267, 284, 321, 324, 346], "breakthrough": [264, 331], "emerg": [264, 331, 342], "analysi": [264, 331, 334, 341], "chatbot": [264, 331, 335], "fuel": [264, 331], "nevertheless": [264, 331], "challeng": [264, 268, 331, 337], "explos": [264, 331], "growth": [264, 265, 328, 329, 331, 334], "pose": [264, 331, 337], "obstacl": [264, 331], "practic": [264, 331], "preserv": [264, 268, 311, 331, 334, 339], "promot": [264, 268, 331], "microsoft": [264, 284, 285, 331], "msfp": [264, 331], "mxfp8": [264, 331], "e8m0": [264, 331], "mxfp6": [264, 331], "fp6": [264, 331], "e3m2": [264, 331], "e2m3": [264, 331], "mxfp4": [264, 331], "e2m1": [264, 268, 331, 339], "mxint8": [264, 331], "At": [264, 281, 286, 331, 344], "demonstr": [264, 268, 273, 275, 284, 317, 331], "abil": [264, 285, 286, 320, 331, 342], "occupi": [264, 331], "incur": [264, 331], "energi": [264, 331], "silicon": [264, 331], "seamlessli": [264, 331, 334, 344], "offer": [264, 268, 272, 331], "meticul": [264, 331], "craft": [264, 331], "empow": [264, 331], "sacrif": [264, 331, 335], "explor": [264, 285, 331], "focus": [264, 268, 272, 280, 285, 321, 331], "distinct": [264, 331], "friendli": [264, 279, 320, 328, 331, 335, 342], "adapt": [264, 280, 286, 331, 335], "consumpt": [264, 268, 279, 331, 342], "frac": [264, 279, 331, 342], "expon": [264, 331], "floor": [264, 331], "log2": [264, 331], "rmin": [264, 272, 279, 331, 336], "user_model": [264, 321, 331], "darvish": [264, 331], "rouhani": [264, 331], "bita": [264, 331], "et": [264, 268, 279, 311, 331, 339, 342], "al": [264, 268, 279, 284, 311, 324, 331, 339, 342], "push": [264, 268, 279, 281, 331, 334, 339, 342], "narrow": [264, 331], "inferenc": [264, 331], "cloud": [264, 281, 284, 331, 335], "33": [264, 326, 331, 345], "2020": [264, 331], "10271": [264, 331], "10281": [264, 331], "ocp": [264, 331], "preprint": [264, 268, 279, 311, 331, 334, 339, 342], "2310": [264, 331], "10537": [264, 331], "2023": [264, 268, 279, 284, 331, 334, 339, 342], "recent": [265, 328, 329], "significantli": [265, 268, 328, 329, 334, 344], "propos": [265, 268, 279, 285, 329, 339, 342], "googl": [265, 284, 312, 329, 335], "ieee": [265, 279, 329, 342], "wide": [265, 268, 279, 284, 317, 329, 334, 336], "sixteen": [265, 329], "bandwidth": [265, 268, 279, 328, 329, 339], "3rd": [265, 279, 329, 335, 336, 338], "gen": [265, 279, 326, 329, 335, 336, 338], "xeon": [265, 274, 279, 284, 324, 325, 326, 329, 335, 336, 338, 345], "scalabl": [265, 272, 279, 284, 324, 326, 329, 335, 336, 338], "codenam": [265, 326, 329], "cooper": [265, 324, 329, 335], "lake": [265, 324, 329, 335], "boost": [265, 284, 329, 334, 335], "purpos": [265, 266, 267, 268, 270, 320, 329, 336], "x86": [265, 329], "instruct": [265, 266, 279, 286, 287, 324, 329, 334, 335, 336, 342, 345], "avx512": [265, 279, 329, 336], "vcvtne2ps2bf16": [265, 329], "vcvtneps2bf16": [265, 329], "vdpbf16p": [265, 329], "product": [265, 279, 323, 329, 335, 336, 341, 344], "publish": [265, 280, 325, 326, 329, 342], "4th": [265, 279, 326, 335, 336], "isa": 265, "vector": 265, "512": [265, 268], "avx": 265, "16": [265, 324, 339, 345], "754": 265, "complement": [265, 334], "latest": [265, 269, 284, 324, 335, 340], "deliv": [265, 268, 328, 335, 340], "flexibl": [265, 268, 272, 284, 334, 339], "amx": [265, 335], "improv": [265, 267, 268, 279, 281, 284, 311, 312, 328, 334, 335, 336, 338, 339, 344, 345], "ideal": 265, "recognit": [265, 316, 318, 334], "advantag": [265, 334, 344], "onednn": [265, 272, 329, 336], "engin": 265, "fbgemm": [265, 329, 336], "10004": [265, 268, 269, 274, 282, 285, 313, 315, 316, 320, 323, 329, 331, 333, 337, 339], "avx512_bf16": [265, 329], "11": [265, 279, 324, 327, 329, 342, 344, 345], "avx512_fp16": 265, "onednn_max_cpu_isa": 265, "avx512_core_amx_fp16": 265, "eval_acc_fn": [265, 270, 272], "acc": [265, 270, 326, 334, 345], "might": [265, 282, 312, 344], "custom_tune_config": [265, 270, 271, 272, 273], "build_torch_model": 265, "gigant": [266, 271, 342], "systemat": [266, 271, 342], "quantif": [266, 268, 271, 339, 342], "difficult": [266, 271, 273, 279, 285, 342], "difficulti": [266, 271, 279, 342], "mathemat": [266, 271, 279, 342], "stai": [266, 268, 269, 339, 342], "achiev": [266, 267, 268, 269, 270, 273, 275, 279, 318, 326, 328, 333, 334, 335, 336, 342, 344], "lambada": [266, 342], "openai": [266, 342], "sweet": [266, 342], "spot": [266, 342], "region": [266, 342], "paper": [266, 268, 279, 334, 339, 342], "bigscienc": [266, 326, 342, 345], "bloom": [266, 279, 284, 326, 334, 342, 345], "560m": [266, 342], "354": [266, 342], "3542": [266, 342], "1b7": [266, 326, 342], "4634": [266, 342], "4936": [266, 342], "3b": [266, 326, 342], "518": [266, 342], "5185": [266, 342], "7b1": [266, 342, 345], "5764": [266, 342, 345], "5977": [266, 342], "bloomz": [266, 342, 345], "3947": [266, 342], "3930": [266, 342], "4828": [266, 342], "4906": [266, 342], "5018": [266, 342], "4980": [266, 342], "5593": [266, 342, 345], "5552": [266, 342], "facebook": [266, 326, 342, 345], "opt": [266, 279, 284, 326, 334, 342, 344, 345], "125m": [266, 321, 342], "379": [266, 342], "3757": [266, 342], "350m": [266, 342], "4516": [266, 342], "4533": [266, 342], "5789": [266, 342], "5742": [266, 342], "7b": [266, 275, 284, 326, 342, 345], "6365": [266, 342], "6404": [266, 342], "6769": [266, 342, 345], "6804": [266, 342, 345], "13b": [266, 326, 342, 345], "6872": [266, 342], "6814": [266, 342], "30b": [266, 326, 342, 345], "7149": [266, 342], "7128": [266, 342], "66b": [266, 342], "7398": [266, 342], "7326": [266, 342], "llama": [266, 275, 284, 326, 334, 335, 337, 339, 342, 345], "7361": [266, 342, 345], "7357": [266, 342], "7627": [266, 342, 345], "7590": [266, 342], "7759": [266, 342, 345], "7840": [266, 342], "65b": [266, 342], "7908": [266, 342], "7957": [266, 342], "eleutherai": [266, 321, 326, 342, 345], "gpt": [266, 284, 321, 326, 334, 342, 345], "j": [266, 279, 284, 326, 334, 342, 345], "6b": [266, 326, 342, 345], "6831": [266, 342, 345], "6821": [266, 279, 342], "mbzuai": [266, 342], "lamini": [266, 334, 342], "124m": [266, 342], "3804": [266, 342], "3887": [266, 342], "774m": [266, 342], "5048": [266, 342], "5057": [266, 342], "5b": [266, 342], "5443": [266, 342, 345], "5436": [266, 342], "mosaicml": [266, 342, 345], "mpt": [266, 334, 342, 345], "chat": [266, 275, 326, 342, 345], "655": [266, 342, 345], "6499": [266, 342], "stabilityai": [266, 342], "stablelm": [266, 342], "4172": [266, 342], "4149": [266, 342], "togethercomput": [266, 342], "redpajama": [266, 342], "incit": [266, 342], "6542": [266, 342], "6735": [266, 342], "6718": [266, 342], "6740": [266, 342, 345], "6569": [266, 342], "6621": [266, 342], "v0": [266, 326, 342], "7143": [266, 342], "7221": [266, 342], "6895": [266, 342], "6953": [266, 342, 345], "databrick": [266, 326, 342, 345], "dolli": [266, 326, 334, 342, 345], "6866": [266, 342, 345], "6297": [266, 342], "6247": [266, 342], "tiiuae": [266, 326, 342, 345], "falcon": [266, 284, 326, 334, 342, 345], "6437": [266, 342, 345], "6392": [266, 342], "asterisk": [266, 342], "gt": [266, 268, 342, 343], "retrain": [267, 315], "involv": 267, "philosophi": [267, 272, 336], "request": [267, 284, 336], "would": [267, 279, 281, 328, 334, 336, 342], "crucial": [267, 334], "occur": 267, "jit": [267, 342], "effect": [267, 268, 285, 334, 335], "begin": [267, 312, 313, 315, 328, 334, 344], "program": [267, 284, 316, 325], "dynamo": [267, 269], "qd": 267, "becom": [268, 279, 285, 318, 334, 339], "preval": [268, 279, 339], "grow": [268, 279, 339], "demand": [268, 279, 339], "modern": [268, 279, 339], "trade": [268, 279, 339], "bottleneck": [268, 279, 339], "deploi": [268, 273, 279, 281, 328, 339, 344], "roughli": [268, 279, 339], "speak": [268, 279, 339], "count": [268, 279, 339], "p": [268, 275, 279, 339], "theoret": [268, 279, 336, 339], "capac": [268, 279, 339, 341], "flop": [268, 279, 339], "famou": [268, 279, 339], "scenario": [268, 269, 279, 285, 310, 328, 334, 339], "approx": [268, 279, 339], "past": [268, 279, 285, 339], "100x": [268, 279, 339], "besid": [268, 279, 285, 339], "mention": [268, 279, 334, 339], "reason": [268, 279, 280, 286, 313, 339, 344], "caus": [268, 279, 286, 313, 334, 339], "straightforward": [268, 272, 279, 334, 339, 342], "think": [268, 339], "intuit": [268, 279, 339, 342], "uniformli": [268, 339], "qlora": [268, 279, 339], "uniform": [268, 311, 339], "prove": [268, 279, 311, 339, 342], "shot": [268, 272, 323, 328, 334, 335, 339], "highli": [268, 335, 339], "invers": [268, 339], "restor": [268, 339], "tailor": [268, 275], "often": [268, 313, 333, 334], "outperform": 268, "signround": 268, "protect": [268, 339], "salient": [268, 334, 339], "greatli": [268, 337, 339], "big": [268, 339], "inspir": [268, 339], "rather": [268, 322, 339], "addition": [268, 287, 316, 334, 344], "incorpor": [268, 286, 287, 315, 334, 344], "l": [268, 274, 311, 344], "norm": 268, "hyper": 268, "laplacian": 268, "heavi": [268, 315], "tail": 268, "nuanc": 268, "weightonlyqu": 268, "c_": [268, 339], "normalfloat": [268, 339], "bnb": [268, 339], "lm": [268, 334], "head": [268, 334], "emb": 268, "rtn_arg": [268, 337, 339], "gptq_arg": [268, 339], "diagon": [268, 339], "rearrang": [268, 334, 339], "stabil": [268, 339], "c_out": 268, "mitig": [268, 339], "actord": [268, 339], "autoround_arg": 268, "rate": [268, 279, 328, 334, 336], "n_block": [268, 339], "gap": [268, 330], "awq_arg": [268, 339], "teq_arg": 268, "train_fn": 268, "hqq_arg": 268, "lm_head": [268, 334, 339], "lm_head_config": 268, "quantit": 268, "date": [268, 339], "orig_model": 268, "yourmodel": 268, "loaded_model": 268, "card": [268, 334], "impract": 268, "lwq": 268, "diagram": [268, 286, 287, 344], "illustr": [268, 286, 287, 315, 344], "figur": [268, 337], "color": [268, 334, 337], "grei": [268, 337], "blue": [268, 337], "rectangl": [268, 337], "model_state_dict_path": [268, 275], "state": [268, 275, 287, 334], "float_model": [268, 275], "quantized_model": [268, 275, 321], "overhead": [268, 342], "xiao": [268, 279, 339, 342], "guangxuan": [268, 279, 339, 342], "2211": [268, 279, 339, 342], "10438": [268, 279, 339, 342], "wei": [268, 279, 339, 342], "xiui": [268, 279, 339, 342], "suppress": [268, 279, 339, 342], "2209": [268, 279, 339, 342, 345], "13325": [268, 279, 339, 342], "lin": [268, 279, 339], "ji": [268, 279, 339], "frantar": [268, 279, 334, 339], "elia": [268, 279, 339], "cheng": [268, 279], "wenhua": [268, 279], "badri": 268, "hicham": 268, "shaji": 268, "appu": 268, "onlin": [268, 280, 341], "dettmer": [268, 279, 339], "tim": [268, 279, 339], "finetun": [268, 279, 334, 339], "2305": [268, 279, 339], "14314": [268, 279, 339], "grain": [269, 334, 335, 344], "varieti": [269, 273, 317, 344], "classic": [269, 344], "research": [269, 284, 325, 342, 345], "simul": [269, 287], "emul": [269, 279, 328, 336], "term": [269, 272, 281, 311, 325, 327, 332, 333, 344], "eas": [269, 272, 324, 335], "commit": [269, 272, 280, 281], "extend": [269, 286, 287, 321], "hand": [269, 272], "reus": 269, "conveni": [269, 328], "discuss": [269, 284], "far": 269, "still": [269, 271, 279, 311, 328, 335, 336, 338], "reli": [269, 328, 342], "plan": [269, 323], "deploy": [269, 314, 335, 337, 342], "One": [269, 287, 312, 316, 323, 334, 335, 344], "orig_sav": 269, "suggest": [269, 282, 312, 341], "statu": [269, 274, 280, 313, 331, 332, 334], "trane": 269, "torchdynamo": 269, "microsc": 269, "pytorchdynamo": 269, "torchimport": 269, "operator_name_or_list": 269, "mlp": [269, 334], "conv1d": [269, 287], "fundament": [270, 271, 311, 328], "fulli": [270, 328, 336, 342], "respons": [270, 336], "val_dataset": [270, 328, 336], "val_dataload": [270, 328, 336], "mydataload": [270, 272, 273], "qmodel": [270, 272], "good": [270, 280, 336, 344], "from_dict": 270, "conv2d_config": 270, "output_graph_def": 271, "sq_config": 271, "static_config": 271, "look": [271, 285, 287, 320, 327, 342], "eval_fn_wrapp": 271, "consider": [271, 342], "experi": [272, 280, 341, 342, 344], "rule": [272, 334], "partial": [272, 334, 336], "particularli": 272, "supplement": 272, "baseline_model": [272, 273], "rmax": [272, 279, 336], "mp": 272, "unseen": [272, 279, 336], "zeropoint": [272, 279, 336], "unlik": 272, "tradit": [272, 334], "signific": [272, 279, 334, 335, 337, 342], "quickli": [273, 326, 344], "despit": 273, "consum": [273, 313], "predefin": 273, "primari": [273, 311, 344], "travers": [273, 286, 287, 339, 344], "incbench": 274, "launch": [274, 329], "therefor": [274, 279, 282, 328, 334, 336, 337, 340, 342], "num_cores_on_numa": 274, "visibl": 274, "cross_memori": 274, "alloc": 274, "insuffici": 274, "num_i": 274, "num_c": 274, "throughput_pattern": 274, "hroughput": 274, "za": 274, "z": [274, 279, 311, 312, 342], "latency_pattern": 274, "atenc": 274, "3f": 274, "sec": [274, 345], "lightweight": [275, 334], "enhanc": [275, 311, 334, 335, 338], "tip": 275, "omp_num_thread": 275, "hybrid": 275, "taskset": 275, "finish": 275, "ten": 275, "gb": 275, "v3": [277, 345], "17": [277, 284, 324, 326], "invent": [279, 336], "int4": [279, 326, 336, 345], "mainli": [279, 284, 321, 328, 334, 336], "miss": [279, 334, 336], "On": [279, 336, 345], "4x": [279, 336], "speedup": [279, 317, 323, 336], "255": [279, 336, 342], "sometim": [279, 282, 336], "overflow": [279, 336], "vnni": [279, 317, 323, 336], "solv": [279, 281, 336, 340], "coarsest": [279, 342], "finer": [279, 342, 344], "matric": [279, 342], "similarli": [279, 342], "finest": [279, 342], "adopt": [279, 281, 334, 335, 342], "bring": [279, 342], "why": [279, 342], "suppos": [279, 342], "6839": [279, 342], "4741": [279, 342], "7451": [279, 342], "9301": [279, 342], "1742": [279, 342], "6835": [279, 342], "formula": [279, 334, 342], "q_min": [279, 342], "q_max": [279, 342], "q_x": [279, 342], "clamp_": [279, 342], "round_": [279, 342], "w_q": [279, 342], "00296431384049356": [279, 342], "59": [279, 326, 342, 345], "172": [279, 342, 345], "192": [279, 342], "w_dq": [279, 342], "2220": [279, 342], "1510": [279, 342], "2420": [279, 342], "2570": [279, 342], "0500": [279, 342], "1890": [279, 342], "mseloss": [279, 342], "1983354538679123": [279, 342], "6848": [279, 342], "4743": [279, 342], "7440": [279, 342], "9308": [279, 342], "1749": [279, 342], "385297635664756e": [279, 342], "07": [279, 284, 342, 345], "affect": [279, 342], "quantize_per_channel": [279, 342], "x_tmp": [279, 342], "detach": [279, 342], "keepdim": [279, 342], "divid": [279, 313, 342, 344], "dequantize_per_channel": [279, 342], "0029": [279, 342, 345], "0036": [279, 342], "162": [279, 342, 345], "93": [279, 342, 345], "207": [279, 342, 345], "139": [279, 342, 345], "6837": [279, 342], "4734": [279, 342], "1751": [279, 342], "637690492221736e": [279, 342], "6376e": [279, 342], "3852e": [279, 342], "cdot": [279, 342], "quantize_per_tensor_absmax": [279, 342], "n_bit": [279, 342], "div_": [279, 342], "0806": [279, 342], "7589": [279, 342], "6038": [279, 342], "3815": [279, 342], "5040": [279, 342], "7174": [279, 342], "5444": [279, 342], "5826": [279, 342], "7772": [279, 342], "5555": [279, 342], "3740": [279, 342], "3253": [279, 342], "0698": [279, 342], "1381": [279, 342], "5972": [279, 342, 345], "0086": [279, 342], "0737": [279, 342], "8298": [279, 342], "6883": [279, 342], "2991": [279, 342], "1601": [279, 342], "6506": [279, 342], "8246": [279, 342], "3924": [279, 342], "3845": [279, 342], "8768": [279, 342], "w_scale": [279, 342], "x_q": [279, 342], "x_scale": [279, 342], "13": [279, 319, 324, 342, 345], "84": [279, 342, 345], "120": [279, 342], "0059755356051027775": [279, 342], "83": [279, 341, 342, 345], "89": [279, 326, 342, 345], "119": [279, 342], "85": [279, 341, 342, 345], "57": [279, 326, 342, 345], "91": [279, 339, 342, 345], "006533813662827015": [279, 342], "y_q": [279, 342], "17509": [279, 342], "7608": [279, 342], "4055": [279, 342], "16599": [279, 342], "21020": [279, 342], "10016": [279, 342], "9860": [279, 342], "22444": [279, 342], "y_dq": [279, 342], "6836": [279, 342], "2970": [279, 342], "1583": [279, 342], "6481": [279, 342], "8207": [279, 342], "3911": [279, 342], "3850": [279, 342], "8763": [279, 342], "major": [279, 322, 336, 342], "peopl": [279, 336], "though": [279, 342], "simplic": [279, 342], "1x2": [279, 342], "2x2": [279, 342], "obtain": [279, 282, 286, 334, 341, 342, 344], "middl": [279, 342], "denot": [279, 342], "fp1": [279, 342], "fp2": [279, 342], "subsect": [279, 342], "even": [279, 337, 339, 342], "lot": [279, 282, 342], "briefli": [279, 328, 342], "similar": [279, 328, 342, 344], "idea": [279, 284, 334, 342, 344], "attach": [279, 328, 342], "x1": [279, 342, 344], "x2": [279, 342, 344], "excel": [279, 339], "mimic": [279, 336], "done": [279, 282, 315, 334, 336], "adjust": [279, 336, 342], "fact": [279, 336], "ultim": [279, 336], "pain": [279, 336], "brought": [279, 330, 336], "lossi": [279, 336], "respect": [279, 280, 320, 334, 342], "chart": [279, 336, 341], "yvinec": [279, 342], "edouard": [279, 342], "proceed": [279, 342], "cvf": [279, 342], "winter": [279, 342], "confer": [279, 334, 342], "interest": [280, 284], "foster": 280, "particip": 280, "commun": 280, "harass": 280, "everyon": 280, "regardless": 280, "ag": 280, "bodi": 280, "ethnic": 280, "characterist": 280, "gender": 280, "educ": 280, "socio": 280, "econom": 280, "race": 280, "religion": 280, "sexual": 280, "orient": 280, "contribut": [280, 284, 334], "inclus": 280, "Being": 280, "viewpoint": 280, "gracefulli": 280, "empathi": 280, "toward": 280, "member": [280, 285], "unaccept": 280, "imageri": 280, "unwelcom": 280, "troll": 280, "insult": 280, "derogatori": 280, "polit": 280, "attack": 280, "public": 280, "privat": 280, "electron": 280, "explicit": 280, "permiss": 280, "inappropri": 280, "profession": 280, "clarifi": 280, "fair": 280, "action": 280, "edit": 280, "reject": 280, "wiki": 280, "ban": 280, "temporarili": 280, "perman": [280, 334], "deem": 280, "threaten": 280, "offens": 280, "harm": 280, "mail": 280, "social": [280, 335], "media": [280, 335], "account": [280, 341, 344], "appoint": 280, "event": 280, "abus": 280, "report": [280, 281, 284, 341], "contact": [280, 340, 341], "complaint": 280, "review": [280, 281, 284, 335], "investig": [280, 312], "necessari": [280, 286, 330, 334, 341, 344], "circumst": 280, "oblig": 280, "confidenti": 280, "regard": [280, 338], "incid": 280, "faith": 280, "repercuss": 280, "leadership": 280, "faq": [280, 284], "page": [280, 281], "send": [281, 286], "view": [281, 284, 317, 340], "star": 281, "repositori": 281, "button": [281, 323], "fork": 281, "clone": [281, 324], "pc": 281, "git": [281, 319, 324], "modif": [281, 285, 320], "checkout": 281, "my": 281, "cover": [281, 318, 322, 335], "certif": 281, "agre": 281, "pr": [281, 313, 327, 340], "least": [281, 328, 334, 344], "approv": 281, "licens": 281, "azur": [281, 284, 335], "devop": 281, "ci": 281, "e16": 281, "v5": 281, "scan": [281, 284], "bandit": 281, "copyright": [281, 325], "docstyl": 281, "spellcheck": 281, "dco": 281, "pytest": 281, "failur": [281, 282], "fault": 281, "coverag": 281, "submit": [281, 335], "bug": [281, 284], "intend": 281, "safe": 281, "collabor": [281, 284], "adher": 281, "tracer": 282, "resolv": [282, 283], "floatfunct": 282, "cat": [282, 318], "eval": [282, 312, 313, 336], "imper": 282, "successfulli": [282, 284, 316, 335], "traceabl": 282, "proxi": 282, "prototyp": 282, "html": [282, 284, 286, 311, 316, 323, 324, 336], "highlight": 282, "untrac": 282, "ssd": [282, 318, 345], "resnet34": [282, 345], "r34": 282, "bboxes_labels_scor": 282, "prob": 282, "45": [282, 326, 345], "max_output": 282, "dbox": 282, "dlabel": 282, "dscore": 282, "decode_singl": 282, "guidelin": [283, 284], "particular": [284, 334, 339], "typic": [284, 315, 317, 334, 345], "gaudi": [284, 324], "ultra": [284, 324, 345], "flex": [284, 324], "amd": [284, 324, 345], "arm": [284, 323, 324, 345], "nvidia": [284, 311, 323, 324, 345], "llama2": 284, "stabl": [284, 334, 335], "diffus": [284, 335], "marketplac": [284, 335], "amazon": 284, "web": 284, "servic": [284, 335], "softwar": [284, 325, 334, 335, 340], "alibaba": [284, 335], "tencent": [284, 335], "taco": [284, 335], "oliv": [284, 335], "ecosystem": [284, 335], "lightn": 284, "2024": [284, 345], "usabl": 284, "pip": [284, 316, 319, 321, 324, 340], "whl": [284, 324], "en": [284, 324], "bare": [284, 319, 324], "metal": [284, 319, 324], "fresh": [284, 324], "click": [284, 323, 324, 335], "sure": [284, 310], "34": [284, 326, 345], "setup": [284, 320, 324, 334], "interact": [284, 341], "habana_visible_devic": 284, "ompi_mca_btl_vader_single_copy_mechan": 284, "cap": 284, "sys_nic": 284, "host": [284, 316], "ipc": 284, "vault": 284, "ubuntu22": 284, "04": [284, 324, 345], "habanalab": 284, "theblok": 284, "torch_dtyp": [284, 287], "safetensor": 284, "overview": [284, 321, 344], "june": [284, 335], "qwen2": [284, 335], "apr": [284, 335], "emnlp": [284, 335], "sep": [284, 335], "legal": [284, 346], "ask": [284, 324], "email": 284, "discord": 284, "join": 284, "technic": 284, "wechat": [284, 335], "img": 284, "bridg": [285, 286, 323], "vanilla": [285, 286, 323], "adaptor_registri": 285, "abcadaptor": 285, "query_fw_cap": [285, 287], "query_fused_pattern": 285, "he": 285, "describ": [285, 287, 312, 320], "hidden": 285, "mainten": 285, "clear": [285, 320, 327, 328], "fragment": 285, "semant": [285, 320], "querybackendcap": [285, 286], "mla": [285, 329, 336], "qtype": 285, "onnxrt_qlinearopsadaptor": 285, "inspect_tensor": 285, "op_list": 285, "iteration_list": 285, "inspect_typ": 285, "save_to_disk": 285, "quantization_cfg": 285, "set_tensor": 285, "tensor_dict": 285, "fw": 286, "outlin": [286, 287], "accommod": [286, 287], "sequencediagram": [286, 287], "autonumb": [286, 287], "query_framework_cap": 286, "opwis": 286, "optypewis": 286, "\u2776": 286, "\u2777": 286, "\u2778": 286, "\u2779": 286, "\u277a": 286, "\u277b": 286, "\u277c": 286, "These": [286, 323], "chapter": 286, "node_op": 286, "confirm": 286, "int8_conv_config": 286, "optype_wise_": 286, "tuning_cfg_to_fw": 286, "Its": [286, 311, 334], "quantize_config": 286, "dispatch": [286, 323], "is_perchannel": 286, "is_asymmetr": 286, "weight_bit": 286, "convert_bf16": 286, "subsequ": 286, "somewhat": 286, "distort": 286, "line": [286, 312, 316, 323], "let": [287, 320, 334], "overal": [287, 339], "drive": 287, "section": [287, 312, 315, 334, 339], "uint4": 287, "independ": 287, "kullback": 287, "leibler": 287, "pytorch_cpu": 287, "1_11_capabl": 287, "cap_s8_1_11": 287, "cap_s8_1_11_conv1d": 287, "per_channel_symmetr": 287, "per_tensor_symmetr": 287, "nativ": 287, "with_arg": 287, "qscheme": 287, "quant_min": 287, "quant_max": 287, "x86_64": 310, "aarch64": 310, "benefici": 311, "\u03b2": 311, "\u03b1": 311, "lie": 311, "simplest": 311, "focu": [311, 344], "essenti": [311, 319], "remaind": 311, "resolut": 311, "extrem": 311, "retain": 311, "noteworthi": 311, "vanhouck": 311, "vincent": 311, "andrew": 311, "senior": 311, "mark": 311, "mao": 311, "2011": 311, "szymon": 311, "migacz": 311, "tensorrt": [311, 329, 336], "2017": 311, "mckinstri": 311, "jeffrei": 311, "discov": 311, "1809": 311, "04191": 311, "2018": 311, "mostli": 312, "conflict": [312, 319], "overli": 312, "argu": 312, "decis": [312, 327], "pep": 312, "tile": 312, "sub_modul": 312, "namespac": 312, "pollut": 312, "popen": 312, "statement": 312, "pipe": 312, "long_str": 312, "extran": 312, "pager": 312, "getenv": 312, "seem": 312, "worth": [312, 334], "4f": 312, "65421": 312, "sentenc": 312, "eval_result": 312, "declar": 312, "typealia": 312, "_lossandgradi": 312, "complextfmap": 312, "xx_func": 312, "pylanc": 312, "cheeseshopaddress": 312, "chees": 312, "shop": 312, "outofcheeseerror": 312, "crbug": 312, "192795": 312, "cpufreq": 312, "facilit": 312, "__all__": 312, "know": [312, 316, 340], "snippet": [312, 323], "rtn_algo_entri": 312, "vscode": 312, "settings_recommend": 312, "encount": [313, 319], "previous": 313, "lack": [313, 319], "faster": [313, 314, 318, 335, 344, 345], "Of": 313, "evenli": 313, "discard": 313, "throw": 313, "awai": 313, "draw": [313, 341, 344], "pin": 313, "reshuffl": 313, "manner": [313, 330], "newdataload": 313, "input_data": 313, "customis": [313, 327], "aid": 314, "infrastructur": 314, "huge": [315, 334, 337], "light": 315, "booster": 315, "degrad": [315, 334, 344], "novel": 315, "10006": 315, "student_output": 315, "student_loss": 315, "training_func_for_nc": 315, "launcher": 315, "experiment": [315, 316, 318, 328, 334, 336, 340, 343], "comb": 315, "distillation_criterion": [315, 328, 333], "q_conf": 315, "horovod": 316, "enable_eager_execut": 316, "yaml_file_path": 316, "pre_process": 316, "simpli": [316, 330], "evaluation_result": 316, "evaluation_time_cost": 316, "partit": [316, 334], "distributedsampl": 316, "train_sampl": 316, "train_dataset": [316, 336], "num_replica": 316, "rank": 316, "train_load": 316, "train_kwarg": 316, "adadelta": 316, "distributedoptim": 316, "named_paramet": 316, "broadcast_paramet": 316, "root_rank": 316, "broadcast_optimizer_st": 316, "set_epoch": 316, "batch_idx": 316, "zero_grad": [316, 328, 334], "nll_loss": 316, "log_interv": 316, "0f": 316, "tloss": 316, "6f": 316, "dry_run": 316, "test_func": 316, "num_of_process": 316, "002": 316, "ssh": 316, "prompt": 316, "readm": 316, "exactli": 316, "cd": [316, 324], "resnet50_v1": [316, 328], "imagerecord": 316, "resizecropimagenet": [316, 343], "realiz": [316, 332, 338, 341], "tow": 316, "node1": 316, "node2": 316, "TO": 316, "your_node1_nam": 316, "your_node2_nam": 316, "resnet50_fp32_pretrained_model": 316, "nc_resnet50_v1": 316, "resnet": [316, 345], "2x": [317, 323], "exchang": 318, "hope": 318, "inc_model": [318, 330], "fp32_onnx_config": 318, "verifi": [318, 326], "vgg16": [318, 345], "mobilenet": [318, 341, 345], "rcnn": 318, "unsupport": [318, 328, 334], "add_relu": 318, "conv1d_relu": 318, "conv2d_relu": 318, "group_norm": 318, "hardswish": 318, "instance_norm": 318, "layer_norm": 318, "leaky_relu": 318, "sigmoid": 318, "toolchain": [319, 335], "sudo": 319, "apt": [319, 324], "python3": 319, "dev": 319, "distutil": 319, "libgl1": 319, "mesa": 319, "glx": 319, "libglib2": 319, "wget": 319, "ln": 319, "sf": 319, "usr": 319, "incompat": 319, "88": [319, 341, 345], "80": [319, 326, 337, 345], "pyobject": 319, "reinstal": 319, "libgl": 319, "yum": [319, 324], "opencv": 319, "conda": [319, 340], "pend": 319, "sqlalchemi": 319, "27": [319, 326, 345], "alemb": 319, "forg": 319, "3x": 319, "docker": 319, "tbb": 319, "requirements_pt": [319, 324], "ld_library_path": 319, "lib": 319, "syntax": 320, "go": [320, 339, 343], "up1": 320, "up2": 320, "valid_mixed_precis": 320, "addn": 320, "grappler_optim": 320, "constfold": 320, "arithmet": 320, "debug_stripp": 320, "neo": [321, 345], "especi": 321, "benefit": [321, 333], "custom_metr": 322, "420": 323, "geomean": 323, "coder": [323, 335], "gui": [323, 334], "upload": 323, "qintegerop": [323, 336], "lock": [323, 333, 334], "momentum": [323, 328, 334], "sensit": [323, 334], "lasso": [323, 334], "satisfi": 324, "success": 324, "frequent": 324, "pypi": 324, "requirements_tf": 324, "consolid": 324, "streamlin": [324, 335], "scienc": 324, "websit": 324, "anaconda": 324, "suit": 324, "skylak": 324, "cascad": 324, "ic": [324, 335], "sapphir": [324, 326], "rapid": [324, 326], "hbm": 324, "meteor": 324, "arctic": 324, "sound": 324, "pont": 324, "vecchio": 324, "cento": [324, 345], "ubuntu": 324, "22": [324, 326, 345], "maco": 324, "ventura": 324, "fortensorflow": 324, "forpytorch": 324, "18": [324, 326, 335, 345], "apach": 325, "subject": 325, "accompani": [325, 344], "wish": 325, "bibtex": 325, "author": 325, "feng": 325, "tian": 325, "hanwen": 325, "haihao": [325, 334], "shen": [325, 334], "suyu": 325, "chen": 325, "howpublish": 325, "year": 325, "logo": 325, "atom": 325, "phi": 325, "pentium": 325, "vtune": 325, "corpor": 325, "subsidiari": 325, "brand": 325, "claim": 325, "wip": 326, "70b": [326, 345], "40b": 326, "baichuan": 326, "baichuan2": 326, "12b": 326, "neox": [326, 345], "20b": [326, 345], "mistralai": 326, "mistral": 326, "thudm": 326, "chatglm2": 326, "chatglm3": 326, "soon": 326, "lambada_openai": [326, 345], "67": [326, 345], "86": [326, 345], "0043": 326, "55": [326, 345], "9997": 326, "46": [326, 345], "9984": [326, 345], "51": [326, 345], "75": [326, 334, 345], "0559": 326, "0008": [326, 345], "9992": 326, "70": [326, 345], "9911": 326, "9976": 326, "61": [326, 345], "9991": 326, "68": [326, 343, 345], "0061": 326, "9928": 326, "97": [326, 328, 345], "0352": 326, "9972": 326, "00": [326, 345], "0142": 326, "35": [326, 334, 345], "63": [326, 334, 345], "92": [326, 345], "9933": [326, 345], "31": [326, 345], "9955": 326, "9994": [326, 345], "9988": 326, "40": [326, 345], "9867": 326, "29": [326, 345], "9975": 326, "9907": 326, "58": [326, 345], "12": [326, 345], "0040": 326, "0021": 326, "49": [326, 345], "0003": [326, 345], "53": [326, 345], "0006": [326, 345], "82": [326, 345], "0046": [326, 345], "43": [326, 345], "76": [326, 345], "77": [326, 345], "0016": 326, "96": [326, 345], "0025": 326, "79": [326, 345], "9986": 326, "62": [326, 345], "0051": 326, "73": [326, 345], "9945": [326, 345], "9987": 326, "37": [326, 345], "9930": 326, "9989": 326, "9957": [326, 345], "09": [326, 345], "03": [326, 345], "9990": 326, "9915": 326, "26": [326, 345], "0005": 326, "9995": 326, "0097": 326, "74": [326, 345], "0201": 326, "popularli": 327, "industri": [327, 335], "label_map": 327, "ap": 327, "curv": 327, "turn": [327, 337], "target_boxes_num": 327, "str_label": 327, "int_label": 327, "inturn": 327, "cocomap": 327, "vocmap": 327, "categor": 327, "multiclass": 327, "multilabel": 327, "newmetr": 327, "reset": 327, "reflect": [327, 343], "new_metr": 327, "upgrad": 328, "kind": 328, "resort": 328, "automodelforsequenceclassif": 328, "autotoken": 328, "worker": [328, 336], "ping_memori": [328, 336], "formul": 328, "templat": [328, 334], "effort": 328, "written": 328, "onnxrt_integ": 328, "onnxrt_qlinear": 328, "image_tensor": 328, "post_training_static_qu": [328, 344], "post_training_dynamic_qu": [328, 344], "1000": 328, "2000": 328, "sampling_s": 328, "model_wis": 328, "op_dict": 328, "op_wis": 328, "sigopt_api_token": [328, 341, 344], "sigopt_project_id": [328, 341, 344], "sigopt_experiment_nam": [328, 341, 344], "600": [328, 345], "training_arg": 328, "trainer": 328, "compact": [328, 334], "maxim": [328, 334, 344], "pruning_func": 328, "num_train_epoch": [328, 334], "train_dataload": [328, 334, 336], "n_gpu": 328, "gradient_accumulation_step": 328, "clip_grad_norm_": 328, "max_grad_norm": 328, "start_epoch": 328, "end_epoch": 328, "pruner": [328, 334], "newli": [328, 334], "on_after_optimizer_step": [328, 334], "layer3": [328, 334], "layer2": [328, 334, 336], "1x1": [328, 334], "expens": [328, 344], "mobil": [328, 345], "knowledgedistillationloss": 328, "weight_decai": 328, "0004": 328, "nesterov": 328, "randomresizedcrop": [328, 343], "totensor": [328, 343], "485": 328, "456": 328, "406": [328, 345], "nepoch": 328, "cnt": 328, "loss_sum": 328, "iter_bar": 328, "tqdm": 328, "desc": 328, "teacher_logit": 328, "pytorchknowledgedistillationloss": 328, "unnecessari": 328, "train_fun": 328, "training_func": 328, "output_model": 328, "exit_polici": 328, "determinist": 328, "meaning": [328, 333], "prune_conf": 328, "quantization_aware_training_conf": 328, "aforement": 328, "inset": 328, "p_conf": [328, 333], "ssd_mobilenet_v1": 328, "benchmarkconf": 328, "cpuexecutionprovid": [329, 336], "tensorrtexecutionprovid": [329, 336], "cudaexecutionprovid": [329, 336], "dnnlexecutionprovid": [329, 336], "plu": 329, "helloworld": [329, 343], "persist": 330, "tf1": 330, "tf2": 330, "h5": 330, "hybridblock": 330, "0000": 330, "input_model": 330, "10005": [331, 337], "multi_object": 332, "simultan": 333, "gain": [333, 335], "instanti": 333, "neuron": 334, "art": 334, "grown": 334, "unpreced": 334, "increasingli": 334, "stand": [334, 344], "delet": 334, "consecut": 334, "commonli": 334, "shrink": 334, "influenc": 334, "contextu": 334, "vari": [334, 342, 345], "scene": 334, "haven": 334, "lowest": [334, 344], "interv": 334, "gradual": 334, "emsp": 334, "immedi": 334, "pure": 334, "downstream": 334, "simplifi": [334, 335], "procedur": [334, 344], "prone": 334, "co": 334, "discourag": 334, "connect": [334, 341], "penal": 334, "parameter": 334, "sparsegpt": 334, "perceptron": 334, "valuabl": 334, "basi": 334, "mha": 334, "billion": 334, "tend": 334, "exemplifi": 334, "250": 334, "fortieth": 334, "pruner2": 334, "prepare_prun": 334, "retrain_fre": 334, "300": 334, "few": [334, 335, 342, 344], "yourself": 334, "uncertain": 334, "parse_auto_slim_config": 334, "auto_config": 334, "ffn2_sparsiti": 334, "mha_spars": 334, "itself": 334, "quit": 334, "pruning_pattern": 334, "pruning_start": 334, "pruning_end": 334, "sparse_gpt": 334, "embed_out": 334, "readi": 334, "hesit": 334, "clm": 334, "sst": [334, 345], "25": [334, 345], "v": [334, 344], "flan": 334, "t5": 334, "english": 334, "romanian": 334, "404": [334, 345], "381": 334, "yolov5": 334, "2x1": [334, 345], "801": 334, "7895": 334, "reduct": [334, 337], "xgboost": 334, "namhoon": 334, "lee": 334, "thalaiyasingam": 334, "ajanthan": 334, "philip": 334, "torr": 334, "2019": 334, "zafrir": 334, "ofir": 334, "ariel": 334, "larei": 334, "boudoukh": 334, "mosh": 334, "wasserblat": 334, "2111": 334, "05754": 334, "2021": 334, "kwon": 334, "kim": 334, "mahonei": 334, "hassoun": 334, "keutzer": 334, "gholami": 334, "pp": 334, "24101": 334, "24116": 334, "alistarh": 334, "massiv": 334, "2301": 334, "00774": 334, "oct": 335, "medium": 335, "diagnosi": 335, "insight": [335, 340, 344], "aug": 335, "juli": 335, "onnxcommunitymeetup2023": 335, "msft": 335, "autom": [335, 342], "netflix": 335, "mlperf": [335, 345], "5x": 335, "\u96c6\u6210\u82f1\u7279\u5c14": 335, "\u817e\u8baf\u4e91taco": 335, "kit\u4e3aai\u5e94\u7528\u5e26\u6765\u9ad8\u6548\u5f02\u6784\u52a0\u901f\u670d\u52a1": 335, "mar": 335, "heterogen": 335, "jan": 335, "busi": 335, "innov": 335, "journei": 335, "dec": 335, "mleffici": 335, "deepen": 335, "foundat": 335, "intellig": 335, "vmware": 335, "applianc": 335, "bitnami": 335, "nov": 335, "sota": 335, "neurip": 335, "quala": 335, "minilm": [335, 345], "plug": 335, "twitter": 335, "linkedin": 335, "zone": 335, "land": 335, "gcp": 335, "aw": [335, 345], "pat": 335, "keynot": 335, "intelon": 335, "chines": 335, "purif": 335, "jun": 335, "partner": 335, "democrat": 335, "feb": 335, "joint": 335, "bilibili": 335, "gestalt": 335, "ml": 335, "spars": 335, "easier": 335, "youtub": 335, "abound": 335, "lpot": [335, 340], "nextplatform": 335, "cern": 335, "gan": 335, "3dgan": 335, "iml": 335, "workshop": 335, "asplo": 335, "convolut": 335, "intelcaff": 335, "neither": 336, "nor": 336, "val_load": 336, "avg": 336, "themselv": 336, "dmlexecutionprovid": 336, "yet": 336, "meanwhil": 337, "substanti": 337, "constrain": 337, "ouput_dir": 337, "fp32_model_path": 337, "int8_model_path": 337, "ON": 338, "postposttrainingquantconfig": 338, "datatyp": [338, 344, 345], "matter": 338, "bf16wrapper": 338, "retrac": 338, "enable_mse_search": 339, "805": 339, "005": 339, "enable_auto_scal": 339, "pad_max_length": 339, "true_sequenti": 339, "slower": 339, "sym_full_rang": 339, "qweight_config_path": 339, "gptq_config_path": 339, "gptq_config": 339, "re": 339, "use_full_length": 339, "compressed_model": 339, "rtn_g32asym": 339, "gptq_g32asym": 339, "gptq_g32asym_disable_last_matmul": 339, "gptq_g128asym": 339, "awq_g32asym": 339, "site": 340, "inspect": 340, "sed": 340, "your_script": 340, "backbon": 341, "fill": [341, 343, 344], "sigopt_experiment_id": 341, "nc": [341, 344], "login": 341, "although": 341, "suffici": 341, "ordinari": 341, "receiv": 341, "latenc": [341, 344], "durat": 341, "8266": 341, "8372": 341, "2132": 341, "7495": 341, "8299": 341, "8294": 341, "0837": 341, "8291": 341, "4469": 341, "allevi": 342, "herebi": 342, "optdecoderlay": 342, "blockwis": 342, "accordingli": 342, "waq": 342, "hardtanh": 342, "t5norm": 342, "llamanorm": 342, "groupnorm": 342, "7392": [342, 345], "7335": 342, "7058": [342, 345], "6994": 342, "7677": [342, 345], "7615": [342, 345], "7332": 342, "7632": 342, "arang": 342, "tolist": 342, "default_alpha": 342, "step_siz": 342, "jason": 342, "transact": 342, "ensp": 343, "centercrop": 343, "randomcrop": 343, "cropres": 343, "decodeimag": 343, "jpeg": 343, "encodejp": 343, "alignimagechannel": 343, "116": 343, "78": [343, 345], "103": [343, 345], "94": [343, 345], "017": 343, "bilinearimagenet": 343, "topilimag": 343, "padding_mod": 343, "border": 343, "pixel": 343, "edg": 343, "colorjitt": 343, "bright": 343, "contrast": 343, "satur": 343, "hue": 343, "jitter": 343, "tondarrai": 343, "o1": 344, "aggress": 344, "flowchart": 344, "htmllabel": 344, "td": 344, "classdef": 344, "itemstyl": 344, "cce5ff": 344, "stroke": 344, "99ccff": 344, "s1": 344, "s2": 344, "s3": 344, "s4": 344, "s5": 344, "s6": 344, "s7": 344, "nbsp": [344, 345], "subgraphstyl": 344, "ffffff": 344, "attempt": 344, "post_training_auto_qu": 344, "increment": 344, "ii": 344, "highest": 344, "confidence_batch": 344, "spent": 344, "hawq_v2_loss": 344, "model_loss": 344, "black": 344, "discret": 344, "compli": 344, "posterior": 344, "short": 344, "loglevel": 344, "endlessli": 344, "perspect": 344, "smbo": 344, "appl": 344, "surrog": 344, "repeat": 344, "densiti": 344, "parzen": 344, "greatest": 344, "hour": 344, "dai": 344, "next_tune_cfg": 344, "overridden": 344, "cluster": 344, "mpi": 344, "replic": 344, "replica": 344, "resourc": 344, "mpirun": 344, "number_of_process": 344, "run_cmd": 344, "abctunestrategi": 344, "1x": 345, "platinum": 345, "8480": 345, "8ghz": 345, "56": 345, "ht": 345, "turbo": 345, "256gb": 345, "16x16gb": 345, "ddr5": 345, "4800": 345, "mt": 345, "bio": 345, "3a14": 345, "tel2p1": 345, "microcod": 345, "0x2b0001b0": 345, "gcc": 345, "20210514": 345, "red": 345, "hat": 345, "visit": 345, "1s4c14ins1bsthroughput": 345, "1720": 345, "582": 345, "95x": 345, "1517": 345, "38": 345, "570": 345, "65": 345, "66x": 345, "resnet101": 345, "52": 345, "41": 345, "1058": 345, "382": 345, "77x": 345, "incept": 345, "69": 345, "2080": 345, "951": 345, "19x": 345, "1587": 345, "863": 345, "84x": 345, "1052": 345, "434": 345, "42x": 345, "v4": 345, "707": 345, "234": 345, "02x": 345, "320": 345, "179": 345, "79x": 345, "4312": 345, "1512": 345, "85x": 345, "2287": 345, "1406": 345, "63x": 345, "1367": 345, "59x": 345, "vgg19": 345, "1244": 345, "176": 345, "04x": 345, "resnetv2": 345, "780": 345, "34x": 345, "494": 345, "329": 345, "50x": 345, "152": 345, "349": 345, "235": 345, "48x": 345, "densenet": 345, "161": 345, "282": 345, "223": 345, "19": 345, "26x": 345, "1284": 345, "756": 345, "70x": 345, "1280": 345, "530": 345, "cnn": 345, "39": 345, "178": 345, "13x": 345, "yolov3": 345, "249": 345, "44": 345, "64x": 345, "54": 345, "28x": 345, "36": 345, "05x": 345, "390": 345, "212": 345, "83x": 345, "vit": 345, "81": 345, "230": 345, "142": 345, "62x": 345, "1989": 345, "31x": 345, "1165": 345, "303": 345, "953": 345, "302": 345, "15x": 345, "resnest50": 345, "365": 345, "66": 345, "21x": 345, "resnext101_32x8d": 345, "548": 345, "104": 345, "27x": 345, "efficientnet_b0": 345, "636": 345, "566": 345, "12x": 345, "efficientnet_b3": 345, "471": 345, "358": 345, "32x": 345, "peleenet": 345, "790": 345, "504": 345, "57x": 345, "yolo": 345, "137": 345, "88x": 345, "175": 345, "23x": 345, "camembert": 345, "393": 345, "174": 345, "783": 345, "344": 345, "684": 345, "99x": 345, "albert": 345, "312": 345, "155": 345, "60": 345, "01x": 345, "funnel": 345, "281": 345, "395": 345, "173": 345, "373": 345, "405": 345, "30x": 345, "stsb": 345, "396": 345, "136": 345, "377": 345, "17x": 345, "391": 345, "25x": 345, "135": 345, "61x": 345, "117": 345, "93x": 345, "lvwerra": 345, "pegasu": 345, "samsum": 345, "1981": 345, "598": 345, "1095": 345, "298": 345, "67x": 345, "549": 345, "29x": 345, "375": 345, "hellaswag": 345, "winogrand": 345, "piqa": 345, "wikitext": 345, "word_perplex": 345, "4954": 345, "6409": 345, "7541": 345, "6434": 345, "8816": 345, "gptqw4g128asym": 345, "679": 345, "4895": 345, "6433": 345, "7476": 345, "6399": 345, "0999": 345, "gptqw4g32asym": 345, "6829": 345, "4923": 345, "6401": 345, "7486": 345, "6410": 345, "9963": 345, "0141": 345, "gptqw4g128sym": 345, "685": 345, "4907": 345, "6361": 345, "7443": 345, "6390": 345, "9932": 345, "1498": 345, "gptqw4g32sym": 345, "6911": 345, "4899": 345, "6448": 345, "7497": 345, "6439": 345, "0927": 345, "5049": 345, "6543": 345, "7628": 345, "6497": 345, "2862": 345, "4984": 345, "6535": 345, "7568": 345, "6473": 345, "9962": 345, "4193": 345, "6885": 345, "4973": 345, "753": 345, "6455": 345, "9935": 345, "4607": 345, "decapoda": 345, "5642": 345, "6709": 345, "7835": 345, "6887": 345, "4202": 345, "7244": 345, "5603": 345, "6614": 345, "6824": 345, "9909": 345, "5881": 345, "5911": 345, "7009": 345, "7878": 345, "7106": 345, "7518": 345, "5843": 345, "6961": 345, "7911": 345, "4319": 345, "7572": 345, "5898": 345, "7056": 345, "7894": 345, "7105": 345, "9998": 345, "3429": 345, "7596": 345, "5841": 345, "6977": 345, "7905": 345, "7080": 345, "4916": 345, "6266": 345, "7277": 345, "8096": 345, "7350": 345, "2384": 345, "778": 345, "624": 345, "7269": 345, "8047": 345, "7334": 345, "9979": 345, "4237": 345, "7706": 345, "6239": 345, "7285": 345, "8058": 345, "7322": 345, "4697": 345, "7836": 345, "6195": 345, "7337": 345, "9983": 345, "5604": 345, "5732": 345, "648": 345, "7715": 345, "6746": 345, "7107": 345, "6982": 345, "5637": 345, "6527": 345, "7704": 345, "6713": 345, "9950": 345, "9702": 345, "5682": 345, "6575": 345, "7758": 345, "6742": 345, "9317": 345, "567": 345, "6902": 345, "7353": 345, "6622": 345, "7829": 345, "6862": 345, "9942": 345, "9635": 345, "7246": 345, "5617": 345, "6756": 345, "7797": 345, "6854": 345, "9931": 345, "2799": 345, "7312": 345, "6059": 345, "7103": 345, "7077": 345, "2213": 345, "7273": 345, "6018": 345, "7088": 345, "7742": 345, "7030": 345, "9934": 345, "2538": 345, "083": 345, "7283": 345, "6053": 345, "7024": 345, "7764": 345, "7031": 345, "1889": 345, "374": 345, "727": 345, "5997": 345, "7018": 345, "9916": 345, "2504": 345, "497": 345, "7122": 345, "8984": 345, "5933": 345, "689": 345, "7851": 345, "7075": 345, "1556": 345, "448": 345, "7675": 345, "5934": 345, "7856": 345, "7111": 345, "1514": 345, "927": 345, "7566": 345, "5899": 345, "7032": 345, "9953": 345, "1374": 345, "728": 345, "4628": 345, "6456": 345, "6029": 345, "6438": 345, "5799": 345, "4542": 345, "6004": 345, "0626": 345, "4789": 345, "6134": 345, "7432": 345, "5525": 345, "4731": 345, "6504": 345, "7617": 345, "6094": 345, "7828": 345, "5098": 345, "7622": 345, "6505": 345, "3242": 345, "6878": 345, "5058": 345, "6393": 345, "7633": 345, "6491": 345, "9978": 345, "5514": 345, "6864": 345, "5084": 345, "6519": 345, "6509": 345, "4728": 345, "6876": 345, "5045": 345, "6474": 345, "9952": 345, "6379": 345, "5282": 345, "614": 345, "7448": 345, "6312": 345, "6377": 345, "5228": 345, "5991": 345, "6261": 345, "9919": 345, "4096": 345, "6224": 345, "4271": 345, "577": 345, "722": 345, "5871": 345, "9359": 345, "6123": 345, "4227": 345, "5738": 345, "7203": 345, "5823": 345, "9917": 345, "3377": 345, "615": 345, "4259": 345, "5714": 345, "7247": 345, "9951": 345, "2083": 345, "6154": 345, "4208": 345, "5777": 345, "7198": 345, "5834": 345, "9937": 345, "3121": 345, "7233": 345, "5359": 345, "7753": 345, "195": 345, "7186": 345, "5328": 345, "7699": 345, "6687": 345, "9922": 345, "3463": 345, "7268": 345, "533": 345, "659": 345, "6726": 345, "2897": 345, "5718": 345, "6859": 345, "7927": 345, "6890": 345, "9324": 345, "7006": 345, "5655": 345, "6803": 345, "7965": 345, "6857": 345, "1515": 345, "5752": 345, "6748": 345, "7845": 345, "6724": 345, "5951": 345, "6472": 345, "5716": 345, "6685": 345, "784": 345, "6678": 345, "8539": 345, "6918": 345, "5819": 345, "678": 345, "6861": 345, "8863": 345, "5765": 345, "6827": 345, "7873": 345, "6832": 345, "9958": 345, "1451": 345, "storywrit": 345, "693": 345, "5477": 345, "663": 345, "6719": 345, "9125": 345, "6661": 345, "7813": 345, "6693": 345, "9961": 345, "1137": 345, "rw": 345, "6604": 345, "5419": 345, "6598": 345, "6594": 345, "7616": 345, "6484": 345, "5369": 345, "7807": 345, "6559": 345, "9947": 345, "9411": 345, "6571": 345, "5398": 345, "6582": 345, "6579": 345, "8809": 345, "652": 345, "535": 345, "7682": 345, "6532": 345, "9906": 345, "0048": 345, "5177": 345, "6669": 345, "7824": 345, "5053": 345, "6301": 345, "5142": 345, "6654": 345, "6483": 345, "8146": 345, "517": 345, "6488": 345, "9941": 345, "1666": 345, "734": 345, "1658": 345, "1495": 345, "733": 345, "1661": 345, "732": 345, "1713": 345, "767": 345, "1747": 345, "770": 345, "7519": 345, "4430": 345, "4413": 345, "72x": 345, "7190": 345, "4019": 345, "613": 345, "170": 345, "611": 345, "186": 345, "619": 345, "184": 345, "36x": 345, "623": 345, "5711": 345, "2584": 345, "6136": 345, "2630": 345, "33x": 345, "shufflenet": 345, "6820": 345, "3686": 345, "googlenet": 345, "1971": 345, "1120": 345, "76x": 345, "1838": 345, "1142": 345, "squeezenet": 345, "10163": 345, "5771": 345, "10339": 345, "6002": 345, "caffenet": 345, "2805": 345, "1077": 345, "60x": 345, "4351": 345, "822": 345, "alexnet": 345, "2169": 345, "893": 345, "06": 345, "43x": 345, "2232": 345, "841": 345, "65x": 345, "zfnet": 345, "921": 345, "525": 345, "75x": 345, "925": 345, "534": 345, "73x": 345, "1862": 345, "1161": 345, "1956": 345, "1262": 345, "55x": 345, "efficientnet": 345, "2793": 345, "1383": 345, "beit": 345, "206": 345, "91x": 345, "duc": 345, "74x": 345, "8780": 345, "1920": 345, "emot": 345, "ferplu": 345, "6360": 345, "3067": 345, "07x": 345, "arcfac": 345, "449": 345, "511": 345, "484": 345, "222": 345, "18x": 345, "integerop": 345, "635": 345, "1324": 345, "244": 345, "47x": 345, "440": 345, "214": 345, "06x": 345, "715": 345, "201": 345, "03x": 345, "714": 345, "213": 345, "339": 345, "58x": 345, "215": 345, "89x": 345, "712": 345, "217": 345, "l12": 345, "h384": 345, "1209": 345, "588": 345, "1268": 345, "16x": 345, "1253": 345, "399": 345, "14x": 345, "l6": 345, "1139": 345, "94x": 345, "2365": 345, "08x": 345, "718": 345, "35x": 345, "electra": 345, "discrimin": 345, "1951": 345, "71x": 345, "2198": 345, "1129": 345, "mini": 345, "5814": 345, "3388": 345, "6396": 345, "3445": 345, "86x": 345, "bart": 345, "126": 345, "spanbert": 345, "multilingu": 345, "82x": 345, "118": 345, "46x": 345, "layoutlmv3": 345, "funsd": 345, "layoutlmv2": 345, "perplex": 345, "2788": 345, "7002": 345, "4124": 345, "9921": 345, "3950": 345, "9892": 345, "9163": 345, "7240": 345, "9902": 345, "0438": 345, "7634": 345, "1186": 345, "9944": 345, "1276": 345, "7543": 345, "6181": 345, "rtnw4g32asym": 345, "6496": 345, "9967": 345, "7964": 345, "6612": 345, "rtnw4g32sym": 345, "7941": 345, "7243": 345, "9971": 345, "taskdataset": 345, "accuracyspars": 345, "ratiospars": 345, "commentsbalancedor": 345, "unbalanc": 345, "answeringsquad": 345, "87f1": 345, "momentumunbalanc": 345, "momentumbalanc": 345, "90f1": 345, "59f1": 345, "23f1": 345, "classificationmrpc": 345, "52f1": 345, "26f1": 345, "classificationsst": 345, "61accuraci": 345, "recognitionimagenet": 345, "95top1": 345, "v5s6": 345, "detectioncoco": 345, "ap0": 345, "6ap0": 345, "584": 345, "34f1": 345, "lassounbalanc": 345, "classificationmnli": 345, "mm": 345, "allbalanc": 345, "32accuraci": 345, "sensitivitybalanc": 345, "classificationqqp": 345, "classificationqnli": 345, "54accuraci": 345, "em": 345, "mobilenetv2": 345, "wideresnet40": 345, "9522": 345, "8178": 345, "0213": 345, "8235": 345, "027": 345, "5494": 345, "7153": 345, "5540": 345, "5523": 345, "vgg": 345, "bn": 345, "7022": 345, "7415": 345, "7025": 345, "6739": 345, "7399": 345, "6845": 345, "0106": 345, "blendcnn": 345, "7034": 345, "8382": 345, "bilstm": 345, "8314": 345, "9403": 345, "9048": 345, "0734": 345, "7323": 345, "8256": 345, "8084": 345, "8814": 345, "7442": 345, "8371": 345, "0119": 345, "0115": 345, "tinybert": 345, "8018": 345, "8044": 345, "8363": 345, "8411": 345, "8025": 345, "8074": 345, "0007": 345, "0030": 345, "8626": 345, "8213": 345, "9091": 345, "8782": 345, "8684": 345, "8259": 345, "0058": 345, "distilroberta": 345, "6057": 345, "6187": 345, "0130": 345, "c6i": 345, "2xlarg": 345, "c6a": 345, "c6g": 345, "a100cuda": 345, "executionprovid": 345}, "objects": {"": [[38, 0, 0, "-", "neural_compressor"]], "neural_compressor": [[2, 0, 0, "-", "algorithm"], [5, 0, 0, "-", "benchmark"], [9, 0, 0, "-", "common"], [16, 0, 0, "-", "config"], [17, 0, 0, "-", "contrib"], [32, 0, 0, "-", "data"], [45, 0, 0, "-", "metric"], [47, 0, 0, "-", "mix_precision"], [49, 0, 0, "-", "model"], [57, 0, 0, "-", "objective"], [58, 0, 0, "-", "profiling"], [59, 0, 0, "-", "quantization"], [67, 0, 0, "-", "strategy"], [86, 0, 0, "-", "tensorflow"], [231, 0, 0, "-", "torch"], [243, 0, 0, "-", "training"], [251, 0, 0, "-", "utils"], [259, 0, 0, "-", "version"]], "neural_compressor.algorithm": [[0, 0, 0, "-", "algorithm"], [1, 0, 0, "-", "fast_bias_correction"], [3, 0, 0, "-", "smooth_quant"], [4, 0, 0, "-", "weight_correction"]], "neural_compressor.algorithm.algorithm": [[0, 1, 1, "", "ALGORITHMS"], [0, 1, 1, "", "Algorithm"], [0, 1, 1, "", "AlgorithmScheduler"], [0, 2, 1, "", "algorithm_registry"]], "neural_compressor.algorithm.fast_bias_correction": [[1, 1, 1, "", "FastBiasCorrection"]], "neural_compressor.algorithm.smooth_quant": [[3, 1, 1, "", "SmoothQuant"]], "neural_compressor.algorithm.weight_correction": [[4, 1, 1, "", "WeightCorrection"]], "neural_compressor.benchmark": [[5, 2, 1, "", "benchmark_with_raw_cmd"], [5, 2, 1, "", "call_one"], [5, 2, 1, "", "config_instance"], [5, 2, 1, "", "fit"], [5, 2, 1, "", "generate_prefix"], [5, 2, 1, "", "get_architecture"], [5, 2, 1, "", "get_bounded_threads"], [5, 2, 1, "", "get_core_ids"], [5, 2, 1, "", "get_physical_ids"], [5, 2, 1, "", "get_threads"], [5, 2, 1, "", "get_threads_per_core"], [5, 2, 1, "", "profile"], [5, 2, 1, "", "run_instance"], [5, 2, 1, "", "set_all_env_var"], [5, 2, 1, "", "set_env_var"], [5, 2, 1, "", "summary_benchmark"]], "neural_compressor.common": [[6, 0, 0, "-", "base_config"], [7, 0, 0, "-", "base_tuning"], [8, 0, 0, "-", "benchmark"], [10, 0, 0, "-", "tuning_param"], [12, 0, 0, "-", "utils"]], "neural_compressor.common.base_config": [[6, 1, 1, "", "BaseConfig"], [6, 1, 1, "", "ComposableConfig"], [6, 1, 1, "", "ConfigRegistry"], [6, 2, 1, "", "get_all_config_set_from_config_registry"], [6, 2, 1, "", "register_config"], [6, 2, 1, "", "register_supported_configs_for_fwk"]], "neural_compressor.common.base_config.BaseConfig": [[6, 3, 1, "", "name"], [6, 3, 1, "", "params_list"]], "neural_compressor.common.base_config.ComposableConfig": [[6, 3, 1, "", "config_list"]], "neural_compressor.common.base_tuning": [[7, 1, 1, "", "ConfigLoader"], [7, 1, 1, "", "ConfigSet"], [7, 1, 1, "", "EvaluationFuncWrapper"], [7, 1, 1, "", "Evaluator"], [7, 1, 1, "", "Sampler"], [7, 1, 1, "", "SequentialSampler"], [7, 1, 1, "", "TuningConfig"], [7, 1, 1, "", "TuningMonitor"], [7, 2, 1, "", "init_tuning"]], "neural_compressor.common.base_tuning.ConfigSet": [[7, 3, 1, "", "config_list"]], "neural_compressor.common.benchmark": [[8, 2, 1, "", "benchmark"], [8, 2, 1, "", "dump_numa_info"], [8, 2, 1, "", "format_list2str"], [8, 2, 1, "", "generate_prefix"], [8, 2, 1, "", "get_linux_numa_info"], [8, 2, 1, "", "get_numa_node"], [8, 2, 1, "", "get_reversed_numa_info"], [8, 2, 1, "", "get_windows_numa_info"], [8, 2, 1, "", "parse_str2list"], [8, 2, 1, "", "run_multi_instance_command"], [8, 2, 1, "", "set_cores_for_instance"], [8, 2, 1, "", "summary_latency_throughput"]], "neural_compressor.common.tuning_param": [[10, 1, 1, "", "ParamLevel"], [10, 1, 1, "", "TuningParam"]], "neural_compressor.common.tuning_param.ParamLevel": [[10, 3, 1, "", "MODEL_LEVEL"], [10, 3, 1, "", "OP_LEVEL"], [10, 3, 1, "", "OP_TYPE_LEVEL"]], "neural_compressor.common.utils": [[11, 0, 0, "-", "constants"], [13, 0, 0, "-", "logger"], [14, 0, 0, "-", "save_load"], [15, 0, 0, "-", "utility"]], "neural_compressor.common.utils.constants": [[11, 1, 1, "", "Mode"]], "neural_compressor.common.utils.logger": [[13, 1, 1, "", "Logger"], [13, 1, 1, "", "TuningLogger"]], "neural_compressor.common.utils.save_load": [[14, 2, 1, "", "load_config_mapping"], [14, 2, 1, "", "save_config_mapping"]], "neural_compressor.common.utils.utility": [[15, 1, 1, "", "CpuInfo"], [15, 1, 1, "", "LazyImport"], [15, 1, 1, "", "ProcessorType"], [15, 1, 1, "", "Statistics"], [15, 2, 1, "", "call_counter"], [15, 2, 1, "", "detect_processor_type_based_on_hw"], [15, 2, 1, "", "dump_elapsed_time"], [15, 2, 1, "", "get_workspace"], [15, 2, 1, "", "log_process"], [15, 2, 1, "", "set_random_seed"], [15, 2, 1, "", "set_resume_from"], [15, 2, 1, "", "set_tensorboard"], [15, 2, 1, "", "set_workspace"], [15, 2, 1, "", "singleton"]], "neural_compressor.config": [[16, 1, 1, "", "AccuracyCriterion"], [16, 1, 1, "", "BenchmarkConfig"], [16, 1, 1, "", "DistillationConfig"], [16, 1, 1, "", "DotDict"], [16, 1, 1, "", "ExportConfig"], [16, 1, 1, "", "HPOConfig"], [16, 1, 1, "", "IntermediateLayersKnowledgeDistillationLossConfig"], [16, 1, 1, "", "Keras"], [16, 1, 1, "", "KnowledgeDistillationLossConfig"], [16, 1, 1, "", "MXNet"], [16, 1, 1, "", "MixedPrecisionConfig"], [16, 1, 1, "", "NASConfig"], [16, 1, 1, "", "ONNX"], [16, 1, 1, "", "ONNXQlinear2QDQConfig"], [16, 1, 1, "", "Options"], [16, 1, 1, "", "PostTrainingQuantConfig"], [16, 1, 1, "", "PyTorch"], [16, 1, 1, "", "QuantizationAwareTrainingConfig"], [16, 1, 1, "", "SelfKnowledgeDistillationLossConfig"], [16, 1, 1, "", "TF2ONNXConfig"], [16, 1, 1, "", "TensorFlow"], [16, 1, 1, "", "Torch2ONNXConfig"], [16, 1, 1, "", "TuningCriterion"], [16, 1, 1, "", "WeightPruningConfig"]], "neural_compressor.contrib": [[18, 0, 0, "-", "strategy"]], "neural_compressor.contrib.strategy": [[19, 0, 0, "-", "sigopt"], [20, 0, 0, "-", "tpe"]], "neural_compressor.contrib.strategy.sigopt": [[19, 1, 1, "", "SigOptTuneStrategy"]], "neural_compressor.contrib.strategy.tpe": [[20, 1, 1, "", "TpeTuneStrategy"]], "neural_compressor.data": [[27, 0, 0, "-", "datasets"], [31, 0, 0, "-", "filters"], [34, 0, 0, "-", "transforms"]], "neural_compressor.data.datasets": [[21, 0, 0, "-", "bert_dataset"], [22, 0, 0, "-", "coco_dataset"], [23, 0, 0, "-", "dataset"], [24, 0, 0, "-", "dummy_dataset"], [25, 0, 0, "-", "dummy_dataset_v2"], [26, 0, 0, "-", "imagenet_dataset"], [28, 0, 0, "-", "style_transfer_dataset"]], "neural_compressor.data.datasets.bert_dataset": [[21, 1, 1, "", "InputFeatures"], [21, 1, 1, "", "ONNXRTBertDataset"], [21, 1, 1, "", "ParseDecodeBert"], [21, 1, 1, "", "PytorchBertDataset"], [21, 1, 1, "", "TensorflowBertDataset"], [21, 1, 1, "", "TensorflowModelZooBertDataset"], [21, 2, 1, "", "convert_examples_to_features"], [21, 2, 1, "", "load_and_cache_examples"]], "neural_compressor.data.datasets.coco_dataset": [[22, 1, 1, "", "COCONpy"], [22, 1, 1, "", "COCORaw"], [22, 1, 1, "", "COCORecordDataset"], [22, 1, 1, "", "ParseDecodeCoco"]], "neural_compressor.data.datasets.dataset": [[23, 1, 1, "", "CIFAR10"], [23, 1, 1, "", "CIFAR100"], [23, 1, 1, "", "Dataset"], [23, 1, 1, "", "Datasets"], [23, 1, 1, "", "FashionMNIST"], [23, 1, 1, "", "ImageFolder"], [23, 1, 1, "", "IterableDataset"], [23, 1, 1, "", "MNIST"], [23, 1, 1, "", "MXNetCIFAR10"], [23, 1, 1, "", "MXNetCIFAR100"], [23, 1, 1, "", "MXNetDatasets"], [23, 1, 1, "", "MXNetFashionMNIST"], [23, 1, 1, "", "MXNetImageFolder"], [23, 1, 1, "", "MXNetMNIST"], [23, 1, 1, "", "ONNXRTITDatasets"], [23, 1, 1, "", "ONNXRTQLDatasets"], [23, 1, 1, "", "PyTorchDatasets"], [23, 1, 1, "", "PytorchCIFAR10"], [23, 1, 1, "", "PytorchCIFAR100"], [23, 1, 1, "", "PytorchFashionMNIST"], [23, 1, 1, "", "PytorchMNIST"], [23, 1, 1, "", "PytorchMxnetWrapDataset"], [23, 1, 1, "", "PytorchMxnetWrapFunction"], [23, 1, 1, "", "Tensorflow"], [23, 1, 1, "", "TensorflowCIFAR10"], [23, 1, 1, "", "TensorflowCIFAR100"], [23, 1, 1, "", "TensorflowDatasets"], [23, 1, 1, "", "TensorflowFashionMNIST"], [23, 1, 1, "", "TensorflowImageRecord"], [23, 1, 1, "", "TensorflowMNIST"], [23, 1, 1, "", "TensorflowTFRecordDataset"], [23, 1, 1, "", "TensorflowVOCRecord"], [23, 2, 1, "", "calculate_md5"], [23, 2, 1, "", "check_integrity"], [23, 2, 1, "", "dataset_registry"], [23, 2, 1, "", "download_url"], [23, 4, 1, "", "framework_datasets"], [23, 2, 1, "", "gen_bar_updater"]], "neural_compressor.data.datasets.dummy_dataset": [[24, 1, 1, "", "DummyDataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[25, 1, 1, "", "DummyDataset"], [25, 1, 1, "", "SparseDummyDataset"]], "neural_compressor.data.datasets.imagenet_dataset": [[26, 1, 1, "", "ImagenetRaw"], [26, 1, 1, "", "MXNetImagenetRaw"], [26, 1, 1, "", "ONNXRTImagenetDataset"], [26, 1, 1, "", "PytorchImagenetRaw"], [26, 1, 1, "", "TensorflowImagenetDataset"], [26, 1, 1, "", "TensorflowImagenetRaw"]], "neural_compressor.data.datasets.style_transfer_dataset": [[28, 1, 1, "", "StyleTransferDataset"]], "neural_compressor.data.filters": [[29, 0, 0, "-", "coco_filter"], [30, 0, 0, "-", "filter"]], "neural_compressor.data.filters.coco_filter": [[29, 1, 1, "", "LabelBalanceCOCORawFilter"], [29, 1, 1, "", "LabelBalanceCOCORecordFilter"]], "neural_compressor.data.filters.filter": [[30, 1, 1, "", "FILTERS"], [30, 1, 1, "", "Filter"], [30, 1, 1, "", "MXNetFilters"], [30, 1, 1, "", "ONNXRTITFilters"], [30, 1, 1, "", "ONNXRTQLFilters"], [30, 1, 1, "", "PyTorchFilters"], [30, 1, 1, "", "TensorflowFilters"], [30, 2, 1, "", "filter_registry"]], "neural_compressor.data.transforms": [[33, 0, 0, "-", "imagenet_transform"], [35, 0, 0, "-", "postprocess"], [36, 0, 0, "-", "tokenization"], [37, 0, 0, "-", "transform"]], "neural_compressor.data.transforms.imagenet_transform": [[33, 1, 1, "", "BilinearImagenetTransform"], [33, 1, 1, "", "LabelShift"], [33, 1, 1, "", "ONNXResizeCropImagenetTransform"], [33, 1, 1, "", "OnnxBilinearImagenetTransform"], [33, 1, 1, "", "ParseDecodeImagenet"], [33, 1, 1, "", "ParseDecodeImagenetTransform"], [33, 1, 1, "", "QuantizedInput"], [33, 1, 1, "", "ResizeWithAspectRatio"], [33, 1, 1, "", "TensorflowResizeCropImagenetTransform"], [33, 1, 1, "", "TensorflowShiftRescale"], [33, 1, 1, "", "TensorflowTransposeLastChannel"]], "neural_compressor.data.transforms.postprocess": [[35, 1, 1, "", "Postprocess"]], "neural_compressor.data.transforms.tokenization": [[36, 1, 1, "", "BasicTokenizer"], [36, 1, 1, "", "FullTokenizer"], [36, 1, 1, "", "WordpieceTokenizer"], [36, 2, 1, "", "convert_by_vocab"], [36, 2, 1, "", "convert_to_unicode"], [36, 2, 1, "", "load_vocab"], [36, 2, 1, "", "whitespace_tokenize"]], "neural_compressor.data.transforms.transform": [[37, 1, 1, "", "AlignImageChannelTransform"], [37, 1, 1, "", "BaseTransform"], [37, 1, 1, "", "CastONNXTransform"], [37, 1, 1, "", "CastPyTorchTransform"], [37, 1, 1, "", "CastTFTransform"], [37, 1, 1, "", "CenterCropTFTransform"], [37, 1, 1, "", "CenterCropTransform"], [37, 1, 1, "", "CollectTransform"], [37, 1, 1, "", "ComposeTransform"], [37, 1, 1, "", "CropResizeTFTransform"], [37, 1, 1, "", "CropResizeTransform"], [37, 1, 1, "", "CropToBoundingBox"], [37, 1, 1, "", "InputFeatures"], [37, 1, 1, "", "MXNetCropResizeTransform"], [37, 1, 1, "", "MXNetCropToBoundingBox"], [37, 1, 1, "", "MXNetNormalizeTransform"], [37, 1, 1, "", "MXNetTransforms"], [37, 1, 1, "", "MXNetTranspose"], [37, 1, 1, "", "NormalizeTFTransform"], [37, 1, 1, "", "NormalizeTransform"], [37, 1, 1, "", "ONNXRTCropToBoundingBox"], [37, 1, 1, "", "ONNXRTITTransforms"], [37, 1, 1, "", "ONNXRTQLTransforms"], [37, 1, 1, "", "PaddedCenterCropTransform"], [37, 1, 1, "", "ParseDecodeVocTransform"], [37, 1, 1, "", "PyTorchAlignImageChannel"], [37, 1, 1, "", "PyTorchCropResizeTransform"], [37, 1, 1, "", "PyTorchNormalizeTransform"], [37, 1, 1, "", "PyTorchTransforms"], [37, 1, 1, "", "PyTorchTranspose"], [37, 1, 1, "", "PytorchMxnetTransform"], [37, 1, 1, "", "PytorchMxnetWrapFunction"], [37, 1, 1, "", "RandomCropTFTransform"], [37, 1, 1, "", "RandomCropTransform"], [37, 1, 1, "", "RandomHorizontalFlip"], [37, 1, 1, "", "RandomResizedCropMXNetTransform"], [37, 1, 1, "", "RandomResizedCropPytorchTransform"], [37, 1, 1, "", "RandomResizedCropTFTransform"], [37, 1, 1, "", "RandomResizedCropTransform"], [37, 1, 1, "", "RandomVerticalFlip"], [37, 1, 1, "", "RescaleKerasPretrainTransform"], [37, 1, 1, "", "RescaleTFTransform"], [37, 1, 1, "", "RescaleTransform"], [37, 1, 1, "", "ResizeMXNetTransform"], [37, 1, 1, "", "ResizePytorchTransform"], [37, 1, 1, "", "ResizeTFTransform"], [37, 1, 1, "", "ResizeTransform"], [37, 1, 1, "", "ResizeWithRatio"], [37, 1, 1, "", "SquadExample"], [37, 1, 1, "", "TFModelZooCollectTransform"], [37, 1, 1, "", "TFSquadV1ModelZooPostTransform"], [37, 1, 1, "", "TFSquadV1PostTransform"], [37, 1, 1, "", "TRANSFORMS"], [37, 1, 1, "", "TensorflowCropToBoundingBox"], [37, 1, 1, "", "TensorflowRandomHorizontalFlip"], [37, 1, 1, "", "TensorflowRandomVerticalFlip"], [37, 1, 1, "", "TensorflowResizeWithRatio"], [37, 1, 1, "", "TensorflowTransform"], [37, 1, 1, "", "TensorflowTransforms"], [37, 1, 1, "", "TensorflowTranspose"], [37, 1, 1, "", "TensorflowWrapFunction"], [37, 1, 1, "", "ToArray"], [37, 1, 1, "", "ToNDArrayTransform"], [37, 1, 1, "", "Transforms"], [37, 1, 1, "", "Transpose"], [37, 2, 1, "", "convert_examples_to_features"], [37, 2, 1, "", "get_final_text"], [37, 2, 1, "", "get_torchvision_map"], [37, 2, 1, "", "read_squad_examples"], [37, 2, 1, "", "transform_registry"]], "neural_compressor.metric": [[39, 0, 0, "-", "bleu"], [40, 0, 0, "-", "bleu_util"], [41, 0, 0, "-", "coco_label_map"], [42, 0, 0, "-", "coco_tools"], [43, 0, 0, "-", "evaluate_squad"], [44, 0, 0, "-", "f1"], [46, 0, 0, "-", "metric"]], "neural_compressor.metric.bleu": [[39, 1, 1, "", "BLEU"], [39, 1, 1, "", "UnicodeRegex"], [39, 2, 1, "", "bleu_tokenize"]], "neural_compressor.metric.bleu.BLEU": [[39, 3, 1, "", "labels"], [39, 3, 1, "", "predictions"]], "neural_compressor.metric.bleu.UnicodeRegex": [[39, 3, 1, "", "nondigit_punct_re"], [39, 3, 1, "", "punct_nondigit_re"], [39, 3, 1, "", "symbol_re"]], "neural_compressor.metric.bleu_util": [[40, 2, 1, "", "compute_bleu"]], "neural_compressor.metric.coco_tools": [[42, 1, 1, "", "COCOEvalWrapper"], [42, 1, 1, "", "COCOWrapper"], [42, 2, 1, "", "ExportSingleImageDetectionBoxesToCoco"], [42, 2, 1, "", "ExportSingleImageDetectionMasksToCoco"], [42, 2, 1, "", "ExportSingleImageGroundtruthToCoco"]], "neural_compressor.metric.coco_tools.COCOWrapper": [[42, 3, 1, "", "dataset"], [42, 3, 1, "", "detection_type"]], "neural_compressor.metric.evaluate_squad": [[43, 2, 1, "", "evaluate"], [43, 2, 1, "", "exact_match_score"], [43, 2, 1, "", "f1_score"], [43, 2, 1, "", "metric_max_over_ground_truths"]], "neural_compressor.metric.f1": [[44, 2, 1, "", "evaluate"], [44, 2, 1, "", "f1_score"], [44, 2, 1, "", "metric_max_over_ground_truths"], [44, 2, 1, "", "normalize_answer"]], "neural_compressor.metric.metric": [[46, 1, 1, "", "Accuracy"], [46, 1, 1, "", "BaseMetric"], [46, 1, 1, "", "COCOmAPv2"], [46, 1, 1, "", "F1"], [46, 1, 1, "", "GeneralTopK"], [46, 1, 1, "", "Loss"], [46, 1, 1, "", "MAE"], [46, 1, 1, "", "METRICS"], [46, 1, 1, "", "MSE"], [46, 1, 1, "", "MXNetMetrics"], [46, 1, 1, "", "Metric"], [46, 1, 1, "", "ONNXRTGLUE"], [46, 1, 1, "", "ONNXRTITMetrics"], [46, 1, 1, "", "ONNXRTQLMetrics"], [46, 1, 1, "", "PyTorchLoss"], [46, 1, 1, "", "PyTorchMetrics"], [46, 1, 1, "", "RMSE"], [46, 1, 1, "", "ROC"], [46, 1, 1, "", "SquadF1"], [46, 1, 1, "", "TensorflowCOCOMAP"], [46, 1, 1, "", "TensorflowMAP"], [46, 1, 1, "", "TensorflowMetrics"], [46, 1, 1, "", "TensorflowTopK"], [46, 1, 1, "", "TensorflowVOCMAP"], [46, 1, 1, "", "WrapMXNetMetric"], [46, 1, 1, "", "WrapONNXRTMetric"], [46, 1, 1, "", "WrapPyTorchMetric"], [46, 1, 1, "", "mIOU"], [46, 2, 1, "", "metric_registry"], [46, 2, 1, "", "register_customer_metric"]], "neural_compressor.metric.metric.Accuracy": [[46, 3, 1, "", "label_list"], [46, 3, 1, "", "pred_list"], [46, 3, 1, "", "sample"]], "neural_compressor.metric.metric.GeneralTopK": [[46, 3, 1, "", "k"], [46, 3, 1, "", "num_correct"], [46, 3, 1, "", "num_sample"]], "neural_compressor.metric.metric.Loss": [[46, 3, 1, "", "sample"], [46, 3, 1, "", "sum"]], "neural_compressor.metric.metric.MAE": [[46, 3, 1, "", "compare_label"], [46, 3, 1, "", "label_list"], [46, 3, 1, "", "pred_list"]], "neural_compressor.metric.metric.METRICS": [[46, 3, 1, "", "metrics"]], "neural_compressor.metric.metric.MSE": [[46, 3, 1, "", "compare_label"], [46, 3, 1, "", "label_list"], [46, 3, 1, "", "pred_list"]], "neural_compressor.metric.metric.MXNetMetrics": [[46, 3, 1, "", "metrics"]], "neural_compressor.metric.metric.ONNXRTITMetrics": [[46, 3, 1, "", "metrics"]], "neural_compressor.metric.metric.ONNXRTQLMetrics": [[46, 3, 1, "", "metrics"]], "neural_compressor.metric.metric.PyTorchMetrics": [[46, 3, 1, "", "metrics"]], "neural_compressor.metric.metric.RMSE": [[46, 3, 1, "", "mse"]], "neural_compressor.metric.metric.TensorflowMetrics": [[46, 3, 1, "", "metrics"]], "neural_compressor.metric.metric.TensorflowTopK": [[46, 3, 1, "", "k"], [46, 3, 1, "", "num_correct"], [46, 3, 1, "", "num_sample"]], "neural_compressor.mix_precision": [[47, 2, 1, "", "fit"]], "neural_compressor.model": [[48, 0, 0, "-", "base_model"], [50, 0, 0, "-", "keras_model"], [51, 0, 0, "-", "model"], [52, 0, 0, "-", "mxnet_model"], [53, 0, 0, "-", "nets_factory"], [54, 0, 0, "-", "onnx_model"], [55, 0, 0, "-", "tensorflow_model"], [56, 0, 0, "-", "torch_model"]], "neural_compressor.model.base_model": [[48, 1, 1, "", "BaseModel"]], "neural_compressor.model.keras_model": [[50, 1, 1, "", "KerasModel"]], "neural_compressor.model.model": [[51, 1, 1, "", "Model"], [51, 2, 1, "", "get_model_fwk_name"]], "neural_compressor.model.mxnet_model": [[52, 1, 1, "", "MXNetModel"]], "neural_compressor.model.nets_factory": [[53, 1, 1, "", "TFSlimNetsFactory"]], "neural_compressor.model.onnx_model": [[54, 1, 1, "", "ONNXModel"]], "neural_compressor.model.tensorflow_model": [[55, 1, 1, "", "TensorflowBaseModel"], [55, 1, 1, "", "TensorflowCheckpointModel"], [55, 1, 1, "", "TensorflowLLMModel"], [55, 1, 1, "", "TensorflowModel"], [55, 1, 1, "", "TensorflowQATModel"], [55, 1, 1, "", "TensorflowSavedModelModel"], [55, 2, 1, "", "checkpoint_session"], [55, 2, 1, "", "estimator_session"], [55, 2, 1, "", "frozen_pb_session"], [55, 2, 1, "", "get_model_type"], [55, 2, 1, "", "graph_def_session"], [55, 2, 1, "", "graph_session"], [55, 2, 1, "", "keras_session"], [55, 2, 1, "", "load_saved_model"], [55, 2, 1, "", "saved_model_session"], [55, 2, 1, "", "slim_session"], [55, 2, 1, "", "try_loading_keras"], [55, 2, 1, "", "validate_and_inference_input_output"], [55, 2, 1, "", "validate_graph_node"]], "neural_compressor.model.torch_model": [[56, 1, 1, "", "IPEXModel"], [56, 1, 1, "", "PyTorchBaseModel"], [56, 1, 1, "", "PyTorchFXModel"], [56, 1, 1, "", "PyTorchModel"]], "neural_compressor.objective": [[57, 1, 1, "", "Accuracy"], [57, 1, 1, "", "Footprint"], [57, 1, 1, "", "ModelSize"], [57, 1, 1, "", "MultiObjective"], [57, 1, 1, "", "Objective"], [57, 1, 1, "", "Performance"], [57, 2, 1, "", "objective_custom_registry"], [57, 2, 1, "", "objective_registry"]], "neural_compressor.quantization": [[59, 2, 1, "", "fit"]], "neural_compressor.strategy": [[60, 0, 0, "-", "auto"], [61, 0, 0, "-", "auto_mixed_precision"], [62, 0, 0, "-", "basic"], [63, 0, 0, "-", "bayesian"], [64, 0, 0, "-", "conservative"], [65, 0, 0, "-", "exhaustive"], [66, 0, 0, "-", "hawq_v2"], [68, 0, 0, "-", "mse"], [69, 0, 0, "-", "mse_v2"], [70, 0, 0, "-", "random"], [71, 0, 0, "-", "strategy"], [73, 0, 0, "-", "utils"]], "neural_compressor.strategy.auto": [[60, 1, 1, "", "AutoTuneStrategy"]], "neural_compressor.strategy.auto_mixed_precision": [[61, 1, 1, "", "AutoMixedPrecisionTuneStrategy"]], "neural_compressor.strategy.basic": [[62, 1, 1, "", "BasicTuneStrategy"]], "neural_compressor.strategy.bayesian": [[63, 1, 1, "", "BayesianOptimization"], [63, 1, 1, "", "BayesianTuneStrategy"], [63, 1, 1, "", "TargetSpace"], [63, 2, 1, "", "acq_max"]], "neural_compressor.strategy.conservative": [[64, 1, 1, "", "ConservativeTuneStrategy"]], "neural_compressor.strategy.exhaustive": [[65, 1, 1, "", "ExhaustiveTuneStrategy"]], "neural_compressor.strategy.hawq_v2": [[66, 1, 1, "", "HAWQ_V2TuneStrategy"]], "neural_compressor.strategy.mse": [[68, 1, 1, "", "MSETuneStrategy"]], "neural_compressor.strategy.mse_v2": [[69, 1, 1, "", "MSE_V2TuneStrategy"]], "neural_compressor.strategy.random": [[70, 1, 1, "", "RandomTuneStrategy"]], "neural_compressor.strategy.strategy": [[71, 1, 1, "", "TuneStrategy"], [71, 1, 1, "", "TuneStrategyMeta"], [71, 2, 1, "", "strategy_registry"]], "neural_compressor.strategy.utils": [[72, 0, 0, "-", "constant"], [74, 0, 0, "-", "tuning_sampler"], [75, 0, 0, "-", "tuning_space"], [76, 0, 0, "-", "tuning_structs"], [77, 0, 0, "-", "utility"]], "neural_compressor.strategy.utils.tuning_sampler": [[74, 1, 1, "", "BlockFallbackTuningSampler"], [74, 1, 1, "", "FallbackTuningSampler"], [74, 1, 1, "", "LowerBitsSampler"], [74, 1, 1, "", "ModelWiseTuningSampler"], [74, 1, 1, "", "OpTypeWiseTuningSampler"], [74, 1, 1, "", "OpWiseTuningSampler"], [74, 1, 1, "", "SmoothQuantSampler"], [74, 1, 1, "", "TuningOrder"], [74, 1, 1, "", "TuningSampler"], [74, 1, 1, "", "WeightOnlyQuantSampler"]], "neural_compressor.strategy.utils.tuning_space": [[75, 1, 1, "", "TuningItem"], [75, 1, 1, "", "TuningSpace"], [75, 2, 1, "", "initial_tuning_cfg_with_quant_mode"], [75, 2, 1, "", "pattern_to_internal"], [75, 2, 1, "", "pattern_to_path"], [75, 2, 1, "", "quant_mode_from_pattern"]], "neural_compressor.strategy.utils.tuning_structs": [[76, 1, 1, "", "OpTuningConfig"]], "neural_compressor.strategy.utils.utility": [[77, 1, 1, "", "ClassRegister"], [77, 1, 1, "", "OrderedDefaultDict"], [77, 1, 1, "", "QuantOptions"], [77, 1, 1, "", "QuantType"], [77, 2, 1, "", "build_slave_faker_model"], [77, 2, 1, "", "extract_data_type"], [77, 2, 1, "", "get_adaptor_name"], [77, 2, 1, "", "preprocess_user_cfg"], [77, 2, 1, "", "reverted_data_type"]], "neural_compressor.tensorflow": [[78, 0, 0, "-", "algorithms"], [87, 0, 0, "-", "keras"], [100, 0, 0, "-", "quantization"], [184, 0, 0, "-", "utils"]], "neural_compressor.tensorflow.algorithms": [[81, 0, 0, "-", "smoother"], [83, 0, 0, "-", "static_quant"]], "neural_compressor.tensorflow.algorithms.smoother": [[79, 0, 0, "-", "calibration"], [80, 0, 0, "-", "core"], [82, 0, 0, "-", "scaler"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[79, 1, 1, "", "SmoothQuantCalibration"], [79, 1, 1, "", "SmoothQuantCalibrationLLM"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[80, 1, 1, "", "SmoothQuant"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[82, 1, 1, "", "SmoothQuantScaler"], [82, 1, 1, "", "SmoothQuantScalerLLM"]], "neural_compressor.tensorflow.algorithms.static_quant": [[84, 0, 0, "-", "keras"], [85, 0, 0, "-", "tensorflow"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[84, 1, 1, "", "KerasAdaptor"], [84, 1, 1, "", "KerasConfigConverter"], [84, 1, 1, "", "KerasQuery"], [84, 1, 1, "", "KerasSurgery"]], "neural_compressor.tensorflow.algorithms.static_quant.tensorflow": [[85, 1, 1, "", "TensorFlowAdaptor"], [85, 1, 1, "", "TensorFlowConfig"], [85, 1, 1, "", "TensorflowConfigConverter"], [85, 1, 1, "", "TensorflowQuery"], [85, 1, 1, "", "Tensorflow_ITEXAdaptor"]], "neural_compressor.tensorflow.keras": [[91, 0, 0, "-", "layers"], [96, 0, 0, "-", "quantization"]], "neural_compressor.tensorflow.keras.layers": [[88, 0, 0, "-", "conv2d"], [89, 0, 0, "-", "dense"], [90, 0, 0, "-", "depthwise_conv2d"], [92, 0, 0, "-", "layer_initializer"], [93, 0, 0, "-", "pool2d"], [94, 0, 0, "-", "separable_conv2d"]], "neural_compressor.tensorflow.keras.layers.conv2d": [[88, 1, 1, "", "QConv2D"], [88, 2, 1, "", "initialize_int8_conv2d"]], "neural_compressor.tensorflow.keras.layers.dense": [[89, 1, 1, "", "QDense"], [89, 2, 1, "", "initialize_int8_dense"]], "neural_compressor.tensorflow.keras.layers.depthwise_conv2d": [[90, 1, 1, "", "QDepthwiseConv2D"], [90, 2, 1, "", "initialize_int8_depthwise_conv2d"]], "neural_compressor.tensorflow.keras.layers.pool2d": [[93, 1, 1, "", "QAvgPool2D"], [93, 1, 1, "", "QMaxPool2D"], [93, 2, 1, "", "initialize_int8_avgpool"], [93, 2, 1, "", "initialize_int8_maxpool"]], "neural_compressor.tensorflow.keras.layers.separable_conv2d": [[94, 1, 1, "", "QSeparableConv2D"], [94, 2, 1, "", "initialize_int8_separable_conv2d"]], "neural_compressor.tensorflow.keras.quantization": [[95, 0, 0, "-", "config"]], "neural_compressor.tensorflow.keras.quantization.config": [[95, 1, 1, "", "OperatorConfig"], [95, 1, 1, "", "StaticQuantConfig"], [95, 2, 1, "", "get_all_registered_configs"], [95, 2, 1, "", "get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization": [[97, 0, 0, "-", "algorithm_entry"], [98, 0, 0, "-", "autotune"], [99, 0, 0, "-", "config"], [101, 0, 0, "-", "quantize"], [157, 0, 0, "-", "utils"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[97, 2, 1, "", "smooth_quant_entry"], [97, 2, 1, "", "static_quant_entry"]], "neural_compressor.tensorflow.quantization.autotune": [[98, 2, 1, "", "autotune"], [98, 2, 1, "", "get_all_config_set"]], "neural_compressor.tensorflow.quantization.config": [[99, 1, 1, "", "SmoothQuantConfig"], [99, 1, 1, "", "StaticQuantConfig"], [99, 2, 1, "", "get_default_sq_config"], [99, 2, 1, "", "get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization.quantize": [[101, 2, 1, "", "need_apply"], [101, 2, 1, "", "quantize_model"], [101, 2, 1, "", "quantize_model_with_single_config"]], "neural_compressor.tensorflow.quantization.utils": [[102, 0, 0, "-", "graph_converter"], [140, 0, 0, "-", "graph_rewriter"], [156, 0, 0, "-", "graph_util"], [158, 0, 0, "-", "quantize_graph"], [175, 0, 0, "-", "quantize_graph_common"], [178, 0, 0, "-", "transform_graph"], [181, 0, 0, "-", "utility"]], "neural_compressor.tensorflow.quantization.utils.graph_converter": [[102, 1, 1, "", "GraphConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[105, 0, 0, "-", "bf16"], [129, 0, 0, "-", "generic"], [139, 0, 0, "-", "graph_base"], [147, 0, 0, "-", "int8"], [152, 0, 0, "-", "qdq"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16": [[103, 0, 0, "-", "bf16_convert"], [104, 0, 0, "-", "dequantize_cast_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert": [[103, 1, 1, "", "BF16Convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[104, 1, 1, "", "DequantizeCastOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[106, 0, 0, "-", "convert_add_to_biasadd"], [107, 0, 0, "-", "convert_layout"], [108, 0, 0, "-", "convert_leakyrelu"], [109, 0, 0, "-", "convert_nan_to_random"], [110, 0, 0, "-", "convert_placeholder_to_const"], [111, 0, 0, "-", "dilated_contraction"], [112, 0, 0, "-", "dummy_biasadd"], [113, 0, 0, "-", "expanddims_optimizer"], [114, 0, 0, "-", "fetch_weight_from_reshape"], [115, 0, 0, "-", "fold_batch_norm"], [116, 0, 0, "-", "fold_constant"], [117, 0, 0, "-", "fuse_biasadd_add"], [118, 0, 0, "-", "fuse_column_wise_mul"], [119, 0, 0, "-", "fuse_conv_with_math"], [120, 0, 0, "-", "fuse_decomposed_bn"], [121, 0, 0, "-", "fuse_decomposed_in"], [122, 0, 0, "-", "fuse_gelu"], [123, 0, 0, "-", "fuse_layer_norm"], [124, 0, 0, "-", "fuse_pad_with_conv"], [125, 0, 0, "-", "fuse_pad_with_fp32_conv"], [126, 0, 0, "-", "fuse_reshape_transpose"], [127, 0, 0, "-", "graph_cse_optimizer"], [128, 0, 0, "-", "grappler_pass"], [130, 0, 0, "-", "insert_print_node"], [131, 0, 0, "-", "move_squeeze_after_relu"], [132, 0, 0, "-", "pre_optimize"], [133, 0, 0, "-", "remove_training_nodes"], [134, 0, 0, "-", "rename_batch_norm"], [135, 0, 0, "-", "split_shared_input"], [136, 0, 0, "-", "strip_equivalent_nodes"], [137, 0, 0, "-", "strip_unused_nodes"], [138, 0, 0, "-", "switch_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[106, 1, 1, "", "ConvertAddToBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[107, 1, 1, "", "ConvertLayoutOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[108, 1, 1, "", "ConvertLeakyReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[109, 1, 1, "", "ConvertNanToRandom"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[110, 1, 1, "", "ConvertPlaceholderToConst"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[111, 1, 1, "", "DilatedContraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[112, 1, 1, "", "InjectDummyBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[113, 1, 1, "", "ExpandDimsOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[114, 1, 1, "", "FetchWeightFromReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[115, 1, 1, "", "FoldBatchNormNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[116, 1, 1, "", "GraphFoldConstantOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[117, 1, 1, "", "FuseBiasAddAndAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[118, 1, 1, "", "FuseColumnWiseMulOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[119, 1, 1, "", "FuseConvWithMathOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[120, 1, 1, "", "FuseDecomposedBNOptimizer"], [120, 2, 1, "", "bypass_reshape"], [120, 2, 1, "", "get_const_dim_count"], [120, 2, 1, "", "node_from_map"], [120, 2, 1, "", "node_name_from_input"], [120, 2, 1, "", "valid_reshape_inputs"], [120, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[121, 1, 1, "", "FuseDecomposedINOptimizer"], [121, 2, 1, "", "bypass_reshape"], [121, 2, 1, "", "get_const_dim_count"], [121, 2, 1, "", "node_from_map"], [121, 2, 1, "", "node_name_from_input"], [121, 2, 1, "", "valid_reshape_inputs"], [121, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[122, 1, 1, "", "FuseGeluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[123, 1, 1, "", "FuseLayerNormOptimizer"], [123, 2, 1, "", "node_from_map"], [123, 2, 1, "", "node_name_from_input"], [123, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[124, 1, 1, "", "FusePadWithConv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[125, 1, 1, "", "FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[126, 1, 1, "", "FuseTransposeReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[127, 1, 1, "", "GraphCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[128, 1, 1, "", "GrapplerOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[130, 1, 1, "", "InsertPrintMinMaxNode"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[131, 1, 1, "", "MoveSqueezeAfterReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[132, 1, 1, "", "PreOptimization"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[133, 1, 1, "", "RemoveTrainingNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[134, 1, 1, "", "RenameBatchNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[135, 1, 1, "", "SplitSharedInputOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[136, 1, 1, "", "StripEquivalentNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[137, 1, 1, "", "StripUnusedNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[138, 1, 1, "", "SwitchOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[139, 1, 1, "", "GraphRewriterBase"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8": [[141, 0, 0, "-", "freeze_fake_quant"], [142, 0, 0, "-", "freeze_value"], [143, 0, 0, "-", "fuse_conv_redundant_dequantize"], [144, 0, 0, "-", "fuse_conv_requantize"], [145, 0, 0, "-", "fuse_matmul_redundant_dequantize"], [146, 0, 0, "-", "fuse_matmul_requantize"], [148, 0, 0, "-", "meta_op_optimizer"], [149, 0, 0, "-", "post_hostconst_converter"], [150, 0, 0, "-", "post_quantized_op_cse"], [151, 0, 0, "-", "scale_propagation"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant": [[141, 1, 1, "", "FreezeFakeQuantOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value": [[142, 1, 1, "", "FreezeValueTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[143, 1, 1, "", "FuseConvRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize": [[144, 1, 1, "", "FuseConvRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[145, 1, 1, "", "FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize": [[146, 1, 1, "", "FuseMatMulRequantizeDequantizeNewAPITransformer"], [146, 1, 1, "", "FuseMatMulRequantizeDequantizeTransformer"], [146, 1, 1, "", "FuseMatMulRequantizeNewAPITransformer"], [146, 1, 1, "", "FuseMatMulRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer": [[148, 1, 1, "", "MetaInfoChangingMemOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter": [[149, 1, 1, "", "PostHostConstConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse": [[150, 1, 1, "", "PostCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation": [[151, 1, 1, "", "ScaleProPagationTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq": [[153, 0, 0, "-", "insert_qdq_pattern"], [154, 0, 0, "-", "merge_duplicated_qdq"], [155, 0, 0, "-", "share_qdq_y_pattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern": [[153, 1, 1, "", "GenerateGraphWithQDQPattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq": [[154, 1, 1, "", "MergeDuplicatedQDQOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern": [[155, 1, 1, "", "ShareQDQForItexYPatternOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[156, 1, 1, "", "GraphAnalyzer"], [156, 1, 1, "", "GraphRewriterHelper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph": [[166, 0, 0, "-", "qdq"], [168, 0, 0, "-", "quantize_graph_base"], [169, 0, 0, "-", "quantize_graph_bn"], [170, 0, 0, "-", "quantize_graph_concatv2"], [171, 0, 0, "-", "quantize_graph_conv"], [172, 0, 0, "-", "quantize_graph_for_intel_cpu"], [173, 0, 0, "-", "quantize_graph_matmul"], [174, 0, 0, "-", "quantize_graph_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq": [[159, 0, 0, "-", "fuse_qdq_bn"], [160, 0, 0, "-", "fuse_qdq_concatv2"], [161, 0, 0, "-", "fuse_qdq_conv"], [162, 0, 0, "-", "fuse_qdq_deconv"], [163, 0, 0, "-", "fuse_qdq_in"], [164, 0, 0, "-", "fuse_qdq_matmul"], [165, 0, 0, "-", "fuse_qdq_pooling"], [167, 0, 0, "-", "optimize_qdq"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn": [[159, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2": [[160, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv": [[161, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv": [[162, 1, 1, "", "FuseNodeStartWithDeconv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in": [[163, 1, 1, "", "FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul": [[164, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling": [[165, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq": [[167, 1, 1, "", "OptimizeQDQGraph"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base": [[168, 1, 1, "", "QuantizeGraphBase"], [168, 1, 1, "", "QuantizeNodeBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn": [[169, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2": [[170, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv": [[171, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu": [[172, 1, 1, "", "QuantizeGraphForIntel"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul": [[173, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling": [[174, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[175, 1, 1, "", "QuantizeGraphHelper"]], "neural_compressor.tensorflow.quantization.utils.transform_graph": [[176, 0, 0, "-", "bias_correction"], [177, 0, 0, "-", "graph_transform_base"], [179, 0, 0, "-", "insert_logging"], [180, 0, 0, "-", "rerange_quantized_concat"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction": [[176, 1, 1, "", "BiasCorrection"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base": [[177, 1, 1, "", "GraphTransformBase"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging": [[179, 1, 1, "", "InsertLogging"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat": [[180, 1, 1, "", "RerangeQuantizedConcat"]], "neural_compressor.tensorflow.quantization.utils.utility": [[181, 2, 1, "", "apply_inlining"], [181, 2, 1, "", "collate_tf_preds"], [181, 2, 1, "", "construct_function_from_graph_def"], [181, 2, 1, "", "fix_ref_type_of_graph_def"], [181, 2, 1, "", "generate_feed_dict"], [181, 2, 1, "", "get_graph_def"], [181, 2, 1, "", "get_input_output_node_names"], [181, 2, 1, "", "get_model_input_shape"], [181, 2, 1, "", "get_tensor_by_name"], [181, 2, 1, "", "is_ckpt_format"], [181, 2, 1, "", "is_saved_model_format"], [181, 2, 1, "", "iterator_sess_run"], [181, 2, 1, "", "parse_saved_model"], [181, 2, 1, "", "read_graph"], [181, 2, 1, "", "reconstruct_saved_model"], [181, 2, 1, "", "strip_equivalent_nodes"], [181, 2, 1, "", "strip_unused_nodes"], [181, 2, 1, "", "write_graph"]], "neural_compressor.tensorflow.utils": [[182, 0, 0, "-", "constants"], [183, 0, 0, "-", "data"], [185, 0, 0, "-", "model"], [186, 0, 0, "-", "model_wrappers"], [187, 0, 0, "-", "utility"]], "neural_compressor.tensorflow.utils.data": [[183, 1, 1, "", "BaseDataLoader"], [183, 1, 1, "", "BatchSampler"], [183, 1, 1, "", "DummyDataset"], [183, 1, 1, "", "DummyDatasetV2"], [183, 1, 1, "", "IndexFetcher"], [183, 1, 1, "", "IterableFetcher"], [183, 1, 1, "", "IterableSampler"], [183, 1, 1, "", "SequentialSampler"], [183, 2, 1, "", "default_collate"]], "neural_compressor.tensorflow.utils.model": [[185, 1, 1, "", "Model"], [185, 1, 1, "", "TensorflowGlobalConfig"]], "neural_compressor.tensorflow.utils.model_wrappers": [[186, 1, 1, "", "BaseModel"], [186, 1, 1, "", "KerasModel"], [186, 1, 1, "", "TensorflowBaseModel"], [186, 1, 1, "", "TensorflowCheckpointModel"], [186, 1, 1, "", "TensorflowLLMModel"], [186, 1, 1, "", "TensorflowModel"], [186, 1, 1, "", "TensorflowSavedModelModel"], [186, 2, 1, "", "checkpoint_session"], [186, 2, 1, "", "estimator_session"], [186, 2, 1, "", "frozen_pb_session"], [186, 2, 1, "", "get_model_type"], [186, 2, 1, "", "get_tf_model_type"], [186, 2, 1, "", "graph_def_session"], [186, 2, 1, "", "graph_session"], [186, 2, 1, "", "keras_session"], [186, 2, 1, "", "load_saved_model"], [186, 2, 1, "", "saved_model_session"], [186, 2, 1, "", "slim_session"], [186, 2, 1, "", "try_loading_keras"], [186, 2, 1, "", "validate_and_inference_input_output"], [186, 2, 1, "", "validate_graph_node"]], "neural_compressor.tensorflow.utils.utility": [[187, 1, 1, "", "CaptureOutputToFile"], [187, 1, 1, "", "CpuInfo"], [187, 1, 1, "", "TFSlimNetsFactory"], [187, 2, 1, "", "combine_histogram"], [187, 2, 1, "", "deep_get"], [187, 2, 1, "", "disable_random"], [187, 2, 1, "", "dump_elapsed_time"], [187, 2, 1, "", "get_all_fp32_data"], [187, 2, 1, "", "get_tensor_histogram"], [187, 2, 1, "", "itex_installed"], [187, 2, 1, "", "register_algo"], [187, 2, 1, "", "singleton"], [187, 2, 1, "", "valid_keras_format"], [187, 2, 1, "", "version1_eq_version2"], [187, 2, 1, "", "version1_gt_version2"], [187, 2, 1, "", "version1_gte_version2"], [187, 2, 1, "", "version1_lt_version2"], [187, 2, 1, "", "version1_lte_version2"]], "neural_compressor.torch": [[189, 0, 0, "-", "algorithms"], [229, 0, 0, "-", "export"], [235, 0, 0, "-", "quantization"], [241, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms": [[188, 0, 0, "-", "base_algorithm"], [190, 0, 0, "-", "layer_wise"], [195, 0, 0, "-", "mixed_precision"], [197, 0, 0, "-", "mx_quant"], [202, 0, 0, "-", "pt2e_quant"], [205, 0, 0, "-", "smooth_quant"], [209, 0, 0, "-", "static_quant"], [223, 0, 0, "-", "weight_only"]], "neural_compressor.torch.algorithms.base_algorithm": [[188, 1, 1, "", "Quantizer"]], "neural_compressor.torch.algorithms.layer_wise": [[191, 0, 0, "-", "load"], [192, 0, 0, "-", "modified_pickle"], [193, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms.layer_wise.load": [[191, 2, 1, "", "load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[192, 5, 1, "", "PickleError"], [192, 5, 1, "", "PicklingError"], [192, 5, 1, "", "UnpicklingError"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[193, 1, 1, "", "QDQLayer"], [193, 2, 1, "", "clean_module_weight"], [193, 2, 1, "", "dowload_hf_model"], [193, 2, 1, "", "get_children"], [193, 2, 1, "", "get_module"], [193, 2, 1, "", "get_named_children"], [193, 2, 1, "", "get_super_module_by_name"], [193, 2, 1, "", "load_empty_model"], [193, 2, 1, "", "load_layer_wise_quantized_model"], [193, 2, 1, "", "load_module"], [193, 2, 1, "", "load_tensor"], [193, 2, 1, "", "load_tensor_from_shard"], [193, 2, 1, "", "load_value"], [193, 2, 1, "", "register_weight_hooks"], [193, 2, 1, "", "update_module"]], "neural_compressor.torch.algorithms.mixed_precision": [[194, 0, 0, "-", "half_precision_convert"], [196, 0, 0, "-", "module_wrappers"]], "neural_compressor.torch.algorithms.mixed_precision.half_precision_convert": [[194, 1, 1, "", "HalfPrecisionConverter"]], "neural_compressor.torch.algorithms.mixed_precision.module_wrappers": [[196, 1, 1, "", "HalfPrecisionModuleWrapper"]], "neural_compressor.torch.algorithms.mx_quant": [[198, 0, 0, "-", "mx"], [199, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms.mx_quant.mx": [[198, 1, 1, "", "MXLinear"], [198, 1, 1, "", "MXQuantizer"]], "neural_compressor.torch.algorithms.mx_quant.utils": [[199, 1, 1, "", "ElemFormat"], [199, 1, 1, "", "RoundingMode"], [199, 2, 1, "", "quantize_elemwise_op"], [199, 2, 1, "", "quantize_mx_op"]], "neural_compressor.torch.algorithms.pt2e_quant": [[200, 0, 0, "-", "core"], [201, 0, 0, "-", "half_precision_rewriter"], [203, 0, 0, "-", "save_load"], [204, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.pt2e_quant.core": [[200, 1, 1, "", "W8A8PT2EQuantizer"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter": [[201, 1, 1, "", "PatternPair"], [201, 2, 1, "", "apply_single_pattern_pair"], [201, 2, 1, "", "get_filter_fn"], [201, 2, 1, "", "get_half_precision_node_set"], [201, 2, 1, "", "get_unquantized_node_set"], [201, 2, 1, "", "pattern_factory"], [201, 2, 1, "", "transformation"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair": [[201, 3, 1, "", "fn"], [201, 3, 1, "", "replace_pattern"], [201, 3, 1, "", "search_pattern"]], "neural_compressor.torch.algorithms.pt2e_quant.save_load": [[203, 2, 1, "", "load"], [203, 2, 1, "", "save"]], "neural_compressor.torch.algorithms.pt2e_quant.utility": [[204, 2, 1, "", "create_quant_spec_from_config"], [204, 2, 1, "", "create_xiq_quantizer_from_pt2e_config"]], "neural_compressor.torch.algorithms.smooth_quant": [[206, 0, 0, "-", "save_load"], [207, 0, 0, "-", "smooth_quant"], [208, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.smooth_quant.save_load": [[206, 2, 1, "", "recover_model_from_json"]], "neural_compressor.torch.algorithms.smooth_quant.smooth_quant": [[207, 1, 1, "", "SmoothQuantQuantizer"], [207, 2, 1, "", "qdq_quantize"]], "neural_compressor.torch.algorithms.smooth_quant.utility": [[208, 1, 1, "", "AutoAlpha"], [208, 1, 1, "", "Calibration"], [208, 1, 1, "", "GraphTrace"], [208, 1, 1, "", "SQLinearWrapper"], [208, 1, 1, "", "TorchSmoothQuant"], [208, 1, 1, "", "WrapperLayer"], [208, 2, 1, "", "build_captured_dataloader"], [208, 2, 1, "", "cal_scale"], [208, 2, 1, "", "cfg_to_qconfig"], [208, 2, 1, "", "check_cfg_and_qconfig"], [208, 2, 1, "", "dump_model_op_stats"], [208, 2, 1, "", "enough_memo_store_scale"], [208, 2, 1, "", "forward_wrapper"], [208, 2, 1, "", "get_module"], [208, 2, 1, "", "get_parent"], [208, 2, 1, "", "get_quantizable_ops_recursively"], [208, 2, 1, "", "model_forward"], [208, 2, 1, "", "model_forward_per_sample"], [208, 2, 1, "", "move_input_to_device"], [208, 2, 1, "", "quant_dequant_w_v1"], [208, 2, 1, "", "quant_dequant_x_v1"], [208, 2, 1, "", "register_autotune"], [208, 2, 1, "", "reshape_in_channel_to_last"], [208, 2, 1, "", "reshape_scale_as_input"], [208, 2, 1, "", "reshape_scale_as_weight"], [208, 2, 1, "", "set_module"], [208, 2, 1, "", "update_sq_scale"]], "neural_compressor.torch.algorithms.static_quant": [[210, 0, 0, "-", "save_load"], [211, 0, 0, "-", "static_quant"], [212, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.static_quant.save_load": [[210, 2, 1, "", "load"], [210, 2, 1, "", "save"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[211, 1, 1, "", "StaticQuantQuantizer"]], "neural_compressor.torch.algorithms.static_quant.utility": [[212, 1, 1, "", "TransformerBasedModelBlockPatternDetector"], [212, 2, 1, "", "cfg_to_qconfig"], [212, 2, 1, "", "check_cfg_and_qconfig"], [212, 2, 1, "", "dump_model_op_stats"], [212, 2, 1, "", "generate_activation_observer"], [212, 2, 1, "", "generate_xpu_qconfig"], [212, 2, 1, "", "get_depth"], [212, 2, 1, "", "get_dict_at_depth"], [212, 2, 1, "", "get_element_under_depth"], [212, 2, 1, "", "get_quantizable_ops_from_cfgs"], [212, 2, 1, "", "get_quantizable_ops_recursively"], [212, 2, 1, "", "parse_cfgs"], [212, 2, 1, "", "simple_inference"]], "neural_compressor.torch.algorithms.weight_only": [[213, 0, 0, "-", "autoround"], [214, 0, 0, "-", "awq"], [215, 0, 0, "-", "gptq"], [219, 0, 0, "-", "hqq"], [224, 0, 0, "-", "modules"], [225, 0, 0, "-", "rtn"], [226, 0, 0, "-", "save_load"], [227, 0, 0, "-", "teq"], [228, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.weight_only.autoround": [[213, 1, 1, "", "AutoRoundQuantizer"], [213, 2, 1, "", "get_dataloader"]], "neural_compressor.torch.algorithms.weight_only.awq": [[214, 1, 1, "", "AWQQuantizer"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[215, 1, 1, "", "GPTQ"], [215, 1, 1, "", "GPTQuantizer"], [215, 1, 1, "", "Quantizer"], [215, 1, 1, "", "RAWGPTQuantizer"], [215, 2, 1, "", "find_layers"], [215, 2, 1, "", "find_layers_name"], [215, 2, 1, "", "is_leaf"], [215, 2, 1, "", "log_quantizable_layers_per_transformer"], [215, 2, 1, "", "trace_gptq_target_blocks"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[216, 0, 0, "-", "bitpack"], [217, 0, 0, "-", "config"], [218, 0, 0, "-", "core"], [220, 0, 0, "-", "optimizer"], [221, 0, 0, "-", "qtensor"], [222, 0, 0, "-", "quantizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[216, 1, 1, "", "Packer"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[217, 1, 1, "", "HQQModuleConfig"], [217, 1, 1, "", "QTensorConfig"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[218, 1, 1, "", "HQQLinear"], [218, 1, 1, "", "HQQTensorHandle"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[220, 2, 1, "", "optimize_weights_proximal_legacy"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[221, 1, 1, "", "QTensor"], [221, 1, 1, "", "QTensorMetaInfo"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo": [[221, 3, 1, "", "axis"], [221, 3, 1, "", "group_size"], [221, 3, 1, "", "nbits"], [221, 3, 1, "", "packing"], [221, 3, 1, "", "shape"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[222, 1, 1, "", "HQQuantizer"], [222, 2, 1, "", "filter_fn"], [222, 2, 1, "", "patch_hqq_moduile"], [222, 2, 1, "", "replacement_fn"]], "neural_compressor.torch.algorithms.weight_only.modules": [[224, 1, 1, "", "FakeAffineTensorQuantFunction"], [224, 1, 1, "", "HPUWeightOnlyLinear"], [224, 1, 1, "", "INCWeightOnlyLinear"], [224, 1, 1, "", "MulLinear"], [224, 1, 1, "", "QDQLayer"], [224, 1, 1, "", "TEQLinearFakeQuant"], [224, 1, 1, "", "UnpackedWeightOnlyLinearParams"], [224, 1, 1, "", "WeightOnlyLinear"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[225, 1, 1, "", "RTNQuantizer"]], "neural_compressor.torch.algorithms.weight_only.save_load": [[226, 1, 1, "", "WOQModelLoader"], [226, 2, 1, "", "load"], [226, 2, 1, "", "save"]], "neural_compressor.torch.algorithms.weight_only.teq": [[227, 1, 1, "", "TEQuantizer"], [227, 1, 1, "", "TrainableEquivalentTransformation"]], "neural_compressor.torch.algorithms.weight_only.utility": [[228, 1, 1, "", "GraphTrace"], [228, 2, 1, "", "fetch_module"], [228, 2, 1, "", "forward_wrapper"], [228, 2, 1, "", "get_absorb_layers"], [228, 2, 1, "", "get_block_prefix"], [228, 2, 1, "", "get_module"], [228, 2, 1, "", "get_module_input_output"], [228, 2, 1, "", "get_parent"], [228, 2, 1, "", "model_forward"], [228, 2, 1, "", "move_input_to_device"], [228, 2, 1, "", "qdq_weight_actor"], [228, 2, 1, "", "qdq_weight_asym"], [228, 2, 1, "", "qdq_weight_sym"], [228, 2, 1, "", "quant_tensor"], [228, 2, 1, "", "quant_weight_w_scale"], [228, 2, 1, "", "quantize_4bit"], [228, 2, 1, "", "recover_forward"], [228, 2, 1, "", "replace_forward"], [228, 2, 1, "", "search_clip"], [228, 2, 1, "", "set_module"]], "neural_compressor.torch.export": [[230, 0, 0, "-", "pt2e_export"]], "neural_compressor.torch.export.pt2e_export": [[230, 2, 1, "", "export"], [230, 2, 1, "", "export_model_for_pt2e_quant"]], "neural_compressor.torch.quantization": [[232, 0, 0, "-", "algorithm_entry"], [233, 0, 0, "-", "autotune"], [234, 0, 0, "-", "config"], [236, 0, 0, "-", "load_entry"], [237, 0, 0, "-", "quantize"]], "neural_compressor.torch.quantization.algorithm_entry": [[232, 2, 1, "", "autoround_quantize_entry"], [232, 2, 1, "", "awq_quantize_entry"], [232, 2, 1, "", "fp8_entry"], [232, 2, 1, "", "gptq_entry"], [232, 2, 1, "", "hqq_entry"], [232, 2, 1, "", "mixed_precision_entry"], [232, 2, 1, "", "mx_quant_entry"], [232, 2, 1, "", "pt2e_dynamic_quant_entry"], [232, 2, 1, "", "pt2e_static_quant_entry"], [232, 2, 1, "", "rtn_entry"], [232, 2, 1, "", "smooth_quant_entry"], [232, 2, 1, "", "static_quant_entry"], [232, 2, 1, "", "teq_quantize_entry"]], "neural_compressor.torch.quantization.autotune": [[233, 2, 1, "", "autotune"], [233, 2, 1, "", "get_all_config_set"], [233, 2, 1, "", "get_rtn_double_quant_config_set"]], "neural_compressor.torch.quantization.config": [[234, 1, 1, "", "AWQConfig"], [234, 1, 1, "", "AutoRoundConfig"], [234, 1, 1, "", "DynamicQuantConfig"], [234, 1, 1, "", "FP8Config"], [234, 1, 1, "", "GPTQConfig"], [234, 1, 1, "", "HQQConfig"], [234, 1, 1, "", "MXQuantConfig"], [234, 1, 1, "", "MixedPrecisionConfig"], [234, 1, 1, "", "OperatorConfig"], [234, 1, 1, "", "RTNConfig"], [234, 1, 1, "", "SmoothQuantConfig"], [234, 1, 1, "", "StaticQuantConfig"], [234, 1, 1, "", "TEQConfig"], [234, 1, 1, "", "TorchBaseConfig"], [234, 2, 1, "", "get_all_registered_configs"], [234, 2, 1, "", "get_default_AutoRound_config"], [234, 2, 1, "", "get_default_awq_config"], [234, 2, 1, "", "get_default_double_quant_config"], [234, 2, 1, "", "get_default_dynamic_config"], [234, 2, 1, "", "get_default_fp8_config"], [234, 2, 1, "", "get_default_fp8_config_set"], [234, 2, 1, "", "get_default_gptq_config"], [234, 2, 1, "", "get_default_hqq_config"], [234, 2, 1, "", "get_default_mixed_precision_config"], [234, 2, 1, "", "get_default_mixed_precision_config_set"], [234, 2, 1, "", "get_default_mx_config"], [234, 2, 1, "", "get_default_rtn_config"], [234, 2, 1, "", "get_default_sq_config"], [234, 2, 1, "", "get_default_static_config"], [234, 2, 1, "", "get_default_teq_config"], [234, 2, 1, "", "get_woq_tuning_config"]], "neural_compressor.torch.quantization.load_entry": [[236, 2, 1, "", "load"]], "neural_compressor.torch.quantization.quantize": [[237, 2, 1, "", "convert"], [237, 2, 1, "", "finalize_calibration"], [237, 2, 1, "", "need_apply"], [237, 2, 1, "", "prepare"], [237, 2, 1, "", "quantize"]], "neural_compressor.torch.utils": [[238, 0, 0, "-", "auto_accelerator"], [239, 0, 0, "-", "constants"], [240, 0, 0, "-", "environ"], [242, 0, 0, "-", "utility"]], "neural_compressor.torch.utils.auto_accelerator": [[238, 1, 1, "", "AcceleratorRegistry"], [238, 1, 1, "", "Auto_Accelerator"], [238, 1, 1, "", "CPU_Accelerator"], [238, 1, 1, "", "CUDA_Accelerator"], [238, 1, 1, "", "HPU_Accelerator"], [238, 1, 1, "", "XPU_Accelerator"], [238, 2, 1, "", "auto_detect_accelerator"], [238, 2, 1, "", "register_accelerator"]], "neural_compressor.torch.utils.constants": [[239, 1, 1, "", "LoadFormat"]], "neural_compressor.torch.utils.environ": [[240, 2, 1, "", "device_synchronize"], [240, 2, 1, "", "get_accelerator"], [240, 2, 1, "", "get_ipex_version"], [240, 2, 1, "", "get_torch_version"], [240, 2, 1, "", "is_hpex_available"], [240, 2, 1, "", "is_ipex_available"], [240, 2, 1, "", "is_ipex_imported"], [240, 2, 1, "", "is_package_available"], [240, 2, 1, "", "is_transformers_imported"]], "neural_compressor.torch.utils.utility": [[242, 2, 1, "", "dowload_hf_model"], [242, 2, 1, "", "dump_model_op_stats"], [242, 2, 1, "", "fetch_module"], [242, 2, 1, "", "get_double_quant_config_dict"], [242, 2, 1, "", "get_model_device"], [242, 2, 1, "", "get_model_info"], [242, 2, 1, "", "get_processor_type_from_user_config"], [242, 2, 1, "", "get_quantizer"], [242, 2, 1, "", "load_empty_model"], [242, 2, 1, "", "postprocess_model"], [242, 2, 1, "", "register_algo"], [242, 2, 1, "", "set_module"]], "neural_compressor.training": [[243, 1, 1, "", "CallBacks"], [243, 1, 1, "", "CompressionManager"], [243, 2, 1, "", "fit"], [243, 2, 1, "", "prepare_compression"]], "neural_compressor.utils": [[244, 0, 0, "-", "collect_layer_histogram"], [245, 0, 0, "-", "constant"], [246, 0, 0, "-", "create_obj_from_config"], [247, 0, 0, "-", "export"], [252, 0, 0, "-", "kl_divergence"], [253, 0, 0, "-", "load_huggingface"], [254, 0, 0, "-", "logger"], [255, 0, 0, "-", "options"], [256, 0, 0, "-", "pytorch"], [257, 0, 0, "-", "utility"], [258, 0, 0, "-", "weights_details"]], "neural_compressor.utils.collect_layer_histogram": [[244, 1, 1, "", "LayerHistogramCollector"]], "neural_compressor.utils.create_obj_from_config": [[246, 2, 1, "", "create_dataloader"], [246, 2, 1, "", "create_dataset"], [246, 2, 1, "", "create_eval_func"], [246, 2, 1, "", "create_train_func"], [246, 2, 1, "", "get_algorithm"], [246, 2, 1, "", "get_func_from_config"], [246, 2, 1, "", "get_metrics"], [246, 2, 1, "", "get_postprocess"], [246, 2, 1, "", "get_preprocess"]], "neural_compressor.utils.export": [[248, 0, 0, "-", "qlinear2qdq"], [249, 0, 0, "-", "tf2onnx"], [250, 0, 0, "-", "torch2onnx"]], "neural_compressor.utils.export.qlinear2qdq": [[248, 2, 1, "", "check_model"], [248, 2, 1, "", "onnx_qlinear_to_qdq"]], "neural_compressor.utils.export.tf2onnx": [[249, 2, 1, "", "tf_to_fp32_onnx"], [249, 2, 1, "", "tf_to_int8_onnx"]], "neural_compressor.utils.export.torch2onnx": [[250, 2, 1, "", "dynamic_quant_export"], [250, 2, 1, "", "get_node_mapping"], [250, 2, 1, "", "get_quantizable_onnx_ops"], [250, 2, 1, "", "static_quant_export"], [250, 2, 1, "", "torch_to_fp32_onnx"], [250, 2, 1, "", "torch_to_int8_onnx"]], "neural_compressor.utils.kl_divergence": [[252, 1, 1, "", "KL_Divergence"]], "neural_compressor.utils.load_huggingface": [[253, 1, 1, "", "OptimizedModel"], [253, 2, 1, "", "export_compressed_model"], [253, 2, 1, "", "save_for_huggingface_upstream"]], "neural_compressor.utils.logger": [[254, 1, 1, "", "Logger"], [254, 2, 1, "", "debug"], [254, 2, 1, "", "error"], [254, 2, 1, "", "fatal"], [254, 2, 1, "", "info"], [254, 2, 1, "", "log"], [254, 2, 1, "", "warn"], [254, 2, 1, "", "warning"]], "neural_compressor.utils.options": [[255, 1, 1, "", "onnxrt"]], "neural_compressor.utils.pytorch": [[256, 2, 1, "", "is_int8_model"], [256, 2, 1, "", "load"], [256, 2, 1, "", "load_weight_only"], [256, 2, 1, "", "recover_model_from_json"]], "neural_compressor.utils.utility": [[257, 1, 1, "", "CaptureOutputToFile"], [257, 1, 1, "", "CpuInfo"], [257, 2, 1, "", "Dequantize"], [257, 1, 1, "", "DotDict"], [257, 1, 1, "", "GLOBAL_STATE"], [257, 1, 1, "", "LazyImport"], [257, 1, 1, "", "MODE"], [257, 1, 1, "", "OpEntry"], [257, 1, 1, "", "Statistics"], [257, 2, 1, "", "alias_param"], [257, 2, 1, "", "calculate_mse"], [257, 2, 1, "", "check_key_exist"], [257, 2, 1, "", "combine_histogram"], [257, 2, 1, "", "compare_objects"], [257, 2, 1, "", "compute_sparsity"], [257, 2, 1, "", "deep_get"], [257, 2, 1, "", "deep_set"], [257, 2, 1, "", "dequantize_weight"], [257, 2, 1, "", "dump_class_attrs"], [257, 2, 1, "", "dump_data_to_local"], [257, 2, 1, "", "dump_elapsed_time"], [257, 2, 1, "", "dump_table"], [257, 2, 1, "", "dump_table_to_csv"], [257, 2, 1, "", "equal_dicts"], [257, 2, 1, "", "fault_tolerant_file"], [257, 2, 1, "", "get_all_fp32_data"], [257, 2, 1, "", "get_number_of_sockets"], [257, 2, 1, "", "get_op_list"], [257, 2, 1, "", "get_size"], [257, 2, 1, "", "get_tensor_histogram"], [257, 2, 1, "", "get_tensors_info"], [257, 2, 1, "", "get_tuning_history"], [257, 2, 1, "", "get_weights_details"], [257, 2, 1, "", "load_data_from_pkl"], [257, 2, 1, "", "mse_metric_gap"], [257, 2, 1, "", "print_op_list"], [257, 2, 1, "", "print_table"], [257, 2, 1, "", "recover"], [257, 2, 1, "", "set_random_seed"], [257, 2, 1, "", "set_resume_from"], [257, 2, 1, "", "set_tensorboard"], [257, 2, 1, "", "set_workspace"], [257, 2, 1, "", "show_memory_info"], [257, 2, 1, "", "singleton"], [257, 2, 1, "", "str2array"], [257, 2, 1, "", "time_limit"], [257, 2, 1, "", "version1_eq_version2"], [257, 2, 1, "", "version1_gt_version2"], [257, 2, 1, "", "version1_gte_version2"], [257, 2, 1, "", "version1_lt_version2"], [257, 2, 1, "", "version1_lte_version2"]], "neural_compressor.utils.weights_details": [[258, 1, 1, "", "WeightsDetails"], [258, 1, 1, "", "WeightsStatistics"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:function", "3": "py:attribute", "4": "py:data", "5": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "function", "Python function"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "data", "Python data"], "5": ["py", "exception", "Python exception"]}, "titleterms": {"neural_compressor": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259], "algorithm": [0, 1, 2, 3, 4, 78, 79, 80, 81, 82, 83, 84, 85, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 311, 339, 342, 344], "class": [0, 1, 3, 4, 6, 7, 10, 11, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 35, 36, 37, 39, 42, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 82, 84, 85, 88, 89, 90, 93, 94, 95, 99, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 183, 185, 186, 187, 188, 193, 194, 196, 198, 199, 200, 201, 207, 208, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 228, 234, 238, 239, 243, 244, 252, 253, 254, 255, 257, 258, 285], "function": [0, 5, 6, 7, 8, 14, 15, 21, 23, 30, 36, 37, 39, 40, 42, 43, 44, 46, 47, 51, 55, 57, 59, 63, 71, 75, 77, 88, 89, 90, 93, 94, 95, 97, 98, 99, 101, 120, 121, 123, 181, 183, 186, 187, 191, 193, 199, 201, 203, 204, 206, 207, 208, 210, 212, 213, 215, 220, 222, 226, 228, 230, 232, 233, 234, 236, 237, 238, 240, 242, 243, 246, 248, 249, 250, 253, 254, 256, 257, 316], "modul": [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 35, 36, 37, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 183, 185, 186, 187, 188, 191, 192, 193, 194, 196, 198, 199, 200, 201, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 224, 225, 226, 227, 228, 230, 232, 233, 234, 236, 237, 238, 239, 240, 242, 243, 244, 246, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258], "content": [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 35, 36, 37, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 183, 185, 186, 187, 188, 191, 192, 193, 194, 196, 198, 199, 200, 201, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 224, 225, 226, 227, 228, 230, 232, 233, 234, 236, 237, 238, 239, 240, 242, 243, 244, 246, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 284], "fast_bias_correct": 1, "submodul": [2, 9, 12, 18, 27, 31, 34, 38, 45, 49, 67, 73, 81, 83, 91, 96, 100, 105, 129, 140, 147, 152, 157, 158, 166, 178, 184, 189, 190, 195, 197, 202, 205, 209, 219, 223, 229, 235, 241, 247, 251], "smooth_quant": [3, 205, 206, 207, 208], "weight_correct": 4, "benchmark": [5, 8, 274, 295, 310, 328], "common": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 268, 269, 282, 319], "base_config": 6, "base_tun": 7, "subpackag": [9, 17, 32, 38, 67, 78, 86, 87, 100, 140, 157, 158, 189, 223, 231, 251], "tuning_param": 10, "util": [11, 12, 13, 14, 15, 72, 73, 74, 75, 76, 77, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 193, 199, 204, 208, 212, 228, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 290], "constant": [11, 72, 182, 239, 245], "logger": [13, 254, 312], "save_load": [14, 203, 206, 210, 226], "config": [16, 95, 99, 217, 234, 297, 305, 308, 332], "contrib": [17, 18, 19, 20], "strategi": [18, 19, 20, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 302, 341, 344], "sigopt": [19, 341, 344], "tpe": [20, 344], "data": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 183, 286, 287, 317], "dataset": [21, 22, 23, 24, 25, 26, 27, 28, 322], "bert_dataset": 21, "coco_dataset": 22, "attribut": [23, 280], "dummy_dataset": 24, "dummy_dataset_v2": 25, "imagenet_dataset": 26, "style_transfer_dataset": 28, "filter": [29, 30, 31], "coco_filt": 29, "transform": [33, 34, 35, 36, 37, 322, 343], "imagenet_transform": 33, "postprocess": 35, "token": 36, "metric": [39, 40, 41, 42, 43, 44, 45, 46, 322, 327], "bleu": 39, "bleu_util": 40, "coco_label_map": 41, "coco_tool": 42, "evaluate_squad": 43, "f1": 44, "mix_precis": 47, "model": [48, 49, 50, 51, 52, 53, 54, 55, 56, 185, 266, 267, 273, 284, 286, 299, 318, 324, 326, 328, 330, 331, 334, 337, 339, 342, 345], "base_model": 48, "keras_model": 50, "mxnet_model": 52, "nets_factori": 53, "onnx_model": 54, "tensorflow_model": 55, "torch_model": 56, "object": [57, 300, 332], "profil": 58, "quantiz": [59, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 222, 232, 233, 234, 235, 236, 237, 260, 263, 264, 266, 267, 268, 269, 270, 272, 275, 279, 282, 284, 286, 287, 301, 303, 304, 305, 306, 307, 308, 311, 315, 318, 324, 326, 328, 329, 331, 336, 337, 338, 339, 342, 345], "auto": [60, 271, 338, 342, 344], "auto_mixed_precis": 61, "basic": [62, 344], "bayesian": [63, 344], "conserv": [64, 344], "exhaust": [65, 344], "hawq_v2": [66, 344], "mse": [68, 344], "mse_v2": [69, 344], "random": [70, 344], "tuning_sampl": 74, "tuning_spac": 75, "tuning_struct": 76, "tensorflow": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 270, 272, 273, 279, 284, 303, 304, 305, 316, 318, 324, 327, 336, 338, 343, 345], "smoother": [79, 80, 81, 82], "calibr": [79, 286, 311], "core": [80, 200, 218], "scaler": 82, "static_qu": [83, 84, 85, 209, 210, 211, 212], "kera": [84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "layer": [88, 89, 90, 91, 92, 93, 94, 268, 337, 342], "conv2d": 88, "dens": 89, "depthwise_conv2d": 90, "layer_initi": 92, "pool2d": 93, "separable_conv2d": 94, "algorithm_entri": [97, 232], "autotun": [98, 233, 265, 269, 273, 303, 306], "graph_convert": 102, "graph_rewrit": [103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155], "bf16": [103, 104, 105, 265, 329], "bf16_convert": 103, "dequantize_cast_optim": 104, "gener": [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 274, 286], "convert_add_to_biasadd": 106, "convert_layout": 107, "convert_leakyrelu": 108, "convert_nan_to_random": 109, "convert_placeholder_to_const": 110, "dilated_contract": 111, "dummy_biasadd": 112, "expanddims_optim": 113, "fetch_weight_from_reshap": 114, "fold_batch_norm": 115, "fold_const": 116, "fuse_biasadd_add": 117, "fuse_column_wise_mul": 118, "fuse_conv_with_math": 119, "fuse_decomposed_bn": 120, "fuse_decomposed_in": 121, "fuse_gelu": 122, "fuse_layer_norm": 123, "fuse_pad_with_conv": 124, "fuse_pad_with_fp32_conv": 125, "fuse_reshape_transpos": 126, "graph_cse_optim": 127, "grappler_pass": 128, "insert_print_nod": 130, "move_squeeze_after_relu": 131, "pre_optim": 132, "remove_training_nod": 133, "rename_batch_norm": 134, "split_shared_input": 135, "strip_equivalent_nod": 136, "strip_unused_nod": 137, "switch_optim": 138, "graph_bas": 139, "int8": [141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 318, 345], "freeze_fake_qu": 141, "freeze_valu": 142, "fuse_conv_redundant_dequant": 143, "fuse_conv_requant": 144, "fuse_matmul_redundant_dequant": 145, "fuse_matmul_requant": 146, "meta_op_optim": 148, "post_hostconst_convert": 149, "post_quantized_op_cs": 150, "scale_propag": 151, "qdq": [152, 153, 154, 155, 159, 160, 161, 162, 163, 164, 165, 166, 167, 345], "insert_qdq_pattern": 153, "merge_duplicated_qdq": 154, "share_qdq_y_pattern": 155, "graph_util": 156, "quantize_graph": [158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174], "fuse_qdq_bn": 159, "fuse_qdq_concatv2": 160, "fuse_qdq_conv": 161, "fuse_qdq_deconv": 162, "fuse_qdq_in": 163, "fuse_qdq_matmul": 164, "fuse_qdq_pool": 165, "optimize_qdq": 167, "quantize_graph_bas": 168, "quantize_graph_bn": 169, "quantize_graph_concatv2": 170, "quantize_graph_conv": 171, "quantize_graph_for_intel_cpu": 172, "quantize_graph_matmul": 173, "quantize_graph_pool": 174, "quantize_graph_common": 175, "transform_graph": [176, 177, 178, 179, 180], "bias_correct": 176, "graph_transform_bas": 177, "insert_log": 179, "rerange_quantized_concat": 180, "model_wrapp": 186, "torch": [188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 269, 284, 290, 324, 345], "base_algorithm": 188, "layer_wis": [190, 191, 192, 193], "load": [191, 268, 269, 284], "modified_pickl": 192, "except": 192, "mixed_precis": [194, 195, 196], "half_precision_convert": 194, "module_wrapp": 196, "mx_quant": [197, 198, 199], "mx": 198, "pt2e_quant": [200, 201, 202, 203, 204], "half_precision_rewrit": 201, "weight_onli": [213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228], "autoround": [213, 268], "awq": [214, 268], "gptq": [215, 268], "hqq": [216, 217, 218, 219, 220, 221, 222, 268], "bitpack": 216, "optim": [220, 333, 334], "qtensor": 221, "rtn": [225, 268], "teq": [227, 268], "export": [229, 230, 247, 248, 249, 250, 318, 339], "pt2e_export": 230, "load_entri": 236, "auto_acceler": 238, "environ": [240, 324], "train": [243, 272, 279, 282, 309, 316, 328, 334, 336], "collect_layer_histogram": 244, "create_obj_from_config": 246, "qlinear2qdq": 248, "tf2onnx": 249, "torch2onnx": 250, "kl_diverg": 252, "load_huggingfac": 253, "option": [255, 316], "pytorch": [256, 265, 266, 267, 268, 273, 279, 306, 307, 308, 316, 318, 327, 336, 337, 338, 343, 345], "weights_detail": 258, "version": [259, 277], "fp8": [260, 284], "introduct": [260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 279, 282, 285, 286, 287, 310, 311, 313, 315, 316, 318, 320, 323, 327, 329, 330, 331, 332, 333, 334, 336, 337, 339, 341, 342, 343, 344], "support": [260, 265, 266, 268, 269, 272, 274, 281, 282, 285, 287, 310, 311, 313, 315, 316, 318, 320, 323, 324, 327, 329, 330, 331, 332, 333, 334, 336, 337, 339, 342, 343], "paramet": 260, "get": [260, 263, 264, 265, 267, 268, 270, 275, 282, 284, 285, 310, 313, 315, 316, 320, 321, 327, 329, 331, 332, 333, 334, 336], "start": [260, 263, 264, 265, 267, 268, 270, 275, 282, 284, 285, 310, 313, 315, 316, 320, 321, 327, 329, 331, 332, 333, 334, 336], "demo": [260, 274], "usag": [260, 266, 267, 268, 271, 274, 342, 344], "exampl": [260, 263, 264, 265, 267, 268, 270, 271, 279, 282, 285, 293, 310, 313, 315, 316, 317, 318, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 339, 342, 345], "intel": [261, 277, 284, 313, 323, 324, 327, 328, 346], "neural": [261, 277, 282, 284, 313, 323, 324, 327, 328, 334, 341, 346], "compressor": [261, 277, 282, 284, 313, 323, 324, 327, 328, 341, 346], "document": [261, 284, 293, 346], "section": [261, 346], "2": [262, 291, 316, 319, 322, 328, 345], "x": [262, 328], "api": [262, 264, 265, 269, 272, 285, 286, 291, 292, 293, 294, 304, 307, 310, 313, 315, 316, 322, 327, 329, 331, 332, 333, 334], "user": [262, 316, 322, 339], "guid": 262, "overview": [262, 273, 281], "python": [262, 313, 327], "base": [262, 304, 307, 324], "advanc": 262, "topic": 262, "dynam": [263, 279, 282, 336], "microsc": [264, 331], "refer": [264, 268, 279, 311, 312, 331, 334, 336, 339, 342], "mix": [265, 272, 298, 328, 329, 338], "precis": [265, 272, 298, 328, 329, 338], "matrix": [265, 266, 268, 269, 272, 274, 282, 285, 310, 311, 313, 315, 316, 318, 320, 321, 323, 327, 329, 330, 331, 332, 333, 334, 336, 337, 339, 342], "hardwar": [265, 324, 329, 345], "softwar": [265, 277, 324, 329], "request": [265, 281, 329], "fp16": [265, 329], "accuraci": [265, 270, 279, 326, 329, 336, 344], "driven": [265, 329], "smooth": [266, 271, 272, 279, 342], "fix": [266, 271, 342], "alpha": [266, 271, 342], "specifi": [266, 267, 268, 270, 336], "rule": [266, 267, 268, 270, 312, 336], "valid": [266, 324, 342, 345], "framework": [266, 284, 286, 313, 318, 320, 324, 330, 331, 337, 339, 342], "static": [267, 272, 279, 282, 336], "ipex": [267, 279, 336], "backend": [267, 272, 285, 336], "sampl": [267, 286, 321], "pt2e": 267, "weight": [268, 279, 284, 339], "onli": [268, 279, 284, 339], "argument": 268, "save": 268, "wise": [268, 337], "effici": 268, "client": [268, 275], "side": 268, "like": [269, 287], "problem": [269, 282], "without": 270, "awar": [270, 279, 282, 328, 334, 336], "tune": [270, 271, 279, 287, 336, 339, 342, 344], "With": 270, "quant": [271, 342], "us": [271, 274, 284, 287, 313, 324, 327, 342], "determin": [271, 342], "through": [271, 324, 342, 345], "scheme": [272, 279, 336], "approach": [272, 336], "post": [272, 282, 328, 336], "devic": [272, 336], "how": [273, 286, 287], "work": [273, 285, 336], "case": 274, "dump": 274, "throughput": 274, "latenc": 274, "summari": [274, 287], "design": [276, 286, 314, 344], "architectur": [276, 314, 323, 324], "workflow": [276, 314], "map": 277, "between": [277, 322], "gaudi": 277, "stack": 277, "fundament": [279, 336, 342], "symmetr": 279, "asymmetr": 279, "per": [279, 342], "tensor": [279, 342], "channel": [279, 342], "matmul": [279, 342], "limit": [279, 342], "contributor": [280, 281], "coven": [280, 281], "code": [280, 281, 312, 328, 339], "conduct": [280, 281], "our": [280, 342], "pledg": 280, "standard": 280, "respons": 280, "scope": [280, 334], "enforc": 280, "contribut": 281, "guidelin": 281, "creat": 281, "pull": 281, "step": 281, "checklist": 281, "templat": 281, "accept": 281, "criteria": [281, 334, 344], "statu": 281, "check": 281, "fx": 282, "mode": [282, 345], "note": [282, 340], "detail": 282, "secur": [283, 316], "polici": [283, 344], "report": 283, "vulner": 283, "what": 284, "": [284, 324], "new": [284, 285, 287, 344], "instal": [284, 324], "cpu": [284, 324, 345], "docker": [284, 324], "imag": [284, 324], "hpu": [284, 324], "intel_extension_for_pytorch": [284, 324], "gpu": [284, 324], "other": [284, 324], "platform": [284, 324, 341], "from": [284, 286, 324, 328], "pypi": 284, "larg": [284, 326, 334], "languag": [284, 326, 334], "llm": [284, 326], "select": 284, "public": [284, 312, 335], "event": [284, 335], "addit": 284, "commun": 284, "adaptor": [285, 286, 288], "flow": [285, 336], "queri": 285, "background": [285, 312], "ad": 285, "capabl": [285, 339], "implement": [285, 286], "onnxrtadaptor": 285, "add": 286, "an": 286, "list": [286, 317, 343], "need": 286, "yaml": [286, 316, 320], "query_fw_cap": 286, "accord": [286, 287], "tune_cfg": 286, "prepar": [286, 341], "fp32": [286, 318], "graph": 286, "run": 286, "iter": 286, "oper": [286, 287], "calcul": 286, "rang": 286, "type": [287, 312, 334], "int4": 287, "few": 287, "line": 287, "chang": [287, 322, 340], "defin": [287, 316], "abil": 287, "specif": 287, "invok": 287, "kernel": 287, "configur": [287, 316, 320, 341], "onnx": [289, 324, 336, 337, 345], "runtim": [289, 324, 336, 337, 345], "0": [291, 292, 345], "3": [292, 319, 335], "compress": [296, 339], "inc": 312, "convent": 312, "import": 312, "string": 312, "annot": 312, "comment": 312, "todo": 312, "intern": 312, "interfac": 312, "folder": 312, "structur": 312, "recommend": 312, "v": 312, "set": 312, "json": 312, "dataload": 313, "build": [313, 319, 327], "custom": [313, 327, 344], "distil": [315, 328, 345], "distribut": [316, 344], "infer": 316, "evalu": 316, "featur": [316, 320, 321, 323, 336], "1": [316, 319, 322, 328, 345], "pure": 316, "horovodrun": 316, "execut": 316, "releas": [317, 340], "appendix": 318, "op": 318, "frequent": 319, "ask": 319, "question": 319, "issu": [319, 340], "4": [319, 335], "5": 319, "file": 320, "quick": 321, "incompat": [322, 340], "v1": 322, "face": 322, "built": [322, 324, 327], "infrastructur": 323, "prerequisit": 324, "binari": 324, "sourc": 324, "ai": 324, "kit": 324, "system": 324, "requir": 324, "heterogen": 324, "two": 324, "comput": 324, "engin": [324, 342], "mme": 324, "tpc": 324, "64": 324, "compat": 324, "processor": 324, "xe": 324, "multipl": [324, 332, 345], "vendor": 324, "legal": 325, "inform": 325, "licens": 325, "citat": 325, "trademark": 325, "recip": [326, 336], "mxnet": [327, 336, 343], "onnxrt": [327, 343], "migrat": 328, "prune": [328, 334, 345], "orchestr": [328, 333], "dure": [329, 338], "singl": 332, "One": 333, "shot": 333, "network": 334, "pattern": 334, "schedul": 334, "sparsiti": 334, "decai": 334, "regular": 334, "retrain": 334, "free": 334, "spars": 334, "deploy": 334, "hyperparamet": 334, "full": 335, "82": 335, "2024": 335, "2023": 335, "25": 335, "2022": 335, "35": 335, "2021": 335, "15": [335, 345], "2018": 335, "2020": 335, "lwq": 337, "turn": 338, "off": 338, "woq": [339, 345], "known": 340, "perform": 341, "benefit": 341, "comparison": 341, "differ": 341, "smoothquant": 342, "enhanc": 342, "entir": 342, "each": 342, "block": 342, "space": 344, "exit": 344, "process": 344, "ptq": 345, "qat": 345, "17": 345, "knowledg": 345}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"neural_compressor.algorithm.algorithm": [[0, "module-neural_compressor.algorithm.algorithm"]], "Classes": [[0, "classes"], [1, "classes"], [3, "classes"], [4, "classes"], [6, "classes"], [7, "classes"], [10, "classes"], [11, "classes"], [13, "classes"], [15, "classes"], [16, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [33, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [39, "classes"], [42, "classes"], [46, "classes"], [48, "classes"], [50, "classes"], [51, "classes"], [52, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [74, "classes"], [75, "classes"], [76, "classes"], [77, "classes"], [79, "classes"], [80, "classes"], [82, "classes"], [84, "classes"], [85, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [93, "classes"], [94, "classes"], [95, "classes"], [99, "classes"], [102, "classes"], [103, "classes"], [104, "classes"], [106, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [110, "classes"], [111, "classes"], [112, "classes"], [113, "classes"], [114, "classes"], [115, "classes"], [116, "classes"], [117, "classes"], [118, "classes"], [119, "classes"], [120, "classes"], [121, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [145, "classes"], [146, "classes"], [148, "classes"], [149, "classes"], [150, "classes"], [151, "classes"], [153, "classes"], [154, "classes"], [155, "classes"], [156, "classes"], [159, "classes"], [160, "classes"], [161, "classes"], [162, "classes"], [163, "classes"], [164, "classes"], [165, "classes"], [167, "classes"], [168, "classes"], [169, "classes"], [170, "classes"], [171, "classes"], [172, "classes"], [173, "classes"], [174, "classes"], [175, "classes"], [176, "classes"], [177, "classes"], [179, "classes"], [180, "classes"], [183, "classes"], [185, "classes"], [186, "classes"], [187, "classes"], [188, "classes"], [193, "classes"], [194, "classes"], [196, "classes"], [198, "classes"], [199, "classes"], [200, "classes"], [201, "classes"], [207, "classes"], [208, "classes"], [211, "classes"], [212, "classes"], [213, "classes"], [214, "classes"], [215, "classes"], [216, "classes"], [217, "classes"], [218, "classes"], [221, "classes"], [222, "classes"], [224, "classes"], [225, "classes"], [226, "classes"], [227, "classes"], [228, "classes"], [234, "classes"], [238, "classes"], [239, "classes"], [243, "classes"], [244, "classes"], [252, "classes"], [253, "classes"], [254, "classes"], [255, "classes"], [257, "classes"], [258, "classes"]], "Functions": [[0, "functions"], [5, "functions"], [6, "functions"], [7, "functions"], [8, "functions"], [14, "functions"], [15, "functions"], [21, "functions"], [23, "functions"], [30, "functions"], [36, "functions"], [37, "functions"], [39, "functions"], [40, "functions"], [42, "functions"], [43, "functions"], [44, "functions"], [46, "functions"], [47, "functions"], [51, "functions"], [55, "functions"], [57, "functions"], [59, "functions"], [63, "functions"], [71, "functions"], [75, "functions"], [77, "functions"], [88, "functions"], [89, "functions"], [90, "functions"], [93, "functions"], [94, "functions"], [95, "functions"], [97, "functions"], [98, "functions"], [99, "functions"], [101, "functions"], [120, "functions"], [121, "functions"], [123, "functions"], [181, "functions"], [183, "functions"], [186, "functions"], [187, "functions"], [191, "functions"], [193, "functions"], [199, "functions"], [201, "functions"], [203, "functions"], [204, "functions"], [206, "functions"], [207, "functions"], [208, "functions"], [210, "functions"], [212, "functions"], [213, "functions"], [215, "functions"], [220, "functions"], [222, "functions"], [226, "functions"], [228, "functions"], [230, "functions"], [232, "functions"], [233, "functions"], [234, "functions"], [236, "functions"], [237, "functions"], [238, "functions"], [240, "functions"], [242, "functions"], [243, "functions"], [246, "functions"], [248, "functions"], [249, "functions"], [250, "functions"], [253, "functions"], [254, "functions"], [256, "functions"], [257, "functions"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [6, "module-contents"], [7, "module-contents"], [8, "module-contents"], [10, "module-contents"], [11, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [33, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [39, "module-contents"], [40, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [46, "module-contents"], [47, "module-contents"], [48, "module-contents"], [50, "module-contents"], [51, "module-contents"], [52, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [74, "module-contents"], [75, "module-contents"], [76, "module-contents"], [77, "module-contents"], [79, "module-contents"], [80, "module-contents"], [82, "module-contents"], [84, "module-contents"], [85, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [101, "module-contents"], [102, "module-contents"], [103, "module-contents"], [104, "module-contents"], [106, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [110, "module-contents"], [111, "module-contents"], [112, "module-contents"], [113, "module-contents"], [114, "module-contents"], [115, "module-contents"], [116, "module-contents"], [117, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [121, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [145, "module-contents"], [146, "module-contents"], [148, "module-contents"], [149, "module-contents"], [150, "module-contents"], [151, "module-contents"], [153, "module-contents"], [154, "module-contents"], [155, "module-contents"], [156, "module-contents"], [159, "module-contents"], [160, "module-contents"], [161, "module-contents"], [162, "module-contents"], [163, "module-contents"], [164, "module-contents"], [165, "module-contents"], [167, "module-contents"], [168, "module-contents"], [169, "module-contents"], [170, "module-contents"], [171, "module-contents"], [172, "module-contents"], [173, "module-contents"], [174, "module-contents"], [175, "module-contents"], [176, "module-contents"], [177, "module-contents"], [179, "module-contents"], [180, "module-contents"], [181, "module-contents"], [183, "module-contents"], [185, "module-contents"], [186, "module-contents"], [187, "module-contents"], [188, "module-contents"], [191, "module-contents"], [192, "module-contents"], [193, "module-contents"], [194, "module-contents"], [196, "module-contents"], [198, "module-contents"], [199, "module-contents"], [200, "module-contents"], [201, "module-contents"], [203, "module-contents"], [204, "module-contents"], [206, "module-contents"], [207, "module-contents"], [208, "module-contents"], [210, "module-contents"], [211, "module-contents"], [212, "module-contents"], [213, "module-contents"], [214, "module-contents"], [215, "module-contents"], [216, "module-contents"], [217, "module-contents"], [218, "module-contents"], [220, "module-contents"], [221, "module-contents"], [222, "module-contents"], [224, "module-contents"], [225, "module-contents"], [226, "module-contents"], [227, "module-contents"], [228, "module-contents"], [230, "module-contents"], [232, "module-contents"], [233, "module-contents"], [234, "module-contents"], [236, "module-contents"], [237, "module-contents"], [238, "module-contents"], [239, "module-contents"], [240, "module-contents"], [242, "module-contents"], [243, "module-contents"], [244, "module-contents"], [246, "module-contents"], [248, "module-contents"], [249, "module-contents"], [250, "module-contents"], [252, "module-contents"], [253, "module-contents"], [254, "module-contents"], [255, "module-contents"], [256, "module-contents"], [257, "module-contents"], [258, "module-contents"]], "neural_compressor.algorithm.fast_bias_correction": [[1, "module-neural_compressor.algorithm.fast_bias_correction"]], "neural_compressor.algorithm": [[2, "module-neural_compressor.algorithm"]], "Submodules": [[2, "submodules"], [9, "submodules"], [12, "submodules"], [18, "submodules"], [27, "submodules"], [31, "submodules"], [34, "submodules"], [38, "submodules"], [45, "submodules"], [49, "submodules"], [67, "submodules"], [73, "submodules"], [81, "submodules"], [83, "submodules"], [91, "submodules"], [96, "submodules"], [100, "submodules"], [105, "submodules"], [129, "submodules"], [140, "submodules"], [147, "submodules"], [152, "submodules"], [157, "submodules"], [158, "submodules"], [166, "submodules"], [178, "submodules"], [184, "submodules"], [189, "submodules"], [190, "submodules"], [195, "submodules"], [197, "submodules"], [202, "submodules"], [205, "submodules"], [209, "submodules"], [219, "submodules"], [223, "submodules"], [229, "submodules"], [235, "submodules"], [241, "submodules"], [247, "submodules"], [251, "submodules"]], "neural_compressor.algorithm.smooth_quant": [[3, "module-neural_compressor.algorithm.smooth_quant"]], "neural_compressor.algorithm.weight_correction": [[4, "module-neural_compressor.algorithm.weight_correction"]], "neural_compressor.benchmark": [[5, "module-neural_compressor.benchmark"]], "neural_compressor.common.base_config": [[6, "module-neural_compressor.common.base_config"]], "neural_compressor.common.base_tuning": [[7, "module-neural_compressor.common.base_tuning"]], "neural_compressor.common.benchmark": [[8, "module-neural_compressor.common.benchmark"]], "neural_compressor.common": [[9, "module-neural_compressor.common"]], "Subpackages": [[9, "subpackages"], [17, "subpackages"], [32, "subpackages"], [38, "subpackages"], [67, "subpackages"], [78, "subpackages"], [86, "subpackages"], [87, "subpackages"], [100, "subpackages"], [140, "subpackages"], [157, "subpackages"], [158, "subpackages"], [189, "subpackages"], [223, "subpackages"], [231, "subpackages"], [251, "subpackages"]], "neural_compressor.common.tuning_param": [[10, "module-neural_compressor.common.tuning_param"]], "neural_compressor.common.utils.constants": [[11, "module-neural_compressor.common.utils.constants"]], "neural_compressor.common.utils": [[12, "module-neural_compressor.common.utils"]], "neural_compressor.common.utils.logger": [[13, "module-neural_compressor.common.utils.logger"]], "neural_compressor.common.utils.save_load": [[14, "module-neural_compressor.common.utils.save_load"]], "neural_compressor.common.utils.utility": [[15, "module-neural_compressor.common.utils.utility"]], "neural_compressor.config": [[16, "module-neural_compressor.config"]], "neural_compressor.contrib": [[17, "module-neural_compressor.contrib"]], "neural_compressor.contrib.strategy": [[18, "module-neural_compressor.contrib.strategy"]], "neural_compressor.contrib.strategy.sigopt": [[19, "module-neural_compressor.contrib.strategy.sigopt"]], "neural_compressor.contrib.strategy.tpe": [[20, "module-neural_compressor.contrib.strategy.tpe"]], "neural_compressor.data.datasets.bert_dataset": [[21, "module-neural_compressor.data.datasets.bert_dataset"]], "neural_compressor.data.datasets.coco_dataset": [[22, "module-neural_compressor.data.datasets.coco_dataset"]], "neural_compressor.data.datasets.dataset": [[23, "module-neural_compressor.data.datasets.dataset"]], "Attributes": [[23, "attributes"]], "neural_compressor.data.datasets.dummy_dataset": [[24, "module-neural_compressor.data.datasets.dummy_dataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[25, "module-neural_compressor.data.datasets.dummy_dataset_v2"]], "neural_compressor.data.datasets.imagenet_dataset": [[26, "module-neural_compressor.data.datasets.imagenet_dataset"]], "neural_compressor.data.datasets": [[27, "module-neural_compressor.data.datasets"]], "neural_compressor.data.datasets.style_transfer_dataset": [[28, "module-neural_compressor.data.datasets.style_transfer_dataset"]], "neural_compressor.data.filters.coco_filter": [[29, "module-neural_compressor.data.filters.coco_filter"]], "neural_compressor.data.filters.filter": [[30, "module-neural_compressor.data.filters.filter"]], "neural_compressor.data.filters": [[31, "module-neural_compressor.data.filters"]], "neural_compressor.data": [[32, "module-neural_compressor.data"]], "neural_compressor.data.transforms.imagenet_transform": [[33, "module-neural_compressor.data.transforms.imagenet_transform"]], "neural_compressor.data.transforms": [[34, "module-neural_compressor.data.transforms"]], "neural_compressor.data.transforms.postprocess": [[35, "module-neural_compressor.data.transforms.postprocess"]], "neural_compressor.data.transforms.tokenization": [[36, "module-neural_compressor.data.transforms.tokenization"]], "neural_compressor.data.transforms.transform": [[37, "module-neural_compressor.data.transforms.transform"]], "neural_compressor": [[38, "module-neural_compressor"]], "neural_compressor.metric.bleu": [[39, "module-neural_compressor.metric.bleu"]], "neural_compressor.metric.bleu_util": [[40, "module-neural_compressor.metric.bleu_util"]], "neural_compressor.metric.coco_label_map": [[41, "module-neural_compressor.metric.coco_label_map"]], "neural_compressor.metric.coco_tools": [[42, "module-neural_compressor.metric.coco_tools"]], "neural_compressor.metric.evaluate_squad": [[43, "module-neural_compressor.metric.evaluate_squad"]], "neural_compressor.metric.f1": [[44, "module-neural_compressor.metric.f1"]], "neural_compressor.metric": [[45, "module-neural_compressor.metric"]], "neural_compressor.metric.metric": [[46, "module-neural_compressor.metric.metric"]], "neural_compressor.mix_precision": [[47, "module-neural_compressor.mix_precision"]], "neural_compressor.model.base_model": [[48, "module-neural_compressor.model.base_model"]], "neural_compressor.model": [[49, "module-neural_compressor.model"]], "neural_compressor.model.keras_model": [[50, "module-neural_compressor.model.keras_model"]], "neural_compressor.model.model": [[51, "module-neural_compressor.model.model"]], "neural_compressor.model.mxnet_model": [[52, "module-neural_compressor.model.mxnet_model"]], "neural_compressor.model.nets_factory": [[53, "module-neural_compressor.model.nets_factory"]], "neural_compressor.model.onnx_model": [[54, "module-neural_compressor.model.onnx_model"]], "neural_compressor.model.tensorflow_model": [[55, "module-neural_compressor.model.tensorflow_model"]], "neural_compressor.model.torch_model": [[56, "module-neural_compressor.model.torch_model"]], "neural_compressor.objective": [[57, "module-neural_compressor.objective"]], "neural_compressor.profiling": [[58, "module-neural_compressor.profiling"]], "neural_compressor.quantization": [[59, "module-neural_compressor.quantization"]], "neural_compressor.strategy.auto": [[60, "module-neural_compressor.strategy.auto"]], "neural_compressor.strategy.auto_mixed_precision": [[61, "module-neural_compressor.strategy.auto_mixed_precision"]], "neural_compressor.strategy.basic": [[62, "module-neural_compressor.strategy.basic"]], "neural_compressor.strategy.bayesian": [[63, "module-neural_compressor.strategy.bayesian"]], "neural_compressor.strategy.conservative": [[64, "module-neural_compressor.strategy.conservative"]], "neural_compressor.strategy.exhaustive": [[65, "module-neural_compressor.strategy.exhaustive"]], "neural_compressor.strategy.hawq_v2": [[66, "module-neural_compressor.strategy.hawq_v2"]], "neural_compressor.strategy": [[67, "module-neural_compressor.strategy"]], "neural_compressor.strategy.mse": [[68, "module-neural_compressor.strategy.mse"]], "neural_compressor.strategy.mse_v2": [[69, "module-neural_compressor.strategy.mse_v2"]], "neural_compressor.strategy.random": [[70, "module-neural_compressor.strategy.random"]], "neural_compressor.strategy.strategy": [[71, "module-neural_compressor.strategy.strategy"]], "neural_compressor.strategy.utils.constant": [[72, "module-neural_compressor.strategy.utils.constant"]], "neural_compressor.strategy.utils": [[73, "module-neural_compressor.strategy.utils"]], "neural_compressor.strategy.utils.tuning_sampler": [[74, "module-neural_compressor.strategy.utils.tuning_sampler"]], "neural_compressor.strategy.utils.tuning_space": [[75, "module-neural_compressor.strategy.utils.tuning_space"]], "neural_compressor.strategy.utils.tuning_structs": [[76, "module-neural_compressor.strategy.utils.tuning_structs"]], "neural_compressor.strategy.utils.utility": [[77, "module-neural_compressor.strategy.utils.utility"]], "neural_compressor.tensorflow.algorithms": [[78, "module-neural_compressor.tensorflow.algorithms"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[79, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[80, "module-neural_compressor.tensorflow.algorithms.smoother.core"]], "neural_compressor.tensorflow.algorithms.smoother": [[81, "module-neural_compressor.tensorflow.algorithms.smoother"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[82, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"]], "neural_compressor.tensorflow.algorithms.static_quant": [[83, "module-neural_compressor.tensorflow.algorithms.static_quant"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[84, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"]], "neural_compressor.tensorflow.algorithms.static_quant.tensorflow": [[85, "module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow"]], "neural_compressor.tensorflow": [[86, "module-neural_compressor.tensorflow"]], "neural_compressor.tensorflow.keras": [[87, "module-neural_compressor.tensorflow.keras"]], "neural_compressor.tensorflow.keras.layers.conv2d": [[88, "module-neural_compressor.tensorflow.keras.layers.conv2d"]], "neural_compressor.tensorflow.keras.layers.dense": [[89, "module-neural_compressor.tensorflow.keras.layers.dense"]], "neural_compressor.tensorflow.keras.layers.depthwise_conv2d": [[90, "module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d"]], "neural_compressor.tensorflow.keras.layers": [[91, "module-neural_compressor.tensorflow.keras.layers"]], "neural_compressor.tensorflow.keras.layers.layer_initializer": [[92, "module-neural_compressor.tensorflow.keras.layers.layer_initializer"]], "neural_compressor.tensorflow.keras.layers.pool2d": [[93, "module-neural_compressor.tensorflow.keras.layers.pool2d"]], "neural_compressor.tensorflow.keras.layers.separable_conv2d": [[94, "module-neural_compressor.tensorflow.keras.layers.separable_conv2d"]], "neural_compressor.tensorflow.keras.quantization.config": [[95, "module-neural_compressor.tensorflow.keras.quantization.config"]], "neural_compressor.tensorflow.keras.quantization": [[96, "module-neural_compressor.tensorflow.keras.quantization"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[97, "module-neural_compressor.tensorflow.quantization.algorithm_entry"]], "neural_compressor.tensorflow.quantization.autotune": [[98, "module-neural_compressor.tensorflow.quantization.autotune"]], "neural_compressor.tensorflow.quantization.config": [[99, "module-neural_compressor.tensorflow.quantization.config"]], "neural_compressor.tensorflow.quantization": [[100, "module-neural_compressor.tensorflow.quantization"]], "neural_compressor.tensorflow.quantization.quantize": [[101, "module-neural_compressor.tensorflow.quantization.quantize"]], "neural_compressor.tensorflow.quantization.utils.graph_converter": [[102, "module-neural_compressor.tensorflow.quantization.utils.graph_converter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert": [[103, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[104, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16": [[105, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[106, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[107, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[108, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[109, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[110, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[111, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[112, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[113, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[114, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[115, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[116, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[117, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[118, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[119, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[120, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[121, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[122, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[123, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[124, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[125, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[126, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[127, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[128, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[129, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[130, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[131, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[132, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[133, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[134, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[135, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[136, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[137, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[138, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[139, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[140, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant": [[141, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value": [[142, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[143, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize": [[144, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[145, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize": [[146, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8": [[147, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer": [[148, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter": [[149, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse": [[150, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation": [[151, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq": [[152, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern": [[153, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq": [[154, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern": [[155, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[156, "module-neural_compressor.tensorflow.quantization.utils.graph_util"]], "neural_compressor.tensorflow.quantization.utils": [[157, "module-neural_compressor.tensorflow.quantization.utils"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph": [[158, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn": [[159, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2": [[160, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv": [[161, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv": [[162, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in": [[163, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul": [[164, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling": [[165, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq": [[166, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq": [[167, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base": [[168, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn": [[169, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2": [[170, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv": [[171, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu": [[172, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul": [[173, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling": [[174, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[175, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction": [[176, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base": [[177, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base"]], "neural_compressor.tensorflow.quantization.utils.transform_graph": [[178, "module-neural_compressor.tensorflow.quantization.utils.transform_graph"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging": [[179, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat": [[180, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat"]], "neural_compressor.tensorflow.quantization.utils.utility": [[181, "module-neural_compressor.tensorflow.quantization.utils.utility"]], "neural_compressor.tensorflow.utils.constants": [[182, "module-neural_compressor.tensorflow.utils.constants"]], "neural_compressor.tensorflow.utils.data": [[183, "module-neural_compressor.tensorflow.utils.data"]], "neural_compressor.tensorflow.utils": [[184, "module-neural_compressor.tensorflow.utils"]], "neural_compressor.tensorflow.utils.model": [[185, "module-neural_compressor.tensorflow.utils.model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[186, "module-neural_compressor.tensorflow.utils.model_wrappers"]], "neural_compressor.tensorflow.utils.utility": [[187, "module-neural_compressor.tensorflow.utils.utility"]], "neural_compressor.torch.algorithms.base_algorithm": [[188, "module-neural_compressor.torch.algorithms.base_algorithm"]], "neural_compressor.torch.algorithms": [[189, "module-neural_compressor.torch.algorithms"]], "neural_compressor.torch.algorithms.layer_wise": [[190, "module-neural_compressor.torch.algorithms.layer_wise"]], "neural_compressor.torch.algorithms.layer_wise.load": [[191, "module-neural_compressor.torch.algorithms.layer_wise.load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[192, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"]], "Exceptions": [[192, "exceptions"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[193, "module-neural_compressor.torch.algorithms.layer_wise.utils"]], "neural_compressor.torch.algorithms.mixed_precision.half_precision_convert": [[194, "module-neural_compressor.torch.algorithms.mixed_precision.half_precision_convert"]], "neural_compressor.torch.algorithms.mixed_precision": [[195, "module-neural_compressor.torch.algorithms.mixed_precision"]], "neural_compressor.torch.algorithms.mixed_precision.module_wrappers": [[196, "module-neural_compressor.torch.algorithms.mixed_precision.module_wrappers"]], "neural_compressor.torch.algorithms.mx_quant": [[197, "module-neural_compressor.torch.algorithms.mx_quant"]], "neural_compressor.torch.algorithms.mx_quant.mx": [[198, "module-neural_compressor.torch.algorithms.mx_quant.mx"]], "neural_compressor.torch.algorithms.mx_quant.utils": [[199, "module-neural_compressor.torch.algorithms.mx_quant.utils"]], "neural_compressor.torch.algorithms.pt2e_quant.core": [[200, "module-neural_compressor.torch.algorithms.pt2e_quant.core"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter": [[201, "module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter"]], "neural_compressor.torch.algorithms.pt2e_quant": [[202, "module-neural_compressor.torch.algorithms.pt2e_quant"]], "neural_compressor.torch.algorithms.pt2e_quant.save_load": [[203, "module-neural_compressor.torch.algorithms.pt2e_quant.save_load"]], "neural_compressor.torch.algorithms.pt2e_quant.utility": [[204, "module-neural_compressor.torch.algorithms.pt2e_quant.utility"]], "neural_compressor.torch.algorithms.smooth_quant": [[205, "module-neural_compressor.torch.algorithms.smooth_quant"]], "neural_compressor.torch.algorithms.smooth_quant.save_load": [[206, "module-neural_compressor.torch.algorithms.smooth_quant.save_load"]], "neural_compressor.torch.algorithms.smooth_quant.smooth_quant": [[207, "module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant"]], "neural_compressor.torch.algorithms.smooth_quant.utility": [[208, "module-neural_compressor.torch.algorithms.smooth_quant.utility"]], "neural_compressor.torch.algorithms.static_quant": [[209, "module-neural_compressor.torch.algorithms.static_quant"]], "neural_compressor.torch.algorithms.static_quant.save_load": [[210, "module-neural_compressor.torch.algorithms.static_quant.save_load"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[211, "module-neural_compressor.torch.algorithms.static_quant.static_quant"]], "neural_compressor.torch.algorithms.static_quant.utility": [[212, "module-neural_compressor.torch.algorithms.static_quant.utility"]], "neural_compressor.torch.algorithms.weight_only.autoround": [[213, "module-neural_compressor.torch.algorithms.weight_only.autoround"]], "neural_compressor.torch.algorithms.weight_only.awq": [[214, "module-neural_compressor.torch.algorithms.weight_only.awq"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[215, "module-neural_compressor.torch.algorithms.weight_only.gptq"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[216, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[217, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[218, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[219, "module-neural_compressor.torch.algorithms.weight_only.hqq"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[220, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[221, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[222, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"]], "neural_compressor.torch.algorithms.weight_only": [[223, "module-neural_compressor.torch.algorithms.weight_only"]], "neural_compressor.torch.algorithms.weight_only.modules": [[224, "module-neural_compressor.torch.algorithms.weight_only.modules"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[225, "module-neural_compressor.torch.algorithms.weight_only.rtn"]], "neural_compressor.torch.algorithms.weight_only.save_load": [[226, "module-neural_compressor.torch.algorithms.weight_only.save_load"]], "neural_compressor.torch.algorithms.weight_only.teq": [[227, "module-neural_compressor.torch.algorithms.weight_only.teq"]], "neural_compressor.torch.algorithms.weight_only.utility": [[228, "module-neural_compressor.torch.algorithms.weight_only.utility"]], "neural_compressor.torch.export": [[229, "module-neural_compressor.torch.export"]], "neural_compressor.torch.export.pt2e_export": [[230, "module-neural_compressor.torch.export.pt2e_export"]], "neural_compressor.torch": [[231, "module-neural_compressor.torch"]], "neural_compressor.torch.quantization.algorithm_entry": [[232, "module-neural_compressor.torch.quantization.algorithm_entry"]], "neural_compressor.torch.quantization.autotune": [[233, "module-neural_compressor.torch.quantization.autotune"]], "neural_compressor.torch.quantization.config": [[234, "module-neural_compressor.torch.quantization.config"]], "neural_compressor.torch.quantization": [[235, "module-neural_compressor.torch.quantization"]], "neural_compressor.torch.quantization.load_entry": [[236, "module-neural_compressor.torch.quantization.load_entry"]], "neural_compressor.torch.quantization.quantize": [[237, "module-neural_compressor.torch.quantization.quantize"]], "neural_compressor.torch.utils.auto_accelerator": [[238, "module-neural_compressor.torch.utils.auto_accelerator"]], "neural_compressor.torch.utils.constants": [[239, "module-neural_compressor.torch.utils.constants"]], "neural_compressor.torch.utils.environ": [[240, "module-neural_compressor.torch.utils.environ"]], "neural_compressor.torch.utils": [[241, "module-neural_compressor.torch.utils"]], "neural_compressor.torch.utils.utility": [[242, "module-neural_compressor.torch.utils.utility"]], "neural_compressor.training": [[243, "module-neural_compressor.training"]], "neural_compressor.utils.collect_layer_histogram": [[244, "module-neural_compressor.utils.collect_layer_histogram"]], "neural_compressor.utils.constant": [[245, "module-neural_compressor.utils.constant"]], "neural_compressor.utils.create_obj_from_config": [[246, "module-neural_compressor.utils.create_obj_from_config"]], "neural_compressor.utils.export": [[247, "module-neural_compressor.utils.export"]], "neural_compressor.utils.export.qlinear2qdq": [[248, "module-neural_compressor.utils.export.qlinear2qdq"]], "neural_compressor.utils.export.tf2onnx": [[249, "module-neural_compressor.utils.export.tf2onnx"]], "neural_compressor.utils.export.torch2onnx": [[250, "module-neural_compressor.utils.export.torch2onnx"]], "neural_compressor.utils": [[251, "module-neural_compressor.utils"]], "neural_compressor.utils.kl_divergence": [[252, "module-neural_compressor.utils.kl_divergence"]], "neural_compressor.utils.load_huggingface": [[253, "module-neural_compressor.utils.load_huggingface"]], "neural_compressor.utils.logger": [[254, "module-neural_compressor.utils.logger"]], "neural_compressor.utils.options": [[255, "module-neural_compressor.utils.options"]], "neural_compressor.utils.pytorch": [[256, "module-neural_compressor.utils.pytorch"]], "neural_compressor.utils.utility": [[257, "module-neural_compressor.utils.utility"]], "neural_compressor.utils.weights_details": [[258, "module-neural_compressor.utils.weights_details"]], "neural_compressor.version": [[259, "module-neural_compressor.version"]], "FP8 Quantization": [[260, "fp8-quantization"], [284, "fp8-quantization"]], "Introduction": [[260, "introduction"], [263, "introduction"], [264, "introduction"], [265, "introduction"], [266, "introduction"], [267, "introduction"], [268, "introduction"], [269, "introduction"], [270, "introduction"], [271, "introduction"], [272, "introduction"], [274, "introduction"], [275, "introduction"], [279, "introduction"], [282, "introduction"], [285, "introduction"], [286, "introduction"], [287, "introduction"], [310, "introduction"], [311, "introduction"], [313, "introduction"], [315, "introduction"], [316, "introduction"], [318, "introduction"], [320, "introduction"], [323, "introduction"], [327, "introduction"], [329, "introduction"], [330, "introduction"], [331, "introduction"], [332, "introduction"], [333, "introduction"], [334, "introduction"], [337, "introduction"], [339, "introduction"], [341, "introduction"], [342, "introduction"], [343, "introduction"], [344, "introduction"]], "Supported Parameters": [[260, "supported-parameters"]], "Get Start with FP8 Quantization": [[260, "get-start-with-fp8-quantization"]], "Demo Usage": [[260, "demo-usage"]], "Examples": [[260, "examples"], [263, "examples"], [264, "examples"], [265, "examples"], [268, "examples"], [270, "examples"], [271, "examples"], [282, "examples"], [310, "examples"], [313, "examples"], [315, "examples"], [316, "examples"], [317, "examples"], [318, "examples"], [328, "examples"], [329, "examples"], [330, "examples"], [331, "examples"], [333, "examples"], [334, "examples"], [336, "examples"], [337, "examples"], [339, "examples"]], "Intel\u00ae Neural Compressor Documentation": [[261, "intel-neural-compressor-documentation"], [346, "intel-neural-compressor-documentation"]], "Sections": [[261, "sections"], [346, "sections"]], "2.X API User Guide": [[262, "x-api-user-guide"]], "Overview": [[262, "overview"], [273, "overview"]], "Python-based APIs": [[262, "python-based-apis"]], "Advanced Topics": [[262, "advanced-topics"]], "Dynamic Quantization": [[263, "dynamic-quantization"], [279, "dynamic-quantization"], [282, "dynamic-quantization"]], "Getting Started with Dynamic Quantization": [[263, "getting-started-with-dynamic-quantization"]], "Microscaling Quantization": [[264, "microscaling-quantization"], [331, "microscaling-quantization"]], "Get Started with Microscaling Quantization API": [[264, "get-started-with-microscaling-quantization-api"], [331, "get-started-with-microscaling-quantization-api"]], "Reference": [[264, "reference"], [268, "reference"], [279, "reference"], [311, "reference"], [312, "reference"], [331, "reference"], [334, "reference"], [336, "reference"], [339, "reference"], [342, "reference"]], "PyTorch Mixed Precision": [[265, "pytorch-mixed-precision"]], "Mixed Precision Support Matrix": [[265, "mixed-precision-support-matrix"], [329, "mixed-precision-support-matrix"]], "Hardware and Software requests for BF16": [[265, "hardware-and-software-requests-for-bf16"], [329, "hardware-and-software-requests-for-bf16"]], "Hardware and Software requests for FP16": [[265, "hardware-and-software-requests-for-fp16"], [329, "hardware-and-software-requests-for-fp16"]], "Accuracy-driven mixed precision": [[265, "accuracy-driven-mixed-precision"], [329, "accuracy-driven-mixed-precision"]], "Get Started with autotune API": [[265, "get-started-with-autotune-api"]], "PyTorch Smooth Quantization": [[266, "pytorch-smooth-quantization"]], "Usage": [[266, "usage"], [268, "usage"], [271, "usage"], [274, "usage"], [342, "usage"], [344, "usage"], [344, "id2"], [344, "id4"], [344, "id6"], [344, "id8"], [344, "id10"], [344, "id12"], [344, "id14"], [344, "id16"], [344, "id18"], [344, "id20"], [344, "id22"]], "Fixed Alpha": [[266, "fixed-alpha"]], "Specify Quantization Rules": [[266, "specify-quantization-rules"], [267, "specify-quantization-rules"], [268, "specify-quantization-rules"], [270, "specify-quantization-rules"], [336, "specify-quantization-rules"]], "Validated Models": [[266, "validated-models"], [342, "validated-models"], [345, "validated-models"]], "Supported Framework Matrix": [[266, "supported-framework-matrix"], [342, "supported-framework-matrix"]], "PyTorch Static Quantization": [[267, "pytorch-static-quantization"]], "Get Started": [[267, "get-started"], [268, "get-started"], [270, "get-started"], [275, "get-started"], [282, "get-started"], [336, "get-started"]], "Static Quantization with IPEX Backend": [[267, "static-quantization-with-ipex-backend"]], "Usage Sample with IPEX": [[267, "usage-sample-with-ipex"]], "Model Examples": [[267, "model-examples"]], "Static Quantization with PT2E Backend": [[267, "static-quantization-with-pt2e-backend"]], "Usage Sample with PT2E": [[267, "usage-sample-with-pt2e"]], "Model Examples with PT2E": [[267, "model-examples-with-pt2e"]], "PyTorch Weight Only Quantization": [[268, "pytorch-weight-only-quantization"]], "Supported Matrix": [[268, "supported-matrix"], [269, "supported-matrix"], [274, "supported-matrix"]], "Common arguments": [[268, "common-arguments"]], "RTN": [[268, "rtn"]], "GPTQ": [[268, "gptq"]], "AutoRound": [[268, "autoround"]], "AWQ": [[268, "awq"]], "TEQ": [[268, "teq"]], "HQQ": [[268, "hqq"]], "Saving and Loading": [[268, "saving-and-loading"]], "Layer Wise Quantization": [[268, "layer-wise-quantization"]], "Efficient Usage on Client-Side": [[268, "efficient-usage-on-client-side"]], "Torch": [[269, "torch"]], "Torch-like APIs": [[269, "torch-like-apis"]], "Quantization APIs": [[269, "quantization-apis"]], "Autotune API": [[269, "autotune-api"]], "Load API": [[269, "load-api"]], "Common Problems": [[269, "common-problems"]], "TensorFlow Quantization": [[270, "tensorflow-quantization"]], "Without Accuracy Aware Tuning": [[270, "without-accuracy-aware-tuning"]], "With Accuracy Aware Tuning": [[270, "with-accuracy-aware-tuning"]], "Smooth Quant": [[271, "smooth-quant"], [342, "smooth-quant"]], "Using a Fixed alpha": [[271, "using-a-fixed-alpha"]], "Determining the alpha through auto-tuning": [[271, "determining-the-alpha-through-auto-tuning"], [342, "determining-the-alpha-through-auto-tuning"]], "TensorFlow": [[272, "tensorflow"], [327, "tensorflow"], [343, "tensorflow"]], "API for TensorFlow": [[272, "api-for-tensorflow"]], "Support Matrix": [[272, "support-matrix"], [311, "support-matrix"]], "Quantization Scheme": [[272, "quantization-scheme"]], "Quantization Approaches": [[272, "quantization-approaches"], [336, "quantization-approaches"]], "Post Training Static Quantization": [[272, "post-training-static-quantization"], [282, "post-training-static-quantization"], [336, "post-training-static-quantization"]], "Smooth Quantization": [[272, "smooth-quantization"], [279, "smooth-quantization"]], "Mixed Precision": [[272, "mixed-precision"], [329, "mixed-precision"]], "Backend and Device": [[272, "backend-and-device"]], "AutoTune": [[273, "autotune"]], "How it Works": [[273, "how-it-works"]], "Working with Autotune": [[273, "working-with-autotune"]], "Working with PyTorch Model": [[273, "working-with-pytorch-model"]], "Working with Tensorflow Model": [[273, "working-with-tensorflow-model"]], "Benchmark": [[274, "benchmark"], [295, "benchmark"], [328, "benchmark"]], "General Use Cases": [[274, "general-use-cases"]], "Dump Throughput and Latency Summary": [[274, "dump-throughput-and-latency-summary"]], "Demo usage": [[274, "demo-usage"]], "Quantization on Client": [[275, "quantization-on-client"]], "Design": [[276, "design"], [314, "design"], [344, "design"], [344, "id1"], [344, "id3"], [344, "id5"], [344, "id7"], [344, "id9"], [344, "id11"], [344, "id13"], [344, "id15"], [344, "id17"], [344, "id19"], [344, "id21"]], "Architecture": [[276, "architecture"], [314, "architecture"], [323, "architecture"]], "Workflows": [[276, "workflows"]], "Version mapping between Intel Neural Compressor to Gaudi Software Stack": [[277, "version-mapping-between-intel-neural-compressor-to-gaudi-software-stack"]], "Quantization": [[279, "quantization"], [301, "quantization"], [336, "quantization"]], "Quantization Fundamentals": [[279, "quantization-fundamentals"], [336, "quantization-fundamentals"], [342, "quantization-fundamentals"]], "Symmetric & Asymmetric": [[279, "symmetric-asymmetric"]], "Quantization Scheme in TensorFlow": [[279, "quantization-scheme-in-tensorflow"], [336, "quantization-scheme-in-tensorflow"]], "Quantization Scheme in PyTorch": [[279, "quantization-scheme-in-pytorch"], [336, "quantization-scheme-in-pytorch"]], "Quantization Scheme in IPEX": [[279, "quantization-scheme-in-ipex"], [336, "quantization-scheme-in-ipex"]], "Per-tensor & Per-channel": [[279, "per-tensor-per-channel"], [342, "per-tensor-per-channel"]], "Per-tensor example": [[279, "per-tensor-example"], [342, "per-tensor-example"]], "Per-channel example": [[279, "per-channel-example"], [342, "per-channel-example"]], "Matmul quantization example": [[279, "matmul-quantization-example"], [342, "matmul-quantization-example"]], "Static Quantization": [[279, "static-quantization"]], "Per-channel limitation": [[279, "per-channel-limitation"], [342, "per-channel-limitation"]], "Weight Only Quantization": [[279, "weight-only-quantization"]], "Quantization Aware Training": [[279, "quantization-aware-training"], [328, "quantization-aware-training"], [336, "quantization-aware-training"], [336, "id1"]], "Accuracy Aware Tuning": [[279, "accuracy-aware-tuning"], [336, "accuracy-aware-tuning"]], "Contributor Covenant Code of Conduct": [[280, "contributor-covenant-code-of-conduct"], [281, "contributor-covenant-code-of-conduct"]], "Our Pledge": [[280, "our-pledge"]], "Our Standards": [[280, "our-standards"]], "Our Responsibilities": [[280, "our-responsibilities"]], "Scope": [[280, "scope"]], "Enforcement": [[280, "enforcement"]], "Attribution": [[280, "attribution"]], "Contribution Guidelines": [[281, "contribution-guidelines"]], "Create Pull Request": [[281, "create-pull-request"]], "Step-by-Step guidelines": [[281, "step-by-step-guidelines"]], "Pull Request Checklist": [[281, "pull-request-checklist"]], "Pull Request Template": [[281, "pull-request-template"]], "Pull Request Acceptance Criteria": [[281, "pull-request-acceptance-criteria"]], "Pull Request Status Checks Overview": [[281, "pull-request-status-checks-overview"]], "Support": [[281, "support"]], "FX": [[282, "fx"]], "FX Mode Support Matrix in Neural Compressor": [[282, "fx-mode-support-matrix-in-neural-compressor"]], "Post Training Dynamic Quantization": [[282, "post-training-dynamic-quantization"], [336, "post-training-dynamic-quantization"]], "Quantization-Aware Training": [[282, "quantization-aware-training"]], "Note": [[282, "note"]], "Details": [[282, "details"]], "Common Problem": [[282, "common-problem"]], "Static Quantization & Quantization Aware Training": [[282, "static-quantization-quantization-aware-training"]], "Security Policy": [[283, "security-policy"]], "Report a Vulnerability": [[283, "report-a-vulnerability"]], "Intel\u00ae Neural Compressor": [[284, "intel-neural-compressor"]], "What\u2019s New": [[284, "what-s-new"]], "Installation": [[284, "installation"], [324, "installation"], [324, "id1"]], "Install Framework": [[284, "install-framework"], [324, "install-framework"]], "Install torch for CPU": [[284, "install-torch-for-cpu"], [324, "install-torch-for-cpu"]], "Use Docker Image with torch installed for HPU": [[284, "use-docker-image-with-torch-installed-for-hpu"], [324, "use-docker-image-with-torch-installed-for-hpu"]], "Install torch/intel_extension_for_pytorch for Intel GPU": [[284, "install-torch-intel-extension-for-pytorch-for-intel-gpu"], [324, "install-torch-intel-extension-for-pytorch-for-intel-gpu"]], "Install torch for other platform": [[284, "install-torch-for-other-platform"], [324, "install-torch-for-other-platform"]], "Install tensorflow": [[284, "install-tensorflow"], [324, "install-tensorflow"]], "Install from pypi": [[284, "install-from-pypi"]], "Getting Started": [[284, "getting-started"], [321, "getting-started"]], "Weight-Only Large Language Model Loading (LLMs)": [[284, "weight-only-large-language-model-loading-llms"]], "Documentation": [[284, "documentation"]], "Selected Publications/Events": [[284, "selected-publications-events"]], "Additional Content": [[284, "additional-content"]], "Communication": [[284, "communication"]], "Adaptor": [[285, "adaptor"], [288, "adaptor"]], "Adaptor Support Matrix": [[285, "adaptor-support-matrix"]], "Working Flow": [[285, "working-flow"], [336, "working-flow"]], "Get Started with Adaptor API": [[285, "get-started-with-adaptor-api"]], "Query API": [[285, "query-api"]], "Background": [[285, "background"], [312, "background"]], "Query API Introduction": [[285, "query-api-introduction"]], "Example of Adding a New Backend Support": [[285, "example-of-adding-a-new-backend-support"]], "Capability": [[285, "capability"]], "Implement ONNXRTAdaptor Class": [[285, "implement-onnxrtadaptor-class"]], "How to Add An Adaptor": [[286, "how-to-add-an-adaptor"]], "API List that Need to Implement": [[286, "api-list-that-need-to-implement"]], "Design the framework YAML": [[286, "design-the-framework-yaml"]], "Add query_fw_capability to Adaptor": [[286, "add-query-fw-capability-to-adaptor"]], "Add quantize API according to tune_cfg": [[286, "add-quantize-api-according-to-tune-cfg"]], "Prepare calibration model from fp32 graph": [[286, "prepare-calibration-model-from-fp32-graph"]], "Run sampling iterations of the fp32 graph to calibrate quantizable operators.": [[286, "run-sampling-iterations-of-the-fp32-graph-to-calibrate-quantizable-operators"]], "Calculate the data range and generate quantized model": [[286, "calculate-the-data-range-and-generate-quantized-model"]], "How to Support New Data Type, Like Int4, with a Few Line Changes": [[287, "how-to-support-new-data-type-like-int4-with-a-few-line-changes"]], "Define the Quantization Ability of the Specific Operator": [[287, "define-the-quantization-ability-of-the-specific-operator"]], "Invoke the Operator Kernel According to the Tuning Configuration": [[287, "invoke-the-operator-kernel-according-to-the-tuning-configuration"]], "Use the New Data Type": [[287, "use-the-new-data-type"]], "Summary": [[287, "summary"]], "ONNX Runtime": [[289, "onnx-runtime"]], "Torch Utils": [[290, "torch-utils"]], "2.0 API": [[291, "api"]], "3.0 API": [[292, "api"]], "API Document Example": [[293, "api-document-example"]], "APIs": [[294, "apis"]], "Compression": [[296, "compression"]], "Config": [[297, "config"]], "Mix Precision": [[298, "mix-precision"], [328, "mix-precision"]], "Model": [[299, "model"], [330, "model"]], "Objective": [[300, "objective"], [332, "objective"]], "Strategy": [[302, "strategy"]], "Tensorflow Quantization AutoTune": [[303, "tensorflow-quantization-autotune"]], "Tensorflow Quantization Base API": [[304, "tensorflow-quantization-base-api"]], "Tensorflow Quantization Config": [[305, "tensorflow-quantization-config"]], "Pytorch Quantization AutoTune": [[306, "pytorch-quantization-autotune"]], "Pytorch Quantization Base API": [[307, "pytorch-quantization-base-api"]], "Pytorch Quantization Config": [[308, "pytorch-quantization-config"]], "Training": [[309, "training"]], "Benchmarking": [[310, "benchmarking"]], "Benchmark Support Matrix": [[310, "benchmark-support-matrix"]], "Get Started with Benchmark API": [[310, "get-started-with-benchmark-api"]], "Calibration Algorithms in Quantization": [[311, "calibration-algorithms-in-quantization"]], "Calibration Algorithms": [[311, "calibration-algorithms"]], "INC Coding Conventions": [[312, "inc-coding-conventions"]], "Rules": [[312, "rules"]], "Imports": [[312, "imports"]], "Strings": [[312, "strings"]], "Logger": [[312, "logger"]], "Type Annotations": [[312, "type-annotations"]], "Comments": [[312, "comments"]], "TODO Comments": [[312, "todo-comments"]], "Public and Internal Interfaces": [[312, "public-and-internal-interfaces"]], "Folder structure": [[312, "folder-structure"]], "Recommend VS Code settings.json": [[312, "recommend-vs-code-settings-json"]], "DataLoader": [[313, "dataloader"]], "Supported Framework Dataloader Matrix": [[313, "supported-framework-dataloader-matrix"]], "Get Started with DataLoader": [[313, "get-started-with-dataloader"]], "Use Intel\u00ae Neural Compressor DataLoader API": [[313, "use-intel-neural-compressor-dataloader-api"]], "Build Custom Dataloader with Python API": [[313, "build-custom-dataloader-with-python-api"]], "Workflow": [[314, "workflow"]], "Distillation for Quantization": [[315, "distillation-for-quantization"]], "Distillation for Quantization Support Matrix": [[315, "distillation-for-quantization-support-matrix"]], "Get Started with Distillation for Quantization API": [[315, "get-started-with-distillation-for-quantization-api"]], "Distributed Training and Inference (Evaluation)": [[316, "distributed-training-and-inference-evaluation"]], "Supported Feature Matrix": [[316, "supported-feature-matrix"], [320, "supported-feature-matrix"], [323, "supported-feature-matrix"], [336, "supported-feature-matrix"]], "Get Started with Distributed Training and Inference API": [[316, "get-started-with-distributed-training-and-inference-api"]], "Option 1: Pure Yaml Configuration": [[316, "option-1-pure-yaml-configuration"]], "Option 2: User Defined Training Function": [[316, "option-2-user-defined-training-function"]], "Horovodrun Execution": [[316, "horovodrun-execution"]], "Security": [[316, "security"]], "PyTorch Examples:": [[316, "pytorch-examples"]], "TensorFlow Examples:": [[316, "tensorflow-examples"]], "Example List": [[317, "example-list"]], "Release Data": [[317, "release-data"]], "Export": [[318, "export"]], "Supported Framework Model Matrix": [[318, "supported-framework-model-matrix"], [330, "supported-framework-model-matrix"], [331, "supported-framework-model-matrix"], [337, "supported-framework-model-matrix"], [339, "supported-framework-model-matrix"]], "PyTorch Model": [[318, "pytorch-model"]], "FP32 Model Export": [[318, "fp32-model-export"], [318, "id1"]], "INT8 Model Export": [[318, "int8-model-export"], [318, "id2"]], "Tensorflow Model": [[318, "tensorflow-model"]], "Appendix": [[318, "appendix"]], "Supported quantized ops": [[318, "supported-quantized-ops"]], "Frequently Asked Questions": [[319, "frequently-asked-questions"]], "Common Build Issues": [[319, "common-build-issues"]], "Issue 1:": [[319, "issue-1"]], "Issue 2:": [[319, "issue-2"]], "Issue 3:": [[319, "issue-3"]], "Issue 4:": [[319, "issue-4"]], "Issue 5:": [[319, "issue-5"]], "Framework YAML Configuration Files": [[320, "framework-yaml-configuration-files"]], "Get started with Framework YAML Files": [[320, "get-started-with-framework-yaml-files"]], "Quick Samples": [[321, "quick-samples"]], "Feature Matrix": [[321, "feature-matrix"]], "Incompatible changes between v1.2 and v1.1": [[322, "incompatible-changes-between-v1-2-and-v1-1"]], "User-facing APIs": [[322, "user-facing-apis"]], "Built-in transform/dataset/metric APIs": [[322, "built-in-transform-dataset-metric-apis"]], "Infrastructure of Intel\u00ae Neural Compressor": [[323, "infrastructure-of-intel-neural-compressor"]], "Prerequisites": [[324, "prerequisites"]], "Install from Binary": [[324, "install-from-binary"]], "Install from Source": [[324, "install-from-source"]], "Install from AI Kit": [[324, "install-from-ai-kit"]], "System Requirements": [[324, "system-requirements"]], "Validated Hardware Environment": [[324, "validated-hardware-environment"]], "Intel\u00ae Neural Compressor supports HPUs based on heterogeneous architecture with two compute engines (MME and TPC):": [[324, "intel-neural-compressor-supports-hpus-based-on-heterogeneous-architecture-with-two-compute-engines-mme-and-tpc"]], "Intel\u00ae Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:": [[324, "intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors"]], "Intel\u00ae Neural Compressor supports GPUs built on Intel\u2019s Xe architecture:": [[324, "intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture"]], "Intel\u00ae Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:": [[324, "intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime"]], "Validated Software Environment": [[324, "validated-software-environment"]], "Legal Information": [[325, "legal-information"]], "License": [[325, "license"]], "Citation": [[325, "citation"]], "Trademarks": [[325, "trademarks"]], "LLMs Quantization Recipes": [[326, "llms-quantization-recipes"]], "Large Language Models Recipes": [[326, "large-language-models-recipes"]], "Large Language Models Accuracy": [[326, "large-language-models-accuracy"]], "Metrics": [[327, "metrics"]], "Supported Built-in Metric Matrix": [[327, "supported-built-in-metric-matrix"]], "PyTorch": [[327, "pytorch"], [338, "pytorch"]], "MXNet": [[327, "mxnet"], [343, "mxnet"]], "ONNXRT": [[327, "onnxrt"], [343, "onnxrt"]], "Get Started with Metric": [[327, "get-started-with-metric"]], "Use Intel\u00ae Neural Compressor Metric API": [[327, "use-intel-neural-compressor-metric-api"]], "Build Custom Metric with Python API": [[327, "build-custom-metric-with-python-api"]], "Example": [[327, "example"], [332, "example"]], "Code Migration from Intel Neural Compressor 1.X to Intel Neural Compressor 2.X": [[328, "code-migration-from-intel-neural-compressor-1-x-to-intel-neural-compressor-2-x"]], "Model Quantization": [[328, "model-quantization"]], "Post-training Quantization": [[328, "post-training-quantization"]], "Pruning": [[328, "pruning"], [334, "pruning"]], "Distillation": [[328, "distillation"]], "Orchestration": [[328, "orchestration"]], "During quantization mixed precision": [[329, "during-quantization-mixed-precision"]], "Get Started with Mixed Precision API": [[329, "get-started-with-mixed-precision-api"]], "Single Objective": [[332, "single-objective"]], "Multiple Objectives": [[332, "multiple-objectives"]], "Objective Support Matrix": [[332, "objective-support-matrix"]], "Get Started with Objective API": [[332, "get-started-with-objective-api"]], "Config Single Objective": [[332, "config-single-objective"]], "Config Multiple Objectives": [[332, "config-multiple-objectives"]], "Optimization Orchestration": [[333, "optimization-orchestration"]], "One-shot": [[333, "one-shot"]], "Orchestration Support Matrix": [[333, "orchestration-support-matrix"]], "Get Started with Orchestration API": [[333, "get-started-with-orchestration-api"]], "Neural Network Pruning": [[334, "neural-network-pruning"]], "Pruning Patterns": [[334, "pruning-patterns"]], "Pruning Criteria": [[334, "pruning-criteria"]], "Pruning Types": [[334, "pruning-types"]], "Pruning Schedules": [[334, "pruning-schedules"]], "Pruning Scope": [[334, "pruning-scope"]], "Sparsity Decay Types": [[334, "sparsity-decay-types"]], "Regularization": [[334, "regularization"]], "Large Language Model Pruning": [[334, "large-language-model-pruning"]], "Pruning Support Matrix": [[334, "pruning-support-matrix"]], "Get Started with Pruning API": [[334, "get-started-with-pruning-api"]], "Training-aware pruning API": [[334, "training-aware-pruning-api"]], "Retrain-free Pruning API": [[334, "retrain-free-pruning-api"]], "Sparse Model Deployment": [[334, "sparse-model-deployment"]], "Pruning with Hyperparameter Optimization": [[334, "pruning-with-hyperparameter-optimization"]], "Full Publications/Events (82)": [[335, "full-publications-events-82"]], "2024 (3)": [[335, "id1"]], "2023 (25)": [[335, "id2"]], "2022 (35)": [[335, "id3"]], "2021 (15)": [[335, "id4"]], "2018 - 2020 (4)": [[335, "id5"]], "Quantization Introduction": [[336, "quantization-introduction"]], "Quantization Support Matrix": [[336, "quantization-support-matrix"]], "Quantization Scheme in MXNet": [[336, "quantization-scheme-in-mxnet"]], "Quantization Scheme in ONNX Runtime": [[336, "quantization-scheme-in-onnx-runtime"]], "Post Training Quantization": [[336, "post-training-quantization"]], "Specify Quantization Recipes": [[336, "specify-quantization-recipes"]], "Specify Quantization Backend and Device": [[336, "specify-quantization-backend-and-device"]], "Layer Wise Quantization (LWQ)": [[337, "layer-wise-quantization-lwq"]], "PyTorch framework example": [[337, "pytorch-framework-example"]], "ONNX Runtime framework example": [[337, "onnx-runtime-framework-example"]], "Turn OFF Auto Mixed Precision during Quantization": [[338, "turn-off-auto-mixed-precision-during-quantization"]], "Tensorflow": [[338, "tensorflow"]], "Weight Only Quantization (WOQ)": [[339, "weight-only-quantization-woq"]], "Quantization Capability": [[339, "quantization-capability"]], "Export Compressed Model": [[339, "export-compressed-model"]], "User Code Example": [[339, "user-code-example"]], "WOQ Algorithms Tuning": [[339, "woq-algorithms-tuning"]], "User code example": [[339, "id1"]], "Release": [[340, "release"]], "Release Notes": [[340, "release-notes"]], "Known Issues": [[340, "known-issues"]], "Incompatible Changes": [[340, "incompatible-changes"]], "SigOpt Strategy": [[341, "sigopt-strategy"]], "Preparation": [[341, "preparation"]], "SigOpt Platform": [[341, "sigopt-platform"]], "Neural Compressor Configuration": [[341, "neural-compressor-configuration"]], "Performance": [[341, "performance"]], "Benefit of SigOpt Strategy": [[341, "benefit-of-sigopt-strategy"]], "Performance Comparison of Different Strategies": [[341, "performance-comparison-of-different-strategies"]], "SmoothQuant and Our Enhancement": [[342, "smoothquant-and-our-enhancement"]], "SmoothQuant": [[342, "smoothquant"]], "Our enhancement:": [[342, "our-enhancement"]], "Algorithm: Auto-tuning of $\\alpha$.": [[342, "algorithm-auto-tuning-of-alpha"]], "Engineering": [[342, "engineering"]], "Using a fixed alpha": [[342, "using-a-fixed-alpha"]], "Auto-tune the alpha for the entire model": [[342, "auto-tune-the-alpha-for-the-entire-model"]], "Auto-tune the alpha for each layer/block": [[342, "auto-tune-the-alpha-for-each-layer-block"]], "Transform": [[343, "transform"]], "Transform Support List": [[343, "transform-support-list"]], "Pytorch": [[343, "pytorch"]], "Tuning Strategies": [[344, "tuning-strategies"]], "Strategy Design": [[344, "strategy-design"]], "Tuning Space": [[344, "tuning-space"]], "Exit Policy": [[344, "exit-policy"]], "Accuracy Criteria": [[344, "accuracy-criteria"]], "Tuning Process": [[344, "tuning-process"]], "Tuning Algorithms": [[344, "tuning-algorithms"]], "Auto": [[344, "auto"]], "Conservative Tuning": [[344, "conservative-tuning"]], "Basic": [[344, "basic"]], "MSE": [[344, "mse"]], "MSE_V2": [[344, "mse-v2"]], "HAWQ_V2": [[344, "hawq-v2"]], "Bayesian": [[344, "bayesian"]], "Exhaustive": [[344, "exhaustive"]], "Random": [[344, "random"]], "SigOpt": [[344, "sigopt"]], "TPE": [[344, "tpe"]], "Distributed Tuning": [[344, "distributed-tuning"]], "Customize a New Tuning Strategy": [[344, "customize-a-new-tuning-strategy"]], "Validated Quantization Examples": [[345, "validated-quantization-examples"]], "TensorFlow Models with TensorFlow 2.15.0": [[345, "tensorflow-models-with-tensorflow-2-15-0"]], "PyTorch Models with Torch 2.2.1+cpu in PTQ Mode": [[345, "pytorch-models-with-torch-2-2-1-cpu-in-ptq-mode"]], "PyTorch Models with Torch 2.2.1+cpu in QAT Mode": [[345, "pytorch-models-with-torch-2-2-1-cpu-in-qat-mode"]], "PyTorch Models with Torch 2.0.1+cpu in WOQ Mode": [[345, "pytorch-models-with-torch-2-0-1-cpu-in-woq-mode"]], "ONNX Models with ONNX Runtime 1.17.1": [[345, "onnx-models-with-onnx-runtime-1-17-1"]], "ONNX Models with ONNX Runtime 1.15.0 in WOQ Mode": [[345, "onnx-models-with-onnx-runtime-1-15-0-in-woq-mode"]], "Validated Pruning Examples": [[345, "validated-pruning-examples"]], "Validated Knowledge Distillation Examples": [[345, "validated-knowledge-distillation-examples"]], "Validated ONNX QDQ INT8 Models on Multiple Hardware through ONNX Runtime": [[345, "validated-onnx-qdq-int8-models-on-multiple-hardware-through-onnx-runtime"]]}, "indexentries": {"algorithms (class in neural_compressor.algorithm.algorithm)": [[0, "neural_compressor.algorithm.algorithm.ALGORITHMS"]], "algorithm (class in neural_compressor.algorithm.algorithm)": [[0, "neural_compressor.algorithm.algorithm.Algorithm"]], "algorithmscheduler (class in neural_compressor.algorithm.algorithm)": [[0, "neural_compressor.algorithm.algorithm.AlgorithmScheduler"]], "algorithm_registry() (in module neural_compressor.algorithm.algorithm)": [[0, "neural_compressor.algorithm.algorithm.algorithm_registry"]], "module": [[0, "module-neural_compressor.algorithm.algorithm"], [1, "module-neural_compressor.algorithm.fast_bias_correction"], [2, "module-neural_compressor.algorithm"], [3, "module-neural_compressor.algorithm.smooth_quant"], [4, "module-neural_compressor.algorithm.weight_correction"], [5, "module-neural_compressor.benchmark"], [6, "module-neural_compressor.common.base_config"], [7, "module-neural_compressor.common.base_tuning"], [8, "module-neural_compressor.common.benchmark"], [9, "module-neural_compressor.common"], [10, "module-neural_compressor.common.tuning_param"], [11, "module-neural_compressor.common.utils.constants"], [12, "module-neural_compressor.common.utils"], [13, "module-neural_compressor.common.utils.logger"], [14, "module-neural_compressor.common.utils.save_load"], [15, "module-neural_compressor.common.utils.utility"], [16, "module-neural_compressor.config"], [17, "module-neural_compressor.contrib"], [18, "module-neural_compressor.contrib.strategy"], [19, "module-neural_compressor.contrib.strategy.sigopt"], [20, "module-neural_compressor.contrib.strategy.tpe"], [21, "module-neural_compressor.data.datasets.bert_dataset"], [22, "module-neural_compressor.data.datasets.coco_dataset"], [23, "module-neural_compressor.data.datasets.dataset"], [24, "module-neural_compressor.data.datasets.dummy_dataset"], [25, "module-neural_compressor.data.datasets.dummy_dataset_v2"], [26, "module-neural_compressor.data.datasets.imagenet_dataset"], [27, "module-neural_compressor.data.datasets"], [28, "module-neural_compressor.data.datasets.style_transfer_dataset"], [29, "module-neural_compressor.data.filters.coco_filter"], [30, "module-neural_compressor.data.filters.filter"], [31, "module-neural_compressor.data.filters"], [32, "module-neural_compressor.data"], [33, "module-neural_compressor.data.transforms.imagenet_transform"], [34, "module-neural_compressor.data.transforms"], [35, "module-neural_compressor.data.transforms.postprocess"], [36, "module-neural_compressor.data.transforms.tokenization"], [37, "module-neural_compressor.data.transforms.transform"], [38, "module-neural_compressor"], [39, "module-neural_compressor.metric.bleu"], [40, "module-neural_compressor.metric.bleu_util"], [41, "module-neural_compressor.metric.coco_label_map"], [42, "module-neural_compressor.metric.coco_tools"], [43, "module-neural_compressor.metric.evaluate_squad"], [44, "module-neural_compressor.metric.f1"], [45, "module-neural_compressor.metric"], [46, "module-neural_compressor.metric.metric"], [47, "module-neural_compressor.mix_precision"], [48, "module-neural_compressor.model.base_model"], [49, "module-neural_compressor.model"], [50, "module-neural_compressor.model.keras_model"], [51, "module-neural_compressor.model.model"], [52, "module-neural_compressor.model.mxnet_model"], [53, "module-neural_compressor.model.nets_factory"], [54, "module-neural_compressor.model.onnx_model"], [55, "module-neural_compressor.model.tensorflow_model"], [56, "module-neural_compressor.model.torch_model"], [57, "module-neural_compressor.objective"], [58, "module-neural_compressor.profiling"], [59, "module-neural_compressor.quantization"], [60, "module-neural_compressor.strategy.auto"], [61, "module-neural_compressor.strategy.auto_mixed_precision"], [62, "module-neural_compressor.strategy.basic"], [63, "module-neural_compressor.strategy.bayesian"], [64, "module-neural_compressor.strategy.conservative"], [65, "module-neural_compressor.strategy.exhaustive"], [66, "module-neural_compressor.strategy.hawq_v2"], [67, "module-neural_compressor.strategy"], [68, "module-neural_compressor.strategy.mse"], [69, "module-neural_compressor.strategy.mse_v2"], [70, "module-neural_compressor.strategy.random"], [71, "module-neural_compressor.strategy.strategy"], [72, "module-neural_compressor.strategy.utils.constant"], [73, "module-neural_compressor.strategy.utils"], [74, "module-neural_compressor.strategy.utils.tuning_sampler"], [75, "module-neural_compressor.strategy.utils.tuning_space"], [76, "module-neural_compressor.strategy.utils.tuning_structs"], [77, "module-neural_compressor.strategy.utils.utility"], [78, "module-neural_compressor.tensorflow.algorithms"], [79, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"], [80, "module-neural_compressor.tensorflow.algorithms.smoother.core"], [81, "module-neural_compressor.tensorflow.algorithms.smoother"], [82, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"], [83, "module-neural_compressor.tensorflow.algorithms.static_quant"], [84, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"], [85, "module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow"], [86, "module-neural_compressor.tensorflow"], [87, "module-neural_compressor.tensorflow.keras"], [88, "module-neural_compressor.tensorflow.keras.layers.conv2d"], [89, "module-neural_compressor.tensorflow.keras.layers.dense"], [90, "module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d"], [91, "module-neural_compressor.tensorflow.keras.layers"], [92, "module-neural_compressor.tensorflow.keras.layers.layer_initializer"], [93, "module-neural_compressor.tensorflow.keras.layers.pool2d"], [94, "module-neural_compressor.tensorflow.keras.layers.separable_conv2d"], [95, "module-neural_compressor.tensorflow.keras.quantization.config"], [96, "module-neural_compressor.tensorflow.keras.quantization"], [97, "module-neural_compressor.tensorflow.quantization.algorithm_entry"], [98, "module-neural_compressor.tensorflow.quantization.autotune"], [99, "module-neural_compressor.tensorflow.quantization.config"], [100, "module-neural_compressor.tensorflow.quantization"], [101, "module-neural_compressor.tensorflow.quantization.quantize"], [102, "module-neural_compressor.tensorflow.quantization.utils.graph_converter"], [103, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert"], [104, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer"], [105, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16"], [106, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"], [107, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"], [108, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"], [109, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"], [110, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"], [111, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"], [112, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"], [113, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"], [114, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"], [115, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"], [116, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"], [117, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"], [118, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"], [119, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"], [120, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"], [121, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"], [122, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"], [123, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"], [124, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"], [125, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"], [126, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"], [127, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"], [128, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"], [129, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"], [130, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"], [131, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"], [132, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"], [133, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"], [134, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"], [135, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"], [136, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"], [137, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"], [138, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"], [139, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"], [140, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"], [141, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant"], [142, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value"], [143, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"], [144, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize"], [145, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"], [146, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize"], [147, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8"], [148, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer"], [149, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter"], [150, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse"], [151, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation"], [152, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq"], [153, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern"], [154, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq"], [155, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern"], [156, "module-neural_compressor.tensorflow.quantization.utils.graph_util"], [157, "module-neural_compressor.tensorflow.quantization.utils"], [158, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph"], [159, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn"], [160, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2"], [161, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv"], [162, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv"], [163, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in"], [164, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul"], [165, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling"], [166, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq"], [167, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq"], [168, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base"], [169, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn"], [170, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2"], [171, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv"], [172, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu"], [173, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul"], [174, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling"], [175, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"], [176, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction"], [177, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base"], [178, "module-neural_compressor.tensorflow.quantization.utils.transform_graph"], [179, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging"], [180, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat"], [181, "module-neural_compressor.tensorflow.quantization.utils.utility"], [182, "module-neural_compressor.tensorflow.utils.constants"], [183, "module-neural_compressor.tensorflow.utils.data"], [184, "module-neural_compressor.tensorflow.utils"], [185, "module-neural_compressor.tensorflow.utils.model"], [186, "module-neural_compressor.tensorflow.utils.model_wrappers"], [187, "module-neural_compressor.tensorflow.utils.utility"], [188, "module-neural_compressor.torch.algorithms.base_algorithm"], [189, "module-neural_compressor.torch.algorithms"], [190, "module-neural_compressor.torch.algorithms.layer_wise"], [191, "module-neural_compressor.torch.algorithms.layer_wise.load"], [192, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"], [193, "module-neural_compressor.torch.algorithms.layer_wise.utils"], [194, "module-neural_compressor.torch.algorithms.mixed_precision.half_precision_convert"], [195, "module-neural_compressor.torch.algorithms.mixed_precision"], [196, "module-neural_compressor.torch.algorithms.mixed_precision.module_wrappers"], [197, "module-neural_compressor.torch.algorithms.mx_quant"], [198, "module-neural_compressor.torch.algorithms.mx_quant.mx"], [199, "module-neural_compressor.torch.algorithms.mx_quant.utils"], [200, "module-neural_compressor.torch.algorithms.pt2e_quant.core"], [201, "module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter"], [202, "module-neural_compressor.torch.algorithms.pt2e_quant"], [203, "module-neural_compressor.torch.algorithms.pt2e_quant.save_load"], [204, "module-neural_compressor.torch.algorithms.pt2e_quant.utility"], [205, "module-neural_compressor.torch.algorithms.smooth_quant"], [206, "module-neural_compressor.torch.algorithms.smooth_quant.save_load"], [207, "module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant"], [208, "module-neural_compressor.torch.algorithms.smooth_quant.utility"], [209, "module-neural_compressor.torch.algorithms.static_quant"], [210, "module-neural_compressor.torch.algorithms.static_quant.save_load"], [211, "module-neural_compressor.torch.algorithms.static_quant.static_quant"], [212, "module-neural_compressor.torch.algorithms.static_quant.utility"], [213, "module-neural_compressor.torch.algorithms.weight_only.autoround"], [214, "module-neural_compressor.torch.algorithms.weight_only.awq"], [215, "module-neural_compressor.torch.algorithms.weight_only.gptq"], [216, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"], [217, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"], [218, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"], [219, "module-neural_compressor.torch.algorithms.weight_only.hqq"], [220, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"], [221, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"], [222, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"], [223, "module-neural_compressor.torch.algorithms.weight_only"], [224, "module-neural_compressor.torch.algorithms.weight_only.modules"], [225, "module-neural_compressor.torch.algorithms.weight_only.rtn"], [226, "module-neural_compressor.torch.algorithms.weight_only.save_load"], [227, "module-neural_compressor.torch.algorithms.weight_only.teq"], [228, "module-neural_compressor.torch.algorithms.weight_only.utility"], [229, "module-neural_compressor.torch.export"], [230, "module-neural_compressor.torch.export.pt2e_export"], [231, "module-neural_compressor.torch"], [232, "module-neural_compressor.torch.quantization.algorithm_entry"], [233, "module-neural_compressor.torch.quantization.autotune"], [234, "module-neural_compressor.torch.quantization.config"], [235, "module-neural_compressor.torch.quantization"], [236, "module-neural_compressor.torch.quantization.load_entry"], [237, "module-neural_compressor.torch.quantization.quantize"], [238, "module-neural_compressor.torch.utils.auto_accelerator"], [239, "module-neural_compressor.torch.utils.constants"], [240, "module-neural_compressor.torch.utils.environ"], [241, "module-neural_compressor.torch.utils"], [242, "module-neural_compressor.torch.utils.utility"], [243, "module-neural_compressor.training"], [244, "module-neural_compressor.utils.collect_layer_histogram"], [245, "module-neural_compressor.utils.constant"], [246, "module-neural_compressor.utils.create_obj_from_config"], [247, "module-neural_compressor.utils.export"], [248, "module-neural_compressor.utils.export.qlinear2qdq"], [249, "module-neural_compressor.utils.export.tf2onnx"], [250, "module-neural_compressor.utils.export.torch2onnx"], [251, "module-neural_compressor.utils"], [252, "module-neural_compressor.utils.kl_divergence"], [253, "module-neural_compressor.utils.load_huggingface"], [254, "module-neural_compressor.utils.logger"], [255, "module-neural_compressor.utils.options"], [256, "module-neural_compressor.utils.pytorch"], [257, "module-neural_compressor.utils.utility"], [258, "module-neural_compressor.utils.weights_details"], [259, "module-neural_compressor.version"]], "neural_compressor.algorithm.algorithm": [[0, "module-neural_compressor.algorithm.algorithm"]], "fastbiascorrection (class in neural_compressor.algorithm.fast_bias_correction)": [[1, "neural_compressor.algorithm.fast_bias_correction.FastBiasCorrection"]], "neural_compressor.algorithm.fast_bias_correction": [[1, "module-neural_compressor.algorithm.fast_bias_correction"]], "neural_compressor.algorithm": [[2, "module-neural_compressor.algorithm"]], "smoothquant (class in neural_compressor.algorithm.smooth_quant)": [[3, "neural_compressor.algorithm.smooth_quant.SmoothQuant"]], "neural_compressor.algorithm.smooth_quant": [[3, "module-neural_compressor.algorithm.smooth_quant"]], "weightcorrection (class in neural_compressor.algorithm.weight_correction)": [[4, "neural_compressor.algorithm.weight_correction.WeightCorrection"]], "neural_compressor.algorithm.weight_correction": [[4, "module-neural_compressor.algorithm.weight_correction"]], "benchmark_with_raw_cmd() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.benchmark_with_raw_cmd"]], "call_one() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.call_one"]], "config_instance() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.config_instance"]], "fit() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.fit"]], "generate_prefix() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.generate_prefix"]], "get_architecture() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.get_architecture"]], "get_bounded_threads() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.get_bounded_threads"]], "get_core_ids() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.get_core_ids"]], "get_physical_ids() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.get_physical_ids"]], "get_threads() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.get_threads"]], "get_threads_per_core() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.get_threads_per_core"]], "neural_compressor.benchmark": [[5, "module-neural_compressor.benchmark"]], "profile() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.profile"]], "run_instance() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.run_instance"]], "set_all_env_var() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.set_all_env_var"]], "set_env_var() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.set_env_var"]], "summary_benchmark() (in module neural_compressor.benchmark)": [[5, "neural_compressor.benchmark.summary_benchmark"]], "baseconfig (class in neural_compressor.common.base_config)": [[6, "neural_compressor.common.base_config.BaseConfig"]], "composableconfig (class in neural_compressor.common.base_config)": [[6, "neural_compressor.common.base_config.ComposableConfig"]], "configregistry (class in neural_compressor.common.base_config)": [[6, "neural_compressor.common.base_config.ConfigRegistry"]], "config_list (neural_compressor.common.base_config.composableconfig attribute)": [[6, "neural_compressor.common.base_config.ComposableConfig.config_list"]], "get_all_config_set_from_config_registry() (in module neural_compressor.common.base_config)": [[6, "neural_compressor.common.base_config.get_all_config_set_from_config_registry"]], "name (neural_compressor.common.base_config.baseconfig attribute)": [[6, "neural_compressor.common.base_config.BaseConfig.name"]], "neural_compressor.common.base_config": [[6, "module-neural_compressor.common.base_config"]], "params_list (neural_compressor.common.base_config.baseconfig attribute)": [[6, "neural_compressor.common.base_config.BaseConfig.params_list"]], "register_config() (in module neural_compressor.common.base_config)": [[6, "neural_compressor.common.base_config.register_config"]], "register_supported_configs_for_fwk() (in module neural_compressor.common.base_config)": [[6, "neural_compressor.common.base_config.register_supported_configs_for_fwk"]], "configloader (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.ConfigLoader"]], "configset (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.ConfigSet"]], "evaluationfuncwrapper (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.EvaluationFuncWrapper"]], "evaluator (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.Evaluator"]], "sampler (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.Sampler"]], "sequentialsampler (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.SequentialSampler"]], "tuningconfig (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.TuningConfig"]], "tuningmonitor (class in neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.TuningMonitor"]], "config_list (neural_compressor.common.base_tuning.configset attribute)": [[7, "neural_compressor.common.base_tuning.ConfigSet.config_list"]], "init_tuning() (in module neural_compressor.common.base_tuning)": [[7, "neural_compressor.common.base_tuning.init_tuning"]], "neural_compressor.common.base_tuning": [[7, "module-neural_compressor.common.base_tuning"]], "benchmark() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.benchmark"]], "dump_numa_info() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.dump_numa_info"]], "format_list2str() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.format_list2str"]], "generate_prefix() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.generate_prefix"]], "get_linux_numa_info() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.get_linux_numa_info"]], "get_numa_node() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.get_numa_node"]], "get_reversed_numa_info() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.get_reversed_numa_info"]], "get_windows_numa_info() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.get_windows_numa_info"]], "neural_compressor.common.benchmark": [[8, "module-neural_compressor.common.benchmark"]], "parse_str2list() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.parse_str2list"]], "run_multi_instance_command() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.run_multi_instance_command"]], "set_cores_for_instance() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.set_cores_for_instance"]], "summary_latency_throughput() (in module neural_compressor.common.benchmark)": [[8, "neural_compressor.common.benchmark.summary_latency_throughput"]], "neural_compressor.common": [[9, "module-neural_compressor.common"]], "model_level (neural_compressor.common.tuning_param.paramlevel attribute)": [[10, "neural_compressor.common.tuning_param.ParamLevel.MODEL_LEVEL"]], "op_level (neural_compressor.common.tuning_param.paramlevel attribute)": [[10, "neural_compressor.common.tuning_param.ParamLevel.OP_LEVEL"]], "op_type_level (neural_compressor.common.tuning_param.paramlevel attribute)": [[10, "neural_compressor.common.tuning_param.ParamLevel.OP_TYPE_LEVEL"]], "paramlevel (class in neural_compressor.common.tuning_param)": [[10, "neural_compressor.common.tuning_param.ParamLevel"]], "tuningparam (class in neural_compressor.common.tuning_param)": [[10, "neural_compressor.common.tuning_param.TuningParam"]], "neural_compressor.common.tuning_param": [[10, "module-neural_compressor.common.tuning_param"]], "mode (class in neural_compressor.common.utils.constants)": [[11, "neural_compressor.common.utils.constants.Mode"]], "neural_compressor.common.utils.constants": [[11, "module-neural_compressor.common.utils.constants"]], "neural_compressor.common.utils": [[12, "module-neural_compressor.common.utils"]], "logger (class in neural_compressor.common.utils.logger)": [[13, "neural_compressor.common.utils.logger.Logger"]], "tuninglogger (class in neural_compressor.common.utils.logger)": [[13, "neural_compressor.common.utils.logger.TuningLogger"]], "neural_compressor.common.utils.logger": [[13, "module-neural_compressor.common.utils.logger"]], "load_config_mapping() (in module neural_compressor.common.utils.save_load)": [[14, "neural_compressor.common.utils.save_load.load_config_mapping"]], "neural_compressor.common.utils.save_load": [[14, "module-neural_compressor.common.utils.save_load"]], "save_config_mapping() (in module neural_compressor.common.utils.save_load)": [[14, "neural_compressor.common.utils.save_load.save_config_mapping"]], "cpuinfo (class in neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.CpuInfo"]], "lazyimport (class in neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.LazyImport"]], "processortype (class in neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.ProcessorType"]], "statistics (class in neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.Statistics"]], "call_counter() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.call_counter"]], "detect_processor_type_based_on_hw() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.detect_processor_type_based_on_hw"]], "dump_elapsed_time() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.dump_elapsed_time"]], "get_workspace() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.get_workspace"]], "log_process() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.log_process"]], "neural_compressor.common.utils.utility": [[15, "module-neural_compressor.common.utils.utility"]], "set_random_seed() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.set_random_seed"]], "set_resume_from() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.set_resume_from"]], "set_tensorboard() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.set_tensorboard"]], "set_workspace() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.set_workspace"]], "singleton() (in module neural_compressor.common.utils.utility)": [[15, "neural_compressor.common.utils.utility.singleton"]], "accuracycriterion (class in neural_compressor.config)": [[16, "neural_compressor.config.AccuracyCriterion"]], "benchmarkconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.BenchmarkConfig"]], "distillationconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.DistillationConfig"]], "dotdict (class in neural_compressor.config)": [[16, "neural_compressor.config.DotDict"]], "exportconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.ExportConfig"]], "hpoconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.HPOConfig"]], "intermediatelayersknowledgedistillationlossconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.IntermediateLayersKnowledgeDistillationLossConfig"]], "keras (class in neural_compressor.config)": [[16, "neural_compressor.config.Keras"]], "knowledgedistillationlossconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.KnowledgeDistillationLossConfig"]], "mxnet (class in neural_compressor.config)": [[16, "neural_compressor.config.MXNet"]], "mixedprecisionconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.MixedPrecisionConfig"]], "nasconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.NASConfig"]], "onnx (class in neural_compressor.config)": [[16, "neural_compressor.config.ONNX"]], "onnxqlinear2qdqconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.ONNXQlinear2QDQConfig"]], "options (class in neural_compressor.config)": [[16, "neural_compressor.config.Options"]], "posttrainingquantconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.PostTrainingQuantConfig"]], "pytorch (class in neural_compressor.config)": [[16, "neural_compressor.config.PyTorch"]], "quantizationawaretrainingconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.QuantizationAwareTrainingConfig"]], "selfknowledgedistillationlossconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.SelfKnowledgeDistillationLossConfig"]], "tf2onnxconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.TF2ONNXConfig"]], "tensorflow (class in neural_compressor.config)": [[16, "neural_compressor.config.TensorFlow"]], "torch2onnxconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.Torch2ONNXConfig"]], "tuningcriterion (class in neural_compressor.config)": [[16, "neural_compressor.config.TuningCriterion"]], "weightpruningconfig (class in neural_compressor.config)": [[16, "neural_compressor.config.WeightPruningConfig"]], "neural_compressor.config": [[16, "module-neural_compressor.config"]], "neural_compressor.contrib": [[17, "module-neural_compressor.contrib"]], "neural_compressor.contrib.strategy": [[18, "module-neural_compressor.contrib.strategy"]], "sigopttunestrategy (class in neural_compressor.contrib.strategy.sigopt)": [[19, "neural_compressor.contrib.strategy.sigopt.SigOptTuneStrategy"]], "neural_compressor.contrib.strategy.sigopt": [[19, "module-neural_compressor.contrib.strategy.sigopt"]], "tpetunestrategy (class in neural_compressor.contrib.strategy.tpe)": [[20, "neural_compressor.contrib.strategy.tpe.TpeTuneStrategy"]], "neural_compressor.contrib.strategy.tpe": [[20, "module-neural_compressor.contrib.strategy.tpe"]], "inputfeatures (class in neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.InputFeatures"]], "onnxrtbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.ONNXRTBertDataset"]], "parsedecodebert (class in neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.ParseDecodeBert"]], "pytorchbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.PytorchBertDataset"]], "tensorflowbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.TensorflowBertDataset"]], "tensorflowmodelzoobertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.TensorflowModelZooBertDataset"]], "convert_examples_to_features() (in module neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.convert_examples_to_features"]], "load_and_cache_examples() (in module neural_compressor.data.datasets.bert_dataset)": [[21, "neural_compressor.data.datasets.bert_dataset.load_and_cache_examples"]], "neural_compressor.data.datasets.bert_dataset": [[21, "module-neural_compressor.data.datasets.bert_dataset"]], "coconpy (class in neural_compressor.data.datasets.coco_dataset)": [[22, "neural_compressor.data.datasets.coco_dataset.COCONpy"]], "cocoraw (class in neural_compressor.data.datasets.coco_dataset)": [[22, "neural_compressor.data.datasets.coco_dataset.COCORaw"]], "cocorecorddataset (class in neural_compressor.data.datasets.coco_dataset)": [[22, "neural_compressor.data.datasets.coco_dataset.COCORecordDataset"]], "parsedecodecoco (class in neural_compressor.data.datasets.coco_dataset)": [[22, "neural_compressor.data.datasets.coco_dataset.ParseDecodeCoco"]], "neural_compressor.data.datasets.coco_dataset": [[22, "module-neural_compressor.data.datasets.coco_dataset"]], "cifar10 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.CIFAR10"]], "cifar100 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.CIFAR100"]], "dataset (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.Dataset"]], "datasets (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.Datasets"]], "fashionmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.FashionMNIST"]], "imagefolder (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.ImageFolder"]], "iterabledataset (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.IterableDataset"]], "mnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MNIST"]], "mxnetcifar10 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MXNetCIFAR10"]], "mxnetcifar100 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MXNetCIFAR100"]], "mxnetdatasets (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MXNetDatasets"]], "mxnetfashionmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MXNetFashionMNIST"]], "mxnetimagefolder (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MXNetImageFolder"]], "mxnetmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.MXNetMNIST"]], "onnxrtitdatasets (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.ONNXRTITDatasets"]], "onnxrtqldatasets (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.ONNXRTQLDatasets"]], "pytorchdatasets (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PyTorchDatasets"]], "pytorchcifar10 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PytorchCIFAR10"]], "pytorchcifar100 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PytorchCIFAR100"]], "pytorchfashionmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PytorchFashionMNIST"]], "pytorchmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PytorchMNIST"]], "pytorchmxnetwrapdataset (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PytorchMxnetWrapDataset"]], "pytorchmxnetwrapfunction (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.PytorchMxnetWrapFunction"]], "tensorflow (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.Tensorflow"]], "tensorflowcifar10 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowCIFAR10"]], "tensorflowcifar100 (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowCIFAR100"]], "tensorflowdatasets (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowDatasets"]], "tensorflowfashionmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowFashionMNIST"]], "tensorflowimagerecord (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowImageRecord"]], "tensorflowmnist (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowMNIST"]], "tensorflowtfrecorddataset (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowTFRecordDataset"]], "tensorflowvocrecord (class in neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.TensorflowVOCRecord"]], "calculate_md5() (in module neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.calculate_md5"]], "check_integrity() (in module neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.check_integrity"]], "dataset_registry() (in module neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.dataset_registry"]], "download_url() (in module neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.download_url"]], "framework_datasets (in module neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.framework_datasets"]], "gen_bar_updater() (in module neural_compressor.data.datasets.dataset)": [[23, "neural_compressor.data.datasets.dataset.gen_bar_updater"]], "neural_compressor.data.datasets.dataset": [[23, "module-neural_compressor.data.datasets.dataset"]], "dummydataset (class in neural_compressor.data.datasets.dummy_dataset)": [[24, "neural_compressor.data.datasets.dummy_dataset.DummyDataset"]], "neural_compressor.data.datasets.dummy_dataset": [[24, "module-neural_compressor.data.datasets.dummy_dataset"]], "dummydataset (class in neural_compressor.data.datasets.dummy_dataset_v2)": [[25, "neural_compressor.data.datasets.dummy_dataset_v2.DummyDataset"]], "sparsedummydataset (class in neural_compressor.data.datasets.dummy_dataset_v2)": [[25, "neural_compressor.data.datasets.dummy_dataset_v2.SparseDummyDataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[25, "module-neural_compressor.data.datasets.dummy_dataset_v2"]], "imagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[26, "neural_compressor.data.datasets.imagenet_dataset.ImagenetRaw"]], "mxnetimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[26, "neural_compressor.data.datasets.imagenet_dataset.MXNetImagenetRaw"]], "onnxrtimagenetdataset (class in neural_compressor.data.datasets.imagenet_dataset)": [[26, "neural_compressor.data.datasets.imagenet_dataset.ONNXRTImagenetDataset"]], "pytorchimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[26, "neural_compressor.data.datasets.imagenet_dataset.PytorchImagenetRaw"]], "tensorflowimagenetdataset (class in neural_compressor.data.datasets.imagenet_dataset)": [[26, "neural_compressor.data.datasets.imagenet_dataset.TensorflowImagenetDataset"]], "tensorflowimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[26, "neural_compressor.data.datasets.imagenet_dataset.TensorflowImagenetRaw"]], "neural_compressor.data.datasets.imagenet_dataset": [[26, "module-neural_compressor.data.datasets.imagenet_dataset"]], "neural_compressor.data.datasets": [[27, "module-neural_compressor.data.datasets"]], "styletransferdataset (class in neural_compressor.data.datasets.style_transfer_dataset)": [[28, "neural_compressor.data.datasets.style_transfer_dataset.StyleTransferDataset"]], "neural_compressor.data.datasets.style_transfer_dataset": [[28, "module-neural_compressor.data.datasets.style_transfer_dataset"]], "labelbalancecocorawfilter (class in neural_compressor.data.filters.coco_filter)": [[29, "neural_compressor.data.filters.coco_filter.LabelBalanceCOCORawFilter"]], "labelbalancecocorecordfilter (class in neural_compressor.data.filters.coco_filter)": [[29, "neural_compressor.data.filters.coco_filter.LabelBalanceCOCORecordFilter"]], "neural_compressor.data.filters.coco_filter": [[29, "module-neural_compressor.data.filters.coco_filter"]], "filters (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.FILTERS"]], "filter (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.Filter"]], "mxnetfilters (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.MXNetFilters"]], "onnxrtitfilters (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.ONNXRTITFilters"]], "onnxrtqlfilters (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.ONNXRTQLFilters"]], "pytorchfilters (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.PyTorchFilters"]], "tensorflowfilters (class in neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.TensorflowFilters"]], "filter_registry() (in module neural_compressor.data.filters.filter)": [[30, "neural_compressor.data.filters.filter.filter_registry"]], "neural_compressor.data.filters.filter": [[30, "module-neural_compressor.data.filters.filter"]], "neural_compressor.data.filters": [[31, "module-neural_compressor.data.filters"]], "neural_compressor.data": [[32, "module-neural_compressor.data"]], "bilinearimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.BilinearImagenetTransform"]], "labelshift (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.LabelShift"]], "onnxresizecropimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.ONNXResizeCropImagenetTransform"]], "onnxbilinearimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.OnnxBilinearImagenetTransform"]], "parsedecodeimagenet (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.ParseDecodeImagenet"]], "parsedecodeimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.ParseDecodeImagenetTransform"]], "quantizedinput (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.QuantizedInput"]], "resizewithaspectratio (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.ResizeWithAspectRatio"]], "tensorflowresizecropimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.TensorflowResizeCropImagenetTransform"]], "tensorflowshiftrescale (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.TensorflowShiftRescale"]], "tensorflowtransposelastchannel (class in neural_compressor.data.transforms.imagenet_transform)": [[33, "neural_compressor.data.transforms.imagenet_transform.TensorflowTransposeLastChannel"]], "neural_compressor.data.transforms.imagenet_transform": [[33, "module-neural_compressor.data.transforms.imagenet_transform"]], "neural_compressor.data.transforms": [[34, "module-neural_compressor.data.transforms"]], "postprocess (class in neural_compressor.data.transforms.postprocess)": [[35, "neural_compressor.data.transforms.postprocess.Postprocess"]], "neural_compressor.data.transforms.postprocess": [[35, "module-neural_compressor.data.transforms.postprocess"]], "basictokenizer (class in neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.BasicTokenizer"]], "fulltokenizer (class in neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.FullTokenizer"]], "wordpiecetokenizer (class in neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.WordpieceTokenizer"]], "convert_by_vocab() (in module neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.convert_by_vocab"]], "convert_to_unicode() (in module neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.convert_to_unicode"]], "load_vocab() (in module neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.load_vocab"]], "neural_compressor.data.transforms.tokenization": [[36, "module-neural_compressor.data.transforms.tokenization"]], "whitespace_tokenize() (in module neural_compressor.data.transforms.tokenization)": [[36, "neural_compressor.data.transforms.tokenization.whitespace_tokenize"]], "alignimagechanneltransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.AlignImageChannelTransform"]], "basetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.BaseTransform"]], "castonnxtransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CastONNXTransform"]], "castpytorchtransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CastPyTorchTransform"]], "casttftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CastTFTransform"]], "centercroptftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CenterCropTFTransform"]], "centercroptransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CenterCropTransform"]], "collecttransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CollectTransform"]], "composetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ComposeTransform"]], "cropresizetftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CropResizeTFTransform"]], "cropresizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CropResizeTransform"]], "croptoboundingbox (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.CropToBoundingBox"]], "inputfeatures (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.InputFeatures"]], "mxnetcropresizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.MXNetCropResizeTransform"]], "mxnetcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.MXNetCropToBoundingBox"]], "mxnetnormalizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.MXNetNormalizeTransform"]], "mxnettransforms (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.MXNetTransforms"]], "mxnettranspose (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.MXNetTranspose"]], "normalizetftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.NormalizeTFTransform"]], "normalizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.NormalizeTransform"]], "onnxrtcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ONNXRTCropToBoundingBox"]], "onnxrtittransforms (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ONNXRTITTransforms"]], "onnxrtqltransforms (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ONNXRTQLTransforms"]], "paddedcentercroptransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PaddedCenterCropTransform"]], "parsedecodevoctransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ParseDecodeVocTransform"]], "pytorchalignimagechannel (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PyTorchAlignImageChannel"]], "pytorchcropresizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PyTorchCropResizeTransform"]], "pytorchnormalizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PyTorchNormalizeTransform"]], "pytorchtransforms (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PyTorchTransforms"]], "pytorchtranspose (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PyTorchTranspose"]], "pytorchmxnettransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PytorchMxnetTransform"]], "pytorchmxnetwrapfunction (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.PytorchMxnetWrapFunction"]], "randomcroptftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomCropTFTransform"]], "randomcroptransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomCropTransform"]], "randomhorizontalflip (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomHorizontalFlip"]], "randomresizedcropmxnettransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomResizedCropMXNetTransform"]], "randomresizedcroppytorchtransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomResizedCropPytorchTransform"]], "randomresizedcroptftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomResizedCropTFTransform"]], "randomresizedcroptransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomResizedCropTransform"]], "randomverticalflip (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RandomVerticalFlip"]], "rescalekeraspretraintransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RescaleKerasPretrainTransform"]], "rescaletftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RescaleTFTransform"]], "rescaletransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.RescaleTransform"]], "resizemxnettransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ResizeMXNetTransform"]], "resizepytorchtransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ResizePytorchTransform"]], "resizetftransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ResizeTFTransform"]], "resizetransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ResizeTransform"]], "resizewithratio (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ResizeWithRatio"]], "squadexample (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.SquadExample"]], "tfmodelzoocollecttransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TFModelZooCollectTransform"]], "tfsquadv1modelzooposttransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TFSquadV1ModelZooPostTransform"]], "tfsquadv1posttransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TFSquadV1PostTransform"]], "transforms (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TRANSFORMS"], [37, "neural_compressor.data.transforms.transform.Transforms"]], "tensorflowcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowCropToBoundingBox"]], "tensorflowrandomhorizontalflip (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowRandomHorizontalFlip"]], "tensorflowrandomverticalflip (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowRandomVerticalFlip"]], "tensorflowresizewithratio (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowResizeWithRatio"]], "tensorflowtransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowTransform"]], "tensorflowtransforms (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowTransforms"]], "tensorflowtranspose (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowTranspose"]], "tensorflowwrapfunction (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.TensorflowWrapFunction"]], "toarray (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ToArray"]], "tondarraytransform (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.ToNDArrayTransform"]], "transpose (class in neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.Transpose"]], "convert_examples_to_features() (in module neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.convert_examples_to_features"]], "get_final_text() (in module neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.get_final_text"]], "get_torchvision_map() (in module neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.get_torchvision_map"]], "neural_compressor.data.transforms.transform": [[37, "module-neural_compressor.data.transforms.transform"]], "read_squad_examples() (in module neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.read_squad_examples"]], "transform_registry() (in module neural_compressor.data.transforms.transform)": [[37, "neural_compressor.data.transforms.transform.transform_registry"]], "neural_compressor": [[38, "module-neural_compressor"]], "bleu (class in neural_compressor.metric.bleu)": [[39, "neural_compressor.metric.bleu.BLEU"]], "unicoderegex (class in neural_compressor.metric.bleu)": [[39, "neural_compressor.metric.bleu.UnicodeRegex"]], "bleu_tokenize() (in module neural_compressor.metric.bleu)": [[39, "neural_compressor.metric.bleu.bleu_tokenize"]], "labels (neural_compressor.metric.bleu.bleu attribute)": [[39, "neural_compressor.metric.bleu.BLEU.labels"]], "neural_compressor.metric.bleu": [[39, "module-neural_compressor.metric.bleu"]], "nondigit_punct_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[39, "neural_compressor.metric.bleu.UnicodeRegex.nondigit_punct_re"]], "predictions (neural_compressor.metric.bleu.bleu attribute)": [[39, "neural_compressor.metric.bleu.BLEU.predictions"]], "punct_nondigit_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[39, "neural_compressor.metric.bleu.UnicodeRegex.punct_nondigit_re"]], "symbol_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[39, "neural_compressor.metric.bleu.UnicodeRegex.symbol_re"]], "compute_bleu() (in module neural_compressor.metric.bleu_util)": [[40, "neural_compressor.metric.bleu_util.compute_bleu"]], "neural_compressor.metric.bleu_util": [[40, "module-neural_compressor.metric.bleu_util"]], "neural_compressor.metric.coco_label_map": [[41, "module-neural_compressor.metric.coco_label_map"]], "cocoevalwrapper (class in neural_compressor.metric.coco_tools)": [[42, "neural_compressor.metric.coco_tools.COCOEvalWrapper"]], "cocowrapper (class in neural_compressor.metric.coco_tools)": [[42, "neural_compressor.metric.coco_tools.COCOWrapper"]], "exportsingleimagedetectionboxestococo() (in module neural_compressor.metric.coco_tools)": [[42, "neural_compressor.metric.coco_tools.ExportSingleImageDetectionBoxesToCoco"]], "exportsingleimagedetectionmaskstococo() (in module neural_compressor.metric.coco_tools)": [[42, "neural_compressor.metric.coco_tools.ExportSingleImageDetectionMasksToCoco"]], "exportsingleimagegroundtruthtococo() (in module neural_compressor.metric.coco_tools)": [[42, "neural_compressor.metric.coco_tools.ExportSingleImageGroundtruthToCoco"]], "dataset (neural_compressor.metric.coco_tools.cocowrapper attribute)": [[42, "neural_compressor.metric.coco_tools.COCOWrapper.dataset"]], "detection_type (neural_compressor.metric.coco_tools.cocowrapper attribute)": [[42, "neural_compressor.metric.coco_tools.COCOWrapper.detection_type"]], "neural_compressor.metric.coco_tools": [[42, "module-neural_compressor.metric.coco_tools"]], "evaluate() (in module neural_compressor.metric.evaluate_squad)": [[43, "neural_compressor.metric.evaluate_squad.evaluate"]], "exact_match_score() (in module neural_compressor.metric.evaluate_squad)": [[43, "neural_compressor.metric.evaluate_squad.exact_match_score"]], "f1_score() (in module neural_compressor.metric.evaluate_squad)": [[43, "neural_compressor.metric.evaluate_squad.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.metric.evaluate_squad)": [[43, "neural_compressor.metric.evaluate_squad.metric_max_over_ground_truths"]], "neural_compressor.metric.evaluate_squad": [[43, "module-neural_compressor.metric.evaluate_squad"]], "evaluate() (in module neural_compressor.metric.f1)": [[44, "neural_compressor.metric.f1.evaluate"]], "f1_score() (in module neural_compressor.metric.f1)": [[44, "neural_compressor.metric.f1.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.metric.f1)": [[44, "neural_compressor.metric.f1.metric_max_over_ground_truths"]], "neural_compressor.metric.f1": [[44, "module-neural_compressor.metric.f1"]], "normalize_answer() (in module neural_compressor.metric.f1)": [[44, "neural_compressor.metric.f1.normalize_answer"]], "neural_compressor.metric": [[45, "module-neural_compressor.metric"]], "accuracy (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.Accuracy"]], "basemetric (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.BaseMetric"]], "cocomapv2 (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.COCOmAPv2"]], "f1 (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.F1"]], "generaltopk (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.GeneralTopK"]], "loss (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.Loss"]], "mae (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.MAE"]], "metrics (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.METRICS"]], "mse (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.MSE"]], "mxnetmetrics (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.MXNetMetrics"]], "metric (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.Metric"]], "onnxrtglue (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.ONNXRTGLUE"]], "onnxrtitmetrics (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.ONNXRTITMetrics"]], "onnxrtqlmetrics (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.ONNXRTQLMetrics"]], "pytorchloss (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.PyTorchLoss"]], "pytorchmetrics (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.PyTorchMetrics"]], "rmse (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.RMSE"]], "roc (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.ROC"]], "squadf1 (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.SquadF1"]], "tensorflowcocomap (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.TensorflowCOCOMAP"]], "tensorflowmap (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.TensorflowMAP"]], "tensorflowmetrics (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.TensorflowMetrics"]], "tensorflowtopk (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.TensorflowTopK"]], "tensorflowvocmap (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.TensorflowVOCMAP"]], "wrapmxnetmetric (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.WrapMXNetMetric"]], "wraponnxrtmetric (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.WrapONNXRTMetric"]], "wrappytorchmetric (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.WrapPyTorchMetric"]], "compare_label (neural_compressor.metric.metric.mae attribute)": [[46, "neural_compressor.metric.metric.MAE.compare_label"]], "compare_label (neural_compressor.metric.metric.mse attribute)": [[46, "neural_compressor.metric.metric.MSE.compare_label"]], "k (neural_compressor.metric.metric.generaltopk attribute)": [[46, "neural_compressor.metric.metric.GeneralTopK.k"]], "k (neural_compressor.metric.metric.tensorflowtopk attribute)": [[46, "neural_compressor.metric.metric.TensorflowTopK.k"]], "label_list (neural_compressor.metric.metric.accuracy attribute)": [[46, "neural_compressor.metric.metric.Accuracy.label_list"]], "label_list (neural_compressor.metric.metric.mae attribute)": [[46, "neural_compressor.metric.metric.MAE.label_list"]], "label_list (neural_compressor.metric.metric.mse attribute)": [[46, "neural_compressor.metric.metric.MSE.label_list"]], "miou (class in neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.mIOU"]], "metric_registry() (in module neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.metric_registry"]], "metrics (neural_compressor.metric.metric.metrics attribute)": [[46, "neural_compressor.metric.metric.METRICS.metrics"]], "metrics (neural_compressor.metric.metric.mxnetmetrics attribute)": [[46, "neural_compressor.metric.metric.MXNetMetrics.metrics"]], "metrics (neural_compressor.metric.metric.onnxrtitmetrics attribute)": [[46, "neural_compressor.metric.metric.ONNXRTITMetrics.metrics"]], "metrics (neural_compressor.metric.metric.onnxrtqlmetrics attribute)": [[46, "neural_compressor.metric.metric.ONNXRTQLMetrics.metrics"]], "metrics (neural_compressor.metric.metric.pytorchmetrics attribute)": [[46, "neural_compressor.metric.metric.PyTorchMetrics.metrics"]], "metrics (neural_compressor.metric.metric.tensorflowmetrics attribute)": [[46, "neural_compressor.metric.metric.TensorflowMetrics.metrics"]], "mse (neural_compressor.metric.metric.rmse attribute)": [[46, "neural_compressor.metric.metric.RMSE.mse"]], "neural_compressor.metric.metric": [[46, "module-neural_compressor.metric.metric"]], "num_correct (neural_compressor.metric.metric.generaltopk attribute)": [[46, "neural_compressor.metric.metric.GeneralTopK.num_correct"]], "num_correct (neural_compressor.metric.metric.tensorflowtopk attribute)": [[46, "neural_compressor.metric.metric.TensorflowTopK.num_correct"]], "num_sample (neural_compressor.metric.metric.generaltopk attribute)": [[46, "neural_compressor.metric.metric.GeneralTopK.num_sample"]], "num_sample (neural_compressor.metric.metric.tensorflowtopk attribute)": [[46, "neural_compressor.metric.metric.TensorflowTopK.num_sample"]], "pred_list (neural_compressor.metric.metric.accuracy attribute)": [[46, "neural_compressor.metric.metric.Accuracy.pred_list"]], "pred_list (neural_compressor.metric.metric.mae attribute)": [[46, "neural_compressor.metric.metric.MAE.pred_list"]], "pred_list (neural_compressor.metric.metric.mse attribute)": [[46, "neural_compressor.metric.metric.MSE.pred_list"]], "register_customer_metric() (in module neural_compressor.metric.metric)": [[46, "neural_compressor.metric.metric.register_customer_metric"]], "sample (neural_compressor.metric.metric.accuracy attribute)": [[46, "neural_compressor.metric.metric.Accuracy.sample"]], "sample (neural_compressor.metric.metric.loss attribute)": [[46, "neural_compressor.metric.metric.Loss.sample"]], "sum (neural_compressor.metric.metric.loss attribute)": [[46, "neural_compressor.metric.metric.Loss.sum"]], "fit() (in module neural_compressor.mix_precision)": [[47, "neural_compressor.mix_precision.fit"]], "neural_compressor.mix_precision": [[47, "module-neural_compressor.mix_precision"]], "basemodel (class in neural_compressor.model.base_model)": [[48, "neural_compressor.model.base_model.BaseModel"]], "neural_compressor.model.base_model": [[48, "module-neural_compressor.model.base_model"]], "neural_compressor.model": [[49, "module-neural_compressor.model"]], "kerasmodel (class in neural_compressor.model.keras_model)": [[50, "neural_compressor.model.keras_model.KerasModel"]], "neural_compressor.model.keras_model": [[50, "module-neural_compressor.model.keras_model"]], "model (class in neural_compressor.model.model)": [[51, "neural_compressor.model.model.Model"]], "get_model_fwk_name() (in module neural_compressor.model.model)": [[51, "neural_compressor.model.model.get_model_fwk_name"]], "neural_compressor.model.model": [[51, "module-neural_compressor.model.model"]], "mxnetmodel (class in neural_compressor.model.mxnet_model)": [[52, "neural_compressor.model.mxnet_model.MXNetModel"]], "neural_compressor.model.mxnet_model": [[52, "module-neural_compressor.model.mxnet_model"]], "tfslimnetsfactory (class in neural_compressor.model.nets_factory)": [[53, "neural_compressor.model.nets_factory.TFSlimNetsFactory"]], "neural_compressor.model.nets_factory": [[53, "module-neural_compressor.model.nets_factory"]], "onnxmodel (class in neural_compressor.model.onnx_model)": [[54, "neural_compressor.model.onnx_model.ONNXModel"]], "neural_compressor.model.onnx_model": [[54, "module-neural_compressor.model.onnx_model"]], "tensorflowbasemodel (class in neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.TensorflowBaseModel"]], "tensorflowcheckpointmodel (class in neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.TensorflowCheckpointModel"]], "tensorflowllmmodel (class in neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.TensorflowLLMModel"]], "tensorflowmodel (class in neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.TensorflowModel"]], "tensorflowqatmodel (class in neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.TensorflowQATModel"]], "tensorflowsavedmodelmodel (class in neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.TensorflowSavedModelModel"]], "checkpoint_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.checkpoint_session"]], "estimator_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.estimator_session"]], "frozen_pb_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.frozen_pb_session"]], "get_model_type() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.get_model_type"]], "graph_def_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.graph_def_session"]], "graph_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.graph_session"]], "keras_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.keras_session"]], "load_saved_model() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.load_saved_model"]], "neural_compressor.model.tensorflow_model": [[55, "module-neural_compressor.model.tensorflow_model"]], "saved_model_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.saved_model_session"]], "slim_session() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.slim_session"]], "try_loading_keras() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.try_loading_keras"]], "validate_and_inference_input_output() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.validate_and_inference_input_output"]], "validate_graph_node() (in module neural_compressor.model.tensorflow_model)": [[55, "neural_compressor.model.tensorflow_model.validate_graph_node"]], "ipexmodel (class in neural_compressor.model.torch_model)": [[56, "neural_compressor.model.torch_model.IPEXModel"]], "pytorchbasemodel (class in neural_compressor.model.torch_model)": [[56, "neural_compressor.model.torch_model.PyTorchBaseModel"]], "pytorchfxmodel (class in neural_compressor.model.torch_model)": [[56, "neural_compressor.model.torch_model.PyTorchFXModel"]], "pytorchmodel (class in neural_compressor.model.torch_model)": [[56, "neural_compressor.model.torch_model.PyTorchModel"]], "neural_compressor.model.torch_model": [[56, "module-neural_compressor.model.torch_model"]], "accuracy (class in neural_compressor.objective)": [[57, "neural_compressor.objective.Accuracy"]], "footprint (class in neural_compressor.objective)": [[57, "neural_compressor.objective.Footprint"]], "modelsize (class in neural_compressor.objective)": [[57, "neural_compressor.objective.ModelSize"]], "multiobjective (class in neural_compressor.objective)": [[57, "neural_compressor.objective.MultiObjective"]], "objective (class in neural_compressor.objective)": [[57, "neural_compressor.objective.Objective"]], "performance (class in neural_compressor.objective)": [[57, "neural_compressor.objective.Performance"]], "neural_compressor.objective": [[57, "module-neural_compressor.objective"]], "objective_custom_registry() (in module neural_compressor.objective)": [[57, "neural_compressor.objective.objective_custom_registry"]], "objective_registry() (in module neural_compressor.objective)": [[57, "neural_compressor.objective.objective_registry"]], "neural_compressor.profiling": [[58, "module-neural_compressor.profiling"]], "fit() (in module neural_compressor.quantization)": [[59, "neural_compressor.quantization.fit"]], "neural_compressor.quantization": [[59, "module-neural_compressor.quantization"]], "autotunestrategy (class in neural_compressor.strategy.auto)": [[60, "neural_compressor.strategy.auto.AutoTuneStrategy"]], "neural_compressor.strategy.auto": [[60, "module-neural_compressor.strategy.auto"]], "automixedprecisiontunestrategy (class in neural_compressor.strategy.auto_mixed_precision)": [[61, "neural_compressor.strategy.auto_mixed_precision.AutoMixedPrecisionTuneStrategy"]], "neural_compressor.strategy.auto_mixed_precision": [[61, "module-neural_compressor.strategy.auto_mixed_precision"]], "basictunestrategy (class in neural_compressor.strategy.basic)": [[62, "neural_compressor.strategy.basic.BasicTuneStrategy"]], "neural_compressor.strategy.basic": [[62, "module-neural_compressor.strategy.basic"]], "bayesianoptimization (class in neural_compressor.strategy.bayesian)": [[63, "neural_compressor.strategy.bayesian.BayesianOptimization"]], "bayesiantunestrategy (class in neural_compressor.strategy.bayesian)": [[63, "neural_compressor.strategy.bayesian.BayesianTuneStrategy"]], "targetspace (class in neural_compressor.strategy.bayesian)": [[63, "neural_compressor.strategy.bayesian.TargetSpace"]], "acq_max() (in module neural_compressor.strategy.bayesian)": [[63, "neural_compressor.strategy.bayesian.acq_max"]], "neural_compressor.strategy.bayesian": [[63, "module-neural_compressor.strategy.bayesian"]], "conservativetunestrategy (class in neural_compressor.strategy.conservative)": [[64, "neural_compressor.strategy.conservative.ConservativeTuneStrategy"]], "neural_compressor.strategy.conservative": [[64, "module-neural_compressor.strategy.conservative"]], "exhaustivetunestrategy (class in neural_compressor.strategy.exhaustive)": [[65, "neural_compressor.strategy.exhaustive.ExhaustiveTuneStrategy"]], "neural_compressor.strategy.exhaustive": [[65, "module-neural_compressor.strategy.exhaustive"]], "hawq_v2tunestrategy (class in neural_compressor.strategy.hawq_v2)": [[66, "neural_compressor.strategy.hawq_v2.HAWQ_V2TuneStrategy"]], "neural_compressor.strategy.hawq_v2": [[66, "module-neural_compressor.strategy.hawq_v2"]], "neural_compressor.strategy": [[67, "module-neural_compressor.strategy"]], "msetunestrategy (class in neural_compressor.strategy.mse)": [[68, "neural_compressor.strategy.mse.MSETuneStrategy"]], "neural_compressor.strategy.mse": [[68, "module-neural_compressor.strategy.mse"]], "mse_v2tunestrategy (class in neural_compressor.strategy.mse_v2)": [[69, "neural_compressor.strategy.mse_v2.MSE_V2TuneStrategy"]], "neural_compressor.strategy.mse_v2": [[69, "module-neural_compressor.strategy.mse_v2"]], "randomtunestrategy (class in neural_compressor.strategy.random)": [[70, "neural_compressor.strategy.random.RandomTuneStrategy"]], "neural_compressor.strategy.random": [[70, "module-neural_compressor.strategy.random"]], "tunestrategy (class in neural_compressor.strategy.strategy)": [[71, "neural_compressor.strategy.strategy.TuneStrategy"]], "tunestrategymeta (class in neural_compressor.strategy.strategy)": [[71, "neural_compressor.strategy.strategy.TuneStrategyMeta"]], "neural_compressor.strategy.strategy": [[71, "module-neural_compressor.strategy.strategy"]], "strategy_registry() (in module neural_compressor.strategy.strategy)": [[71, "neural_compressor.strategy.strategy.strategy_registry"]], "neural_compressor.strategy.utils.constant": [[72, "module-neural_compressor.strategy.utils.constant"]], "neural_compressor.strategy.utils": [[73, "module-neural_compressor.strategy.utils"]], "blockfallbacktuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.BlockFallbackTuningSampler"]], "fallbacktuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.FallbackTuningSampler"]], "lowerbitssampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.LowerBitsSampler"]], "modelwisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.ModelWiseTuningSampler"]], "optypewisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.OpTypeWiseTuningSampler"]], "opwisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.OpWiseTuningSampler"]], "smoothquantsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.SmoothQuantSampler"]], "tuningorder (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.TuningOrder"]], "tuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.TuningSampler"]], "weightonlyquantsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[74, "neural_compressor.strategy.utils.tuning_sampler.WeightOnlyQuantSampler"]], "neural_compressor.strategy.utils.tuning_sampler": [[74, "module-neural_compressor.strategy.utils.tuning_sampler"]], "tuningitem (class in neural_compressor.strategy.utils.tuning_space)": [[75, "neural_compressor.strategy.utils.tuning_space.TuningItem"]], "tuningspace (class in neural_compressor.strategy.utils.tuning_space)": [[75, "neural_compressor.strategy.utils.tuning_space.TuningSpace"]], "initial_tuning_cfg_with_quant_mode() (in module neural_compressor.strategy.utils.tuning_space)": [[75, "neural_compressor.strategy.utils.tuning_space.initial_tuning_cfg_with_quant_mode"]], "neural_compressor.strategy.utils.tuning_space": [[75, "module-neural_compressor.strategy.utils.tuning_space"]], "pattern_to_internal() (in module neural_compressor.strategy.utils.tuning_space)": [[75, "neural_compressor.strategy.utils.tuning_space.pattern_to_internal"]], "pattern_to_path() (in module neural_compressor.strategy.utils.tuning_space)": [[75, "neural_compressor.strategy.utils.tuning_space.pattern_to_path"]], "quant_mode_from_pattern() (in module neural_compressor.strategy.utils.tuning_space)": [[75, "neural_compressor.strategy.utils.tuning_space.quant_mode_from_pattern"]], "optuningconfig (class in neural_compressor.strategy.utils.tuning_structs)": [[76, "neural_compressor.strategy.utils.tuning_structs.OpTuningConfig"]], "neural_compressor.strategy.utils.tuning_structs": [[76, "module-neural_compressor.strategy.utils.tuning_structs"]], "classregister (class in neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.ClassRegister"]], "ordereddefaultdict (class in neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.OrderedDefaultDict"]], "quantoptions (class in neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.QuantOptions"]], "quanttype (class in neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.QuantType"]], "build_slave_faker_model() (in module neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.build_slave_faker_model"]], "extract_data_type() (in module neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.extract_data_type"]], "get_adaptor_name() (in module neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.get_adaptor_name"]], "neural_compressor.strategy.utils.utility": [[77, "module-neural_compressor.strategy.utils.utility"]], "preprocess_user_cfg() (in module neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.preprocess_user_cfg"]], "reverted_data_type() (in module neural_compressor.strategy.utils.utility)": [[77, "neural_compressor.strategy.utils.utility.reverted_data_type"]], "neural_compressor.tensorflow.algorithms": [[78, "module-neural_compressor.tensorflow.algorithms"]], "smoothquantcalibration (class in neural_compressor.tensorflow.algorithms.smoother.calibration)": [[79, "neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibration"]], "smoothquantcalibrationllm (class in neural_compressor.tensorflow.algorithms.smoother.calibration)": [[79, "neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibrationLLM"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[79, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"]], "smoothquant (class in neural_compressor.tensorflow.algorithms.smoother.core)": [[80, "neural_compressor.tensorflow.algorithms.smoother.core.SmoothQuant"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[80, "module-neural_compressor.tensorflow.algorithms.smoother.core"]], "neural_compressor.tensorflow.algorithms.smoother": [[81, "module-neural_compressor.tensorflow.algorithms.smoother"]], "smoothquantscaler (class in neural_compressor.tensorflow.algorithms.smoother.scaler)": [[82, "neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScaler"]], "smoothquantscalerllm (class in neural_compressor.tensorflow.algorithms.smoother.scaler)": [[82, "neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScalerLLM"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[82, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"]], "neural_compressor.tensorflow.algorithms.static_quant": [[83, "module-neural_compressor.tensorflow.algorithms.static_quant"]], "kerasadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[84, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasAdaptor"]], "kerasconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[84, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasConfigConverter"]], "kerasquery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[84, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasQuery"]], "kerassurgery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[84, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasSurgery"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[84, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"]], "tensorflowadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[85, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorFlowAdaptor"]], "tensorflowconfig (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[85, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorFlowConfig"]], "tensorflowconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[85, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorflowConfigConverter"]], "tensorflowquery (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[85, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorflowQuery"]], "tensorflow_itexadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[85, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.Tensorflow_ITEXAdaptor"]], "neural_compressor.tensorflow.algorithms.static_quant.tensorflow": [[85, "module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow"]], "neural_compressor.tensorflow": [[86, "module-neural_compressor.tensorflow"]], "neural_compressor.tensorflow.keras": [[87, "module-neural_compressor.tensorflow.keras"]], "qconv2d (class in neural_compressor.tensorflow.keras.layers.conv2d)": [[88, "neural_compressor.tensorflow.keras.layers.conv2d.QConv2D"]], "initialize_int8_conv2d() (in module neural_compressor.tensorflow.keras.layers.conv2d)": [[88, "neural_compressor.tensorflow.keras.layers.conv2d.initialize_int8_conv2d"]], "neural_compressor.tensorflow.keras.layers.conv2d": [[88, "module-neural_compressor.tensorflow.keras.layers.conv2d"]], "qdense (class in neural_compressor.tensorflow.keras.layers.dense)": [[89, "neural_compressor.tensorflow.keras.layers.dense.QDense"]], "initialize_int8_dense() (in module neural_compressor.tensorflow.keras.layers.dense)": [[89, "neural_compressor.tensorflow.keras.layers.dense.initialize_int8_dense"]], "neural_compressor.tensorflow.keras.layers.dense": [[89, "module-neural_compressor.tensorflow.keras.layers.dense"]], "qdepthwiseconv2d (class in neural_compressor.tensorflow.keras.layers.depthwise_conv2d)": [[90, "neural_compressor.tensorflow.keras.layers.depthwise_conv2d.QDepthwiseConv2D"]], "initialize_int8_depthwise_conv2d() (in module neural_compressor.tensorflow.keras.layers.depthwise_conv2d)": [[90, "neural_compressor.tensorflow.keras.layers.depthwise_conv2d.initialize_int8_depthwise_conv2d"]], "neural_compressor.tensorflow.keras.layers.depthwise_conv2d": [[90, "module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d"]], "neural_compressor.tensorflow.keras.layers": [[91, "module-neural_compressor.tensorflow.keras.layers"]], "neural_compressor.tensorflow.keras.layers.layer_initializer": [[92, "module-neural_compressor.tensorflow.keras.layers.layer_initializer"]], "qavgpool2d (class in neural_compressor.tensorflow.keras.layers.pool2d)": [[93, "neural_compressor.tensorflow.keras.layers.pool2d.QAvgPool2D"]], "qmaxpool2d (class in neural_compressor.tensorflow.keras.layers.pool2d)": [[93, "neural_compressor.tensorflow.keras.layers.pool2d.QMaxPool2D"]], "initialize_int8_avgpool() (in module neural_compressor.tensorflow.keras.layers.pool2d)": [[93, "neural_compressor.tensorflow.keras.layers.pool2d.initialize_int8_avgpool"]], "initialize_int8_maxpool() (in module neural_compressor.tensorflow.keras.layers.pool2d)": [[93, "neural_compressor.tensorflow.keras.layers.pool2d.initialize_int8_maxpool"]], "neural_compressor.tensorflow.keras.layers.pool2d": [[93, "module-neural_compressor.tensorflow.keras.layers.pool2d"]], "qseparableconv2d (class in neural_compressor.tensorflow.keras.layers.separable_conv2d)": [[94, "neural_compressor.tensorflow.keras.layers.separable_conv2d.QSeparableConv2D"]], "initialize_int8_separable_conv2d() (in module neural_compressor.tensorflow.keras.layers.separable_conv2d)": [[94, "neural_compressor.tensorflow.keras.layers.separable_conv2d.initialize_int8_separable_conv2d"]], "neural_compressor.tensorflow.keras.layers.separable_conv2d": [[94, "module-neural_compressor.tensorflow.keras.layers.separable_conv2d"]], "operatorconfig (class in neural_compressor.tensorflow.keras.quantization.config)": [[95, "neural_compressor.tensorflow.keras.quantization.config.OperatorConfig"]], "staticquantconfig (class in neural_compressor.tensorflow.keras.quantization.config)": [[95, "neural_compressor.tensorflow.keras.quantization.config.StaticQuantConfig"]], "get_all_registered_configs() (in module neural_compressor.tensorflow.keras.quantization.config)": [[95, "neural_compressor.tensorflow.keras.quantization.config.get_all_registered_configs"]], "get_default_static_quant_config() (in module neural_compressor.tensorflow.keras.quantization.config)": [[95, "neural_compressor.tensorflow.keras.quantization.config.get_default_static_quant_config"]], "neural_compressor.tensorflow.keras.quantization.config": [[95, "module-neural_compressor.tensorflow.keras.quantization.config"]], "neural_compressor.tensorflow.keras.quantization": [[96, "module-neural_compressor.tensorflow.keras.quantization"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[97, "module-neural_compressor.tensorflow.quantization.algorithm_entry"]], "smooth_quant_entry() (in module neural_compressor.tensorflow.quantization.algorithm_entry)": [[97, "neural_compressor.tensorflow.quantization.algorithm_entry.smooth_quant_entry"]], "static_quant_entry() (in module neural_compressor.tensorflow.quantization.algorithm_entry)": [[97, "neural_compressor.tensorflow.quantization.algorithm_entry.static_quant_entry"]], "autotune() (in module neural_compressor.tensorflow.quantization.autotune)": [[98, "neural_compressor.tensorflow.quantization.autotune.autotune"]], "get_all_config_set() (in module neural_compressor.tensorflow.quantization.autotune)": [[98, "neural_compressor.tensorflow.quantization.autotune.get_all_config_set"]], "neural_compressor.tensorflow.quantization.autotune": [[98, "module-neural_compressor.tensorflow.quantization.autotune"]], "smoothquantconfig (class in neural_compressor.tensorflow.quantization.config)": [[99, "neural_compressor.tensorflow.quantization.config.SmoothQuantConfig"]], "staticquantconfig (class in neural_compressor.tensorflow.quantization.config)": [[99, "neural_compressor.tensorflow.quantization.config.StaticQuantConfig"]], "get_default_sq_config() (in module neural_compressor.tensorflow.quantization.config)": [[99, "neural_compressor.tensorflow.quantization.config.get_default_sq_config"]], "get_default_static_quant_config() (in module neural_compressor.tensorflow.quantization.config)": [[99, "neural_compressor.tensorflow.quantization.config.get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization.config": [[99, "module-neural_compressor.tensorflow.quantization.config"]], "neural_compressor.tensorflow.quantization": [[100, "module-neural_compressor.tensorflow.quantization"]], "need_apply() (in module neural_compressor.tensorflow.quantization.quantize)": [[101, "neural_compressor.tensorflow.quantization.quantize.need_apply"]], "neural_compressor.tensorflow.quantization.quantize": [[101, "module-neural_compressor.tensorflow.quantization.quantize"]], "quantize_model() (in module neural_compressor.tensorflow.quantization.quantize)": [[101, "neural_compressor.tensorflow.quantization.quantize.quantize_model"]], "quantize_model_with_single_config() (in module neural_compressor.tensorflow.quantization.quantize)": [[101, "neural_compressor.tensorflow.quantization.quantize.quantize_model_with_single_config"]], "graphconverter (class in neural_compressor.tensorflow.quantization.utils.graph_converter)": [[102, "neural_compressor.tensorflow.quantization.utils.graph_converter.GraphConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_converter": [[102, "module-neural_compressor.tensorflow.quantization.utils.graph_converter"]], "bf16convert (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert)": [[103, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert.BF16Convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert": [[103, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert"]], "dequantizecastoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer)": [[104, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer.DequantizeCastOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[104, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16": [[105, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16"]], "convertaddtobiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd)": [[106, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd.ConvertAddToBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[106, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"]], "convertlayoutoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout)": [[107, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout.ConvertLayoutOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[107, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"]], "convertleakyreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu)": [[108, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu.ConvertLeakyReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[108, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"]], "convertnantorandom (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random)": [[109, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random.ConvertNanToRandom"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[109, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"]], "convertplaceholdertoconst (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const)": [[110, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const.ConvertPlaceholderToConst"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[110, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"]], "dilatedcontraction (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction)": [[111, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction.DilatedContraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[111, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"]], "injectdummybiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd)": [[112, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd.InjectDummyBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[112, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"]], "expanddimsoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer)": [[113, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer.ExpandDimsOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[113, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"]], "fetchweightfromreshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape)": [[114, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape.FetchWeightFromReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[114, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "foldbatchnormnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm)": [[115, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm.FoldBatchNormNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[115, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"]], "graphfoldconstantoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant)": [[116, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant.GraphFoldConstantOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[116, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"]], "fusebiasaddandaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add)": [[117, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add.FuseBiasAddAndAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[117, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"]], "fusecolumnwisemuloptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul)": [[118, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul.FuseColumnWiseMulOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[118, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"]], "fuseconvwithmathoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math)": [[119, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math.FuseConvWithMathOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[119, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"]], "fusedecomposedbnoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.FuseDecomposedBNOptimizer"]], "bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.get_const_dim_count"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[120, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[120, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.values_from_const"]], "fusedecomposedinoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.FuseDecomposedINOptimizer"]], "bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.get_const_dim_count"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[121, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[121, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.values_from_const"]], "fusegeluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu)": [[122, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu.FuseGeluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[122, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"]], "fuselayernormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[123, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.FuseLayerNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[123, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[123, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[123, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_name_from_input"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[123, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.values_from_const"]], "fusepadwithconv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv)": [[124, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv.FusePadWithConv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[124, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"]], "fusepadwithfp32conv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv)": [[125, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv.FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[125, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "fusetransposereshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose)": [[126, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose.FuseTransposeReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[126, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"]], "graphcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer)": [[127, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer.GraphCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[127, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"]], "grappleroptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass)": [[128, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass.GrapplerOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[128, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[129, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"]], "insertprintminmaxnode (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node)": [[130, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node.InsertPrintMinMaxNode"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[130, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"]], "movesqueezeafterreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu)": [[131, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu.MoveSqueezeAfterReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[131, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"]], "preoptimization (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize)": [[132, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize.PreOptimization"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[132, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"]], "removetrainingnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes)": [[133, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes.RemoveTrainingNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[133, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"]], "renamebatchnormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm)": [[134, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm.RenameBatchNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[134, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"]], "splitsharedinputoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input)": [[135, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input.SplitSharedInputOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[135, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"]], "stripequivalentnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes)": [[136, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes.StripEquivalentNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[136, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"]], "stripunusednodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes)": [[137, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes.StripUnusedNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[137, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"]], "switchoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer)": [[138, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer.SwitchOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[138, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"]], "graphrewriterbase (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base)": [[139, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base.GraphRewriterBase"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[139, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[140, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"]], "freezefakequantopoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant)": [[141, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant.FreezeFakeQuantOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant": [[141, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant"]], "freezevaluetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value)": [[142, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value.FreezeValueTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value": [[142, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value"]], "fuseconvredundantdequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize)": [[143, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize.FuseConvRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[143, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "fuseconvrequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize)": [[144, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize.FuseConvRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize": [[144, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize"]], "fusematmulredundantdequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize)": [[145, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize.FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[145, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "fusematmulrequantizedequantizenewapitransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[146, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeNewAPITransformer"]], "fusematmulrequantizedequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[146, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeTransformer"]], "fusematmulrequantizenewapitransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[146, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeNewAPITransformer"]], "fusematmulrequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[146, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize": [[146, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8": [[147, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8"]], "metainfochangingmemopoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer)": [[148, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer.MetaInfoChangingMemOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer": [[148, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer"]], "posthostconstconverter (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter)": [[149, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter.PostHostConstConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter": [[149, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter"]], "postcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse)": [[150, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse.PostCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse": [[150, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse"]], "scalepropagationtransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation)": [[151, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation.ScaleProPagationTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation": [[151, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq": [[152, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq"]], "generategraphwithqdqpattern (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern)": [[153, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern.GenerateGraphWithQDQPattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern": [[153, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern"]], "mergeduplicatedqdqoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq)": [[154, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq.MergeDuplicatedQDQOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq": [[154, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "shareqdqforitexypatternoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern)": [[155, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern.ShareQDQForItexYPatternOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern": [[155, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "graphanalyzer (class in neural_compressor.tensorflow.quantization.utils.graph_util)": [[156, "neural_compressor.tensorflow.quantization.utils.graph_util.GraphAnalyzer"]], "graphrewriterhelper (class in neural_compressor.tensorflow.quantization.utils.graph_util)": [[156, "neural_compressor.tensorflow.quantization.utils.graph_util.GraphRewriterHelper"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[156, "module-neural_compressor.tensorflow.quantization.utils.graph_util"]], "neural_compressor.tensorflow.quantization.utils": [[157, "module-neural_compressor.tensorflow.quantization.utils"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph": [[158, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn)": [[159, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn": [[159, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2)": [[160, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2": [[160, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv)": [[161, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv.FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv": [[161, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv"]], "fusenodestartwithdeconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv)": [[162, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv.FuseNodeStartWithDeconv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv": [[162, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv"]], "fusenodestartwithfusedinstancenorm (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in)": [[163, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in.FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in": [[163, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in"]], "fusenodestartwithmatmul (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul)": [[164, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul": [[164, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul"]], "fusenodestartwithpooling (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling)": [[165, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling.FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling": [[165, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq": [[166, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq"]], "optimizeqdqgraph (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq)": [[167, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq.OptimizeQDQGraph"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq": [[167, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq"]], "quantizegraphbase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base)": [[168, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base.QuantizeGraphBase"]], "quantizenodebase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base)": [[168, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base.QuantizeNodeBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base": [[168, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn)": [[169, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn": [[169, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2)": [[170, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2": [[170, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv)": [[171, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv.FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv": [[171, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv"]], "quantizegraphforintel (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu)": [[172, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu.QuantizeGraphForIntel"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu": [[172, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu"]], "fusenodestartwithmatmul (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul)": [[173, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul": [[173, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul"]], "fusenodestartwithpooling (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling)": [[174, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling.FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling": [[174, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling"]], "quantizegraphhelper (class in neural_compressor.tensorflow.quantization.utils.quantize_graph_common)": [[175, "neural_compressor.tensorflow.quantization.utils.quantize_graph_common.QuantizeGraphHelper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[175, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"]], "biascorrection (class in neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction)": [[176, "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction.BiasCorrection"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction": [[176, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction"]], "graphtransformbase (class in neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base)": [[177, "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base.GraphTransformBase"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base": [[177, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base"]], "neural_compressor.tensorflow.quantization.utils.transform_graph": [[178, "module-neural_compressor.tensorflow.quantization.utils.transform_graph"]], "insertlogging (class in neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging)": [[179, "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging.InsertLogging"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging": [[179, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging"]], "rerangequantizedconcat (class in neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat)": [[180, "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat.RerangeQuantizedConcat"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat": [[180, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat"]], "apply_inlining() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.apply_inlining"]], "collate_tf_preds() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.collate_tf_preds"]], "construct_function_from_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.construct_function_from_graph_def"]], "fix_ref_type_of_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.fix_ref_type_of_graph_def"]], "generate_feed_dict() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.generate_feed_dict"]], "get_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.get_graph_def"]], "get_input_output_node_names() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.get_input_output_node_names"]], "get_model_input_shape() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.get_model_input_shape"]], "get_tensor_by_name() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.get_tensor_by_name"]], "is_ckpt_format() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.is_ckpt_format"]], "is_saved_model_format() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.is_saved_model_format"]], "iterator_sess_run() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.iterator_sess_run"]], "neural_compressor.tensorflow.quantization.utils.utility": [[181, "module-neural_compressor.tensorflow.quantization.utils.utility"]], "parse_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.parse_saved_model"]], "read_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.read_graph"]], "reconstruct_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.reconstruct_saved_model"]], "strip_equivalent_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.strip_equivalent_nodes"]], "strip_unused_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.strip_unused_nodes"]], "write_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[181, "neural_compressor.tensorflow.quantization.utils.utility.write_graph"]], "neural_compressor.tensorflow.utils.constants": [[182, "module-neural_compressor.tensorflow.utils.constants"]], "basedataloader (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.BaseDataLoader"]], "batchsampler (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.BatchSampler"]], "dummydataset (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.DummyDataset"]], "dummydatasetv2 (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.DummyDatasetV2"]], "indexfetcher (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.IndexFetcher"]], "iterablefetcher (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.IterableFetcher"]], "iterablesampler (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.IterableSampler"]], "sequentialsampler (class in neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.SequentialSampler"]], "default_collate() (in module neural_compressor.tensorflow.utils.data)": [[183, "neural_compressor.tensorflow.utils.data.default_collate"]], "neural_compressor.tensorflow.utils.data": [[183, "module-neural_compressor.tensorflow.utils.data"]], "neural_compressor.tensorflow.utils": [[184, "module-neural_compressor.tensorflow.utils"]], "model (class in neural_compressor.tensorflow.utils.model)": [[185, "neural_compressor.tensorflow.utils.model.Model"]], "tensorflowglobalconfig (class in neural_compressor.tensorflow.utils.model)": [[185, "neural_compressor.tensorflow.utils.model.TensorflowGlobalConfig"]], "neural_compressor.tensorflow.utils.model": [[185, "module-neural_compressor.tensorflow.utils.model"]], "basemodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.BaseModel"]], "kerasmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.KerasModel"]], "tensorflowbasemodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowBaseModel"]], "tensorflowcheckpointmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowCheckpointModel"]], "tensorflowllmmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowLLMModel"]], "tensorflowmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowModel"]], "tensorflowsavedmodelmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowSavedModelModel"]], "checkpoint_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.checkpoint_session"]], "estimator_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.estimator_session"]], "frozen_pb_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.frozen_pb_session"]], "get_model_type() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.get_model_type"]], "get_tf_model_type() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.get_tf_model_type"]], "graph_def_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.graph_def_session"]], "graph_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.graph_session"]], "keras_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.keras_session"]], "load_saved_model() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.load_saved_model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[186, "module-neural_compressor.tensorflow.utils.model_wrappers"]], "saved_model_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.saved_model_session"]], "slim_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.slim_session"]], "try_loading_keras() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.try_loading_keras"]], "validate_and_inference_input_output() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.validate_and_inference_input_output"]], "validate_graph_node() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[186, "neural_compressor.tensorflow.utils.model_wrappers.validate_graph_node"]], "captureoutputtofile (class in neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.CaptureOutputToFile"]], "cpuinfo (class in neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.CpuInfo"]], "tfslimnetsfactory (class in neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.TFSlimNetsFactory"]], "combine_histogram() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.combine_histogram"]], "deep_get() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.deep_get"]], "disable_random() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.disable_random"]], "dump_elapsed_time() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.dump_elapsed_time"]], "get_all_fp32_data() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.get_all_fp32_data"]], "get_tensor_histogram() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.get_tensor_histogram"]], "itex_installed() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.itex_installed"]], "neural_compressor.tensorflow.utils.utility": [[187, "module-neural_compressor.tensorflow.utils.utility"]], "register_algo() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.register_algo"]], "singleton() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.singleton"]], "valid_keras_format() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.valid_keras_format"]], "version1_eq_version2() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.tensorflow.utils.utility)": [[187, "neural_compressor.tensorflow.utils.utility.version1_lte_version2"]], "quantizer (class in neural_compressor.torch.algorithms.base_algorithm)": [[188, "neural_compressor.torch.algorithms.base_algorithm.Quantizer"]], "neural_compressor.torch.algorithms.base_algorithm": [[188, "module-neural_compressor.torch.algorithms.base_algorithm"]], "neural_compressor.torch.algorithms": [[189, "module-neural_compressor.torch.algorithms"]], "neural_compressor.torch.algorithms.layer_wise": [[190, "module-neural_compressor.torch.algorithms.layer_wise"]], "load() (in module neural_compressor.torch.algorithms.layer_wise.load)": [[191, "neural_compressor.torch.algorithms.layer_wise.load.load"]], "neural_compressor.torch.algorithms.layer_wise.load": [[191, "module-neural_compressor.torch.algorithms.layer_wise.load"]], "pickleerror": [[192, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.PickleError"]], "picklingerror": [[192, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.PicklingError"]], "unpicklingerror": [[192, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.UnpicklingError"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[192, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"]], "qdqlayer (class in neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.QDQLayer"]], "clean_module_weight() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.clean_module_weight"]], "dowload_hf_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.dowload_hf_model"]], "get_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.get_children"]], "get_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.get_module"]], "get_named_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.get_named_children"]], "get_super_module_by_name() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.get_super_module_by_name"]], "load_empty_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.load_empty_model"]], "load_layer_wise_quantized_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.load_layer_wise_quantized_model"]], "load_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.load_module"]], "load_tensor() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.load_tensor"]], "load_tensor_from_shard() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_shard"]], "load_value() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.load_value"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[193, "module-neural_compressor.torch.algorithms.layer_wise.utils"]], "register_weight_hooks() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.register_weight_hooks"]], "update_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[193, "neural_compressor.torch.algorithms.layer_wise.utils.update_module"]], "halfprecisionconverter (class in neural_compressor.torch.algorithms.mixed_precision.half_precision_convert)": [[194, "neural_compressor.torch.algorithms.mixed_precision.half_precision_convert.HalfPrecisionConverter"]], "neural_compressor.torch.algorithms.mixed_precision.half_precision_convert": [[194, "module-neural_compressor.torch.algorithms.mixed_precision.half_precision_convert"]], "neural_compressor.torch.algorithms.mixed_precision": [[195, "module-neural_compressor.torch.algorithms.mixed_precision"]], "halfprecisionmodulewrapper (class in neural_compressor.torch.algorithms.mixed_precision.module_wrappers)": [[196, "neural_compressor.torch.algorithms.mixed_precision.module_wrappers.HalfPrecisionModuleWrapper"]], "neural_compressor.torch.algorithms.mixed_precision.module_wrappers": [[196, "module-neural_compressor.torch.algorithms.mixed_precision.module_wrappers"]], "neural_compressor.torch.algorithms.mx_quant": [[197, "module-neural_compressor.torch.algorithms.mx_quant"]], "mxlinear (class in neural_compressor.torch.algorithms.mx_quant.mx)": [[198, "neural_compressor.torch.algorithms.mx_quant.mx.MXLinear"]], "mxquantizer (class in neural_compressor.torch.algorithms.mx_quant.mx)": [[198, "neural_compressor.torch.algorithms.mx_quant.mx.MXQuantizer"]], "neural_compressor.torch.algorithms.mx_quant.mx": [[198, "module-neural_compressor.torch.algorithms.mx_quant.mx"]], "elemformat (class in neural_compressor.torch.algorithms.mx_quant.utils)": [[199, "neural_compressor.torch.algorithms.mx_quant.utils.ElemFormat"]], "roundingmode (class in neural_compressor.torch.algorithms.mx_quant.utils)": [[199, "neural_compressor.torch.algorithms.mx_quant.utils.RoundingMode"]], "neural_compressor.torch.algorithms.mx_quant.utils": [[199, "module-neural_compressor.torch.algorithms.mx_quant.utils"]], "quantize_elemwise_op() (in module neural_compressor.torch.algorithms.mx_quant.utils)": [[199, "neural_compressor.torch.algorithms.mx_quant.utils.quantize_elemwise_op"]], "quantize_mx_op() (in module neural_compressor.torch.algorithms.mx_quant.utils)": [[199, "neural_compressor.torch.algorithms.mx_quant.utils.quantize_mx_op"]], "w8a8pt2equantizer (class in neural_compressor.torch.algorithms.pt2e_quant.core)": [[200, "neural_compressor.torch.algorithms.pt2e_quant.core.W8A8PT2EQuantizer"]], "neural_compressor.torch.algorithms.pt2e_quant.core": [[200, "module-neural_compressor.torch.algorithms.pt2e_quant.core"]], "patternpair (class in neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair"]], "apply_single_pattern_pair() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.apply_single_pattern_pair"]], "fn (neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.patternpair attribute)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair.fn"]], "get_filter_fn() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_filter_fn"]], "get_half_precision_node_set() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_half_precision_node_set"]], "get_unquantized_node_set() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_unquantized_node_set"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter": [[201, "module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter"]], "pattern_factory() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.pattern_factory"]], "replace_pattern (neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.patternpair attribute)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair.replace_pattern"]], "search_pattern (neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.patternpair attribute)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair.search_pattern"]], "transformation() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[201, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.transformation"]], "neural_compressor.torch.algorithms.pt2e_quant": [[202, "module-neural_compressor.torch.algorithms.pt2e_quant"]], "load() (in module neural_compressor.torch.algorithms.pt2e_quant.save_load)": [[203, "neural_compressor.torch.algorithms.pt2e_quant.save_load.load"]], "neural_compressor.torch.algorithms.pt2e_quant.save_load": [[203, "module-neural_compressor.torch.algorithms.pt2e_quant.save_load"]], "save() (in module neural_compressor.torch.algorithms.pt2e_quant.save_load)": [[203, "neural_compressor.torch.algorithms.pt2e_quant.save_load.save"]], "create_quant_spec_from_config() (in module neural_compressor.torch.algorithms.pt2e_quant.utility)": [[204, "neural_compressor.torch.algorithms.pt2e_quant.utility.create_quant_spec_from_config"]], "create_xiq_quantizer_from_pt2e_config() (in module neural_compressor.torch.algorithms.pt2e_quant.utility)": [[204, "neural_compressor.torch.algorithms.pt2e_quant.utility.create_xiq_quantizer_from_pt2e_config"]], "neural_compressor.torch.algorithms.pt2e_quant.utility": [[204, "module-neural_compressor.torch.algorithms.pt2e_quant.utility"]], "neural_compressor.torch.algorithms.smooth_quant": [[205, "module-neural_compressor.torch.algorithms.smooth_quant"]], "neural_compressor.torch.algorithms.smooth_quant.save_load": [[206, "module-neural_compressor.torch.algorithms.smooth_quant.save_load"]], "recover_model_from_json() (in module neural_compressor.torch.algorithms.smooth_quant.save_load)": [[206, "neural_compressor.torch.algorithms.smooth_quant.save_load.recover_model_from_json"]], "smoothquantquantizer (class in neural_compressor.torch.algorithms.smooth_quant.smooth_quant)": [[207, "neural_compressor.torch.algorithms.smooth_quant.smooth_quant.SmoothQuantQuantizer"]], "neural_compressor.torch.algorithms.smooth_quant.smooth_quant": [[207, "module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant"]], "qdq_quantize() (in module neural_compressor.torch.algorithms.smooth_quant.smooth_quant)": [[207, "neural_compressor.torch.algorithms.smooth_quant.smooth_quant.qdq_quantize"]], "autoalpha (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.AutoAlpha"]], "calibration (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.Calibration"]], "graphtrace (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.GraphTrace"]], "sqlinearwrapper (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.SQLinearWrapper"]], "torchsmoothquant (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.TorchSmoothQuant"]], "wrapperlayer (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.WrapperLayer"]], "build_captured_dataloader() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.build_captured_dataloader"]], "cal_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.cal_scale"]], "cfg_to_qconfig() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.cfg_to_qconfig"]], "check_cfg_and_qconfig() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.check_cfg_and_qconfig"]], "dump_model_op_stats() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.dump_model_op_stats"]], "enough_memo_store_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.enough_memo_store_scale"]], "forward_wrapper() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.forward_wrapper"]], "get_module() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.get_module"]], "get_parent() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.get_parent"]], "get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.get_quantizable_ops_recursively"]], "model_forward() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.model_forward"]], "model_forward_per_sample() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.model_forward_per_sample"]], "move_input_to_device() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.move_input_to_device"]], "neural_compressor.torch.algorithms.smooth_quant.utility": [[208, "module-neural_compressor.torch.algorithms.smooth_quant.utility"]], "quant_dequant_w_v1() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.quant_dequant_w_v1"]], "quant_dequant_x_v1() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.quant_dequant_x_v1"]], "register_autotune() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.register_autotune"]], "reshape_in_channel_to_last() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.reshape_in_channel_to_last"]], "reshape_scale_as_input() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.reshape_scale_as_input"]], "reshape_scale_as_weight() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.reshape_scale_as_weight"]], "set_module() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.set_module"]], "update_sq_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[208, "neural_compressor.torch.algorithms.smooth_quant.utility.update_sq_scale"]], "neural_compressor.torch.algorithms.static_quant": [[209, "module-neural_compressor.torch.algorithms.static_quant"]], "load() (in module neural_compressor.torch.algorithms.static_quant.save_load)": [[210, "neural_compressor.torch.algorithms.static_quant.save_load.load"]], "neural_compressor.torch.algorithms.static_quant.save_load": [[210, "module-neural_compressor.torch.algorithms.static_quant.save_load"]], "save() (in module neural_compressor.torch.algorithms.static_quant.save_load)": [[210, "neural_compressor.torch.algorithms.static_quant.save_load.save"]], "staticquantquantizer (class in neural_compressor.torch.algorithms.static_quant.static_quant)": [[211, "neural_compressor.torch.algorithms.static_quant.static_quant.StaticQuantQuantizer"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[211, "module-neural_compressor.torch.algorithms.static_quant.static_quant"]], "transformerbasedmodelblockpatterndetector (class in neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.TransformerBasedModelBlockPatternDetector"]], "cfg_to_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.cfg_to_qconfig"]], "check_cfg_and_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.check_cfg_and_qconfig"]], "dump_model_op_stats() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.dump_model_op_stats"]], "generate_activation_observer() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.generate_activation_observer"]], "generate_xpu_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.generate_xpu_qconfig"]], "get_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.get_depth"]], "get_dict_at_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.get_dict_at_depth"]], "get_element_under_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.get_element_under_depth"]], "get_quantizable_ops_from_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_from_cfgs"]], "get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_recursively"]], "neural_compressor.torch.algorithms.static_quant.utility": [[212, "module-neural_compressor.torch.algorithms.static_quant.utility"]], "parse_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.parse_cfgs"]], "simple_inference() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[212, "neural_compressor.torch.algorithms.static_quant.utility.simple_inference"]], "autoroundquantizer (class in neural_compressor.torch.algorithms.weight_only.autoround)": [[213, "neural_compressor.torch.algorithms.weight_only.autoround.AutoRoundQuantizer"]], "get_dataloader() (in module neural_compressor.torch.algorithms.weight_only.autoround)": [[213, "neural_compressor.torch.algorithms.weight_only.autoround.get_dataloader"]], "neural_compressor.torch.algorithms.weight_only.autoround": [[213, "module-neural_compressor.torch.algorithms.weight_only.autoround"]], "awqquantizer (class in neural_compressor.torch.algorithms.weight_only.awq)": [[214, "neural_compressor.torch.algorithms.weight_only.awq.AWQQuantizer"]], "neural_compressor.torch.algorithms.weight_only.awq": [[214, "module-neural_compressor.torch.algorithms.weight_only.awq"]], "gptq (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.GPTQ"]], "gptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.GPTQuantizer"]], "quantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.Quantizer"]], "rawgptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.RAWGPTQuantizer"]], "find_layers() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.find_layers"]], "find_layers_name() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.find_layers_name"]], "is_leaf() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.is_leaf"]], "log_quantizable_layers_per_transformer() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.log_quantizable_layers_per_transformer"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[215, "module-neural_compressor.torch.algorithms.weight_only.gptq"]], "trace_gptq_target_blocks() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[215, "neural_compressor.torch.algorithms.weight_only.gptq.trace_gptq_target_blocks"]], "packer (class in neural_compressor.torch.algorithms.weight_only.hqq.bitpack)": [[216, "neural_compressor.torch.algorithms.weight_only.hqq.bitpack.Packer"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[216, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"]], "hqqmoduleconfig (class in neural_compressor.torch.algorithms.weight_only.hqq.config)": [[217, "neural_compressor.torch.algorithms.weight_only.hqq.config.HQQModuleConfig"]], "qtensorconfig (class in neural_compressor.torch.algorithms.weight_only.hqq.config)": [[217, "neural_compressor.torch.algorithms.weight_only.hqq.config.QTensorConfig"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[217, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"]], "hqqlinear (class in neural_compressor.torch.algorithms.weight_only.hqq.core)": [[218, "neural_compressor.torch.algorithms.weight_only.hqq.core.HQQLinear"]], "hqqtensorhandle (class in neural_compressor.torch.algorithms.weight_only.hqq.core)": [[218, "neural_compressor.torch.algorithms.weight_only.hqq.core.HQQTensorHandle"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[218, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[219, "module-neural_compressor.torch.algorithms.weight_only.hqq"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[220, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"]], "optimize_weights_proximal_legacy() (in module neural_compressor.torch.algorithms.weight_only.hqq.optimizer)": [[220, "neural_compressor.torch.algorithms.weight_only.hqq.optimizer.optimize_weights_proximal_legacy"]], "qtensor (class in neural_compressor.torch.algorithms.weight_only.hqq.qtensor)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensor"]], "qtensormetainfo (class in neural_compressor.torch.algorithms.weight_only.hqq.qtensor)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo"]], "axis (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.axis"]], "group_size (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.group_size"]], "nbits (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.nbits"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[221, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"]], "packing (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.packing"]], "shape (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)": [[221, "neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.shape"]], "hqquantizer (class in neural_compressor.torch.algorithms.weight_only.hqq.quantizer)": [[222, "neural_compressor.torch.algorithms.weight_only.hqq.quantizer.HQQuantizer"]], "filter_fn() (in module neural_compressor.torch.algorithms.weight_only.hqq.quantizer)": [[222, "neural_compressor.torch.algorithms.weight_only.hqq.quantizer.filter_fn"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[222, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"]], "patch_hqq_moduile() (in module neural_compressor.torch.algorithms.weight_only.hqq.quantizer)": [[222, "neural_compressor.torch.algorithms.weight_only.hqq.quantizer.patch_hqq_moduile"]], "replacement_fn() (in module neural_compressor.torch.algorithms.weight_only.hqq.quantizer)": [[222, "neural_compressor.torch.algorithms.weight_only.hqq.quantizer.replacement_fn"]], "neural_compressor.torch.algorithms.weight_only": [[223, "module-neural_compressor.torch.algorithms.weight_only"]], "fakeaffinetensorquantfunction (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.FakeAffineTensorQuantFunction"]], "hpuweightonlylinear (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.HPUWeightOnlyLinear"]], "incweightonlylinear (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.INCWeightOnlyLinear"]], "mullinear (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.MulLinear"]], "qdqlayer (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.QDQLayer"]], "teqlinearfakequant (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.TEQLinearFakeQuant"]], "unpackedweightonlylinearparams (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.UnpackedWeightOnlyLinearParams"]], "weightonlylinear (class in neural_compressor.torch.algorithms.weight_only.modules)": [[224, "neural_compressor.torch.algorithms.weight_only.modules.WeightOnlyLinear"]], "neural_compressor.torch.algorithms.weight_only.modules": [[224, "module-neural_compressor.torch.algorithms.weight_only.modules"]], "rtnquantizer (class in neural_compressor.torch.algorithms.weight_only.rtn)": [[225, "neural_compressor.torch.algorithms.weight_only.rtn.RTNQuantizer"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[225, "module-neural_compressor.torch.algorithms.weight_only.rtn"]], "woqmodelloader (class in neural_compressor.torch.algorithms.weight_only.save_load)": [[226, "neural_compressor.torch.algorithms.weight_only.save_load.WOQModelLoader"]], "load() (in module neural_compressor.torch.algorithms.weight_only.save_load)": [[226, "neural_compressor.torch.algorithms.weight_only.save_load.load"]], "neural_compressor.torch.algorithms.weight_only.save_load": [[226, "module-neural_compressor.torch.algorithms.weight_only.save_load"]], "save() (in module neural_compressor.torch.algorithms.weight_only.save_load)": [[226, "neural_compressor.torch.algorithms.weight_only.save_load.save"]], "tequantizer (class in neural_compressor.torch.algorithms.weight_only.teq)": [[227, "neural_compressor.torch.algorithms.weight_only.teq.TEQuantizer"]], "trainableequivalenttransformation (class in neural_compressor.torch.algorithms.weight_only.teq)": [[227, "neural_compressor.torch.algorithms.weight_only.teq.TrainableEquivalentTransformation"]], "neural_compressor.torch.algorithms.weight_only.teq": [[227, "module-neural_compressor.torch.algorithms.weight_only.teq"]], "graphtrace (class in neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.GraphTrace"]], "fetch_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.fetch_module"]], "forward_wrapper() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.forward_wrapper"]], "get_absorb_layers() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.get_absorb_layers"]], "get_block_prefix() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.get_block_prefix"]], "get_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.get_module"]], "get_module_input_output() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.get_module_input_output"]], "get_parent() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.get_parent"]], "model_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.model_forward"]], "move_input_to_device() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.move_input_to_device"]], "neural_compressor.torch.algorithms.weight_only.utility": [[228, "module-neural_compressor.torch.algorithms.weight_only.utility"]], "qdq_weight_actor() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_actor"]], "qdq_weight_asym() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_asym"]], "qdq_weight_sym() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_sym"]], "quant_tensor() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.quant_tensor"]], "quant_weight_w_scale() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.quant_weight_w_scale"]], "quantize_4bit() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.quantize_4bit"]], "recover_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.recover_forward"]], "replace_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.replace_forward"]], "search_clip() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.search_clip"]], "set_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[228, "neural_compressor.torch.algorithms.weight_only.utility.set_module"]], "neural_compressor.torch.export": [[229, "module-neural_compressor.torch.export"]], "export() (in module neural_compressor.torch.export.pt2e_export)": [[230, "neural_compressor.torch.export.pt2e_export.export"]], "export_model_for_pt2e_quant() (in module neural_compressor.torch.export.pt2e_export)": [[230, "neural_compressor.torch.export.pt2e_export.export_model_for_pt2e_quant"]], "neural_compressor.torch.export.pt2e_export": [[230, "module-neural_compressor.torch.export.pt2e_export"]], "neural_compressor.torch": [[231, "module-neural_compressor.torch"]], "autoround_quantize_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.autoround_quantize_entry"]], "awq_quantize_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.awq_quantize_entry"]], "fp8_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.fp8_entry"]], "gptq_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.gptq_entry"]], "hqq_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.hqq_entry"]], "mixed_precision_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.mixed_precision_entry"]], "mx_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.mx_quant_entry"]], "neural_compressor.torch.quantization.algorithm_entry": [[232, "module-neural_compressor.torch.quantization.algorithm_entry"]], "pt2e_dynamic_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.pt2e_dynamic_quant_entry"]], "pt2e_static_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.pt2e_static_quant_entry"]], "rtn_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.rtn_entry"]], "smooth_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.smooth_quant_entry"]], "static_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.static_quant_entry"]], "teq_quantize_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[232, "neural_compressor.torch.quantization.algorithm_entry.teq_quantize_entry"]], "autotune() (in module neural_compressor.torch.quantization.autotune)": [[233, "neural_compressor.torch.quantization.autotune.autotune"]], "get_all_config_set() (in module neural_compressor.torch.quantization.autotune)": [[233, "neural_compressor.torch.quantization.autotune.get_all_config_set"]], "get_rtn_double_quant_config_set() (in module neural_compressor.torch.quantization.autotune)": [[233, "neural_compressor.torch.quantization.autotune.get_rtn_double_quant_config_set"]], "neural_compressor.torch.quantization.autotune": [[233, "module-neural_compressor.torch.quantization.autotune"]], "awqconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.AWQConfig"]], "autoroundconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.AutoRoundConfig"]], "dynamicquantconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.DynamicQuantConfig"]], "fp8config (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.FP8Config"]], "gptqconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.GPTQConfig"]], "hqqconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.HQQConfig"]], "mxquantconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.MXQuantConfig"]], "mixedprecisionconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.MixedPrecisionConfig"]], "operatorconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.OperatorConfig"]], "rtnconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.RTNConfig"]], "smoothquantconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.SmoothQuantConfig"]], "staticquantconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.StaticQuantConfig"]], "teqconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.TEQConfig"]], "torchbaseconfig (class in neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.TorchBaseConfig"]], "get_all_registered_configs() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_all_registered_configs"]], "get_default_autoround_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_AutoRound_config"]], "get_default_awq_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_awq_config"]], "get_default_double_quant_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_double_quant_config"]], "get_default_dynamic_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_dynamic_config"]], "get_default_fp8_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_fp8_config"]], "get_default_fp8_config_set() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_fp8_config_set"]], "get_default_gptq_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_gptq_config"]], "get_default_hqq_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_hqq_config"]], "get_default_mixed_precision_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_mixed_precision_config"]], "get_default_mixed_precision_config_set() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_mixed_precision_config_set"]], "get_default_mx_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_mx_config"]], "get_default_rtn_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_rtn_config"]], "get_default_sq_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_sq_config"]], "get_default_static_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_static_config"]], "get_default_teq_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_default_teq_config"]], "get_woq_tuning_config() (in module neural_compressor.torch.quantization.config)": [[234, "neural_compressor.torch.quantization.config.get_woq_tuning_config"]], "neural_compressor.torch.quantization.config": [[234, "module-neural_compressor.torch.quantization.config"]], "neural_compressor.torch.quantization": [[235, "module-neural_compressor.torch.quantization"]], "load() (in module neural_compressor.torch.quantization.load_entry)": [[236, "neural_compressor.torch.quantization.load_entry.load"]], "neural_compressor.torch.quantization.load_entry": [[236, "module-neural_compressor.torch.quantization.load_entry"]], "convert() (in module neural_compressor.torch.quantization.quantize)": [[237, "neural_compressor.torch.quantization.quantize.convert"]], "finalize_calibration() (in module neural_compressor.torch.quantization.quantize)": [[237, "neural_compressor.torch.quantization.quantize.finalize_calibration"]], "need_apply() (in module neural_compressor.torch.quantization.quantize)": [[237, "neural_compressor.torch.quantization.quantize.need_apply"]], "neural_compressor.torch.quantization.quantize": [[237, "module-neural_compressor.torch.quantization.quantize"]], "prepare() (in module neural_compressor.torch.quantization.quantize)": [[237, "neural_compressor.torch.quantization.quantize.prepare"]], "quantize() (in module neural_compressor.torch.quantization.quantize)": [[237, "neural_compressor.torch.quantization.quantize.quantize"]], "acceleratorregistry (class in neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.AcceleratorRegistry"]], "auto_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.Auto_Accelerator"]], "cpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.CPU_Accelerator"]], "cuda_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.CUDA_Accelerator"]], "hpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.HPU_Accelerator"]], "xpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.XPU_Accelerator"]], "auto_detect_accelerator() (in module neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.auto_detect_accelerator"]], "neural_compressor.torch.utils.auto_accelerator": [[238, "module-neural_compressor.torch.utils.auto_accelerator"]], "register_accelerator() (in module neural_compressor.torch.utils.auto_accelerator)": [[238, "neural_compressor.torch.utils.auto_accelerator.register_accelerator"]], "loadformat (class in neural_compressor.torch.utils.constants)": [[239, "neural_compressor.torch.utils.constants.LoadFormat"]], "neural_compressor.torch.utils.constants": [[239, "module-neural_compressor.torch.utils.constants"]], "device_synchronize() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.device_synchronize"]], "get_accelerator() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.get_accelerator"]], "get_ipex_version() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.get_ipex_version"]], "get_torch_version() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.get_torch_version"]], "is_hpex_available() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.is_hpex_available"]], "is_ipex_available() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.is_ipex_available"]], "is_ipex_imported() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.is_ipex_imported"]], "is_package_available() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.is_package_available"]], "is_transformers_imported() (in module neural_compressor.torch.utils.environ)": [[240, "neural_compressor.torch.utils.environ.is_transformers_imported"]], "neural_compressor.torch.utils.environ": [[240, "module-neural_compressor.torch.utils.environ"]], "neural_compressor.torch.utils": [[241, "module-neural_compressor.torch.utils"]], "dowload_hf_model() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.dowload_hf_model"]], "dump_model_op_stats() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.dump_model_op_stats"]], "fetch_module() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.fetch_module"]], "get_double_quant_config_dict() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.get_double_quant_config_dict"]], "get_model_device() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.get_model_device"]], "get_model_info() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.get_model_info"]], "get_processor_type_from_user_config() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.get_processor_type_from_user_config"]], "get_quantizer() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.get_quantizer"]], "load_empty_model() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.load_empty_model"]], "neural_compressor.torch.utils.utility": [[242, "module-neural_compressor.torch.utils.utility"]], "postprocess_model() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.postprocess_model"]], "register_algo() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.register_algo"]], "set_module() (in module neural_compressor.torch.utils.utility)": [[242, "neural_compressor.torch.utils.utility.set_module"]], "callbacks (class in neural_compressor.training)": [[243, "neural_compressor.training.CallBacks"]], "compressionmanager (class in neural_compressor.training)": [[243, "neural_compressor.training.CompressionManager"]], "fit() (in module neural_compressor.training)": [[243, "neural_compressor.training.fit"]], "neural_compressor.training": [[243, "module-neural_compressor.training"]], "prepare_compression() (in module neural_compressor.training)": [[243, "neural_compressor.training.prepare_compression"]], "layerhistogramcollector (class in neural_compressor.utils.collect_layer_histogram)": [[244, "neural_compressor.utils.collect_layer_histogram.LayerHistogramCollector"]], "neural_compressor.utils.collect_layer_histogram": [[244, "module-neural_compressor.utils.collect_layer_histogram"]], "neural_compressor.utils.constant": [[245, "module-neural_compressor.utils.constant"]], "create_dataloader() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.create_dataloader"]], "create_dataset() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.create_dataset"]], "create_eval_func() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.create_eval_func"]], "create_train_func() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.create_train_func"]], "get_algorithm() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.get_algorithm"]], "get_func_from_config() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.get_func_from_config"]], "get_metrics() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.get_metrics"]], "get_postprocess() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.get_postprocess"]], "get_preprocess() (in module neural_compressor.utils.create_obj_from_config)": [[246, "neural_compressor.utils.create_obj_from_config.get_preprocess"]], "neural_compressor.utils.create_obj_from_config": [[246, "module-neural_compressor.utils.create_obj_from_config"]], "neural_compressor.utils.export": [[247, "module-neural_compressor.utils.export"]], "check_model() (in module neural_compressor.utils.export.qlinear2qdq)": [[248, "neural_compressor.utils.export.qlinear2qdq.check_model"]], "neural_compressor.utils.export.qlinear2qdq": [[248, "module-neural_compressor.utils.export.qlinear2qdq"]], "onnx_qlinear_to_qdq() (in module neural_compressor.utils.export.qlinear2qdq)": [[248, "neural_compressor.utils.export.qlinear2qdq.onnx_qlinear_to_qdq"]], "neural_compressor.utils.export.tf2onnx": [[249, "module-neural_compressor.utils.export.tf2onnx"]], "tf_to_fp32_onnx() (in module neural_compressor.utils.export.tf2onnx)": [[249, "neural_compressor.utils.export.tf2onnx.tf_to_fp32_onnx"]], "tf_to_int8_onnx() (in module neural_compressor.utils.export.tf2onnx)": [[249, "neural_compressor.utils.export.tf2onnx.tf_to_int8_onnx"]], "dynamic_quant_export() (in module neural_compressor.utils.export.torch2onnx)": [[250, "neural_compressor.utils.export.torch2onnx.dynamic_quant_export"]], "get_node_mapping() (in module neural_compressor.utils.export.torch2onnx)": [[250, "neural_compressor.utils.export.torch2onnx.get_node_mapping"]], "get_quantizable_onnx_ops() (in module neural_compressor.utils.export.torch2onnx)": [[250, "neural_compressor.utils.export.torch2onnx.get_quantizable_onnx_ops"]], "neural_compressor.utils.export.torch2onnx": [[250, "module-neural_compressor.utils.export.torch2onnx"]], "static_quant_export() (in module neural_compressor.utils.export.torch2onnx)": [[250, "neural_compressor.utils.export.torch2onnx.static_quant_export"]], "torch_to_fp32_onnx() (in module neural_compressor.utils.export.torch2onnx)": [[250, "neural_compressor.utils.export.torch2onnx.torch_to_fp32_onnx"]], "torch_to_int8_onnx() (in module neural_compressor.utils.export.torch2onnx)": [[250, "neural_compressor.utils.export.torch2onnx.torch_to_int8_onnx"]], "neural_compressor.utils": [[251, "module-neural_compressor.utils"]], "kl_divergence (class in neural_compressor.utils.kl_divergence)": [[252, "neural_compressor.utils.kl_divergence.KL_Divergence"]], "neural_compressor.utils.kl_divergence": [[252, "module-neural_compressor.utils.kl_divergence"]], "optimizedmodel (class in neural_compressor.utils.load_huggingface)": [[253, "neural_compressor.utils.load_huggingface.OptimizedModel"]], "export_compressed_model() (in module neural_compressor.utils.load_huggingface)": [[253, "neural_compressor.utils.load_huggingface.export_compressed_model"]], "neural_compressor.utils.load_huggingface": [[253, "module-neural_compressor.utils.load_huggingface"]], "save_for_huggingface_upstream() (in module neural_compressor.utils.load_huggingface)": [[253, "neural_compressor.utils.load_huggingface.save_for_huggingface_upstream"]], "logger (class in neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.Logger"]], "debug() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.debug"]], "error() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.error"]], "fatal() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.fatal"]], "info() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.info"]], "log() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.log"]], "neural_compressor.utils.logger": [[254, "module-neural_compressor.utils.logger"]], "warn() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.warn"]], "warning() (in module neural_compressor.utils.logger)": [[254, "neural_compressor.utils.logger.warning"]], "neural_compressor.utils.options": [[255, "module-neural_compressor.utils.options"]], "onnxrt (class in neural_compressor.utils.options)": [[255, "neural_compressor.utils.options.onnxrt"]], "is_int8_model() (in module neural_compressor.utils.pytorch)": [[256, "neural_compressor.utils.pytorch.is_int8_model"]], "load() (in module neural_compressor.utils.pytorch)": [[256, "neural_compressor.utils.pytorch.load"]], "load_weight_only() (in module neural_compressor.utils.pytorch)": [[256, "neural_compressor.utils.pytorch.load_weight_only"]], "neural_compressor.utils.pytorch": [[256, "module-neural_compressor.utils.pytorch"]], "recover_model_from_json() (in module neural_compressor.utils.pytorch)": [[256, "neural_compressor.utils.pytorch.recover_model_from_json"]], "captureoutputtofile (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.CaptureOutputToFile"]], "cpuinfo (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.CpuInfo"]], "dequantize() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.Dequantize"]], "dotdict (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.DotDict"]], "global_state (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.GLOBAL_STATE"]], "lazyimport (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.LazyImport"]], "mode (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.MODE"]], "opentry (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.OpEntry"]], "statistics (class in neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.Statistics"]], "alias_param() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.alias_param"]], "calculate_mse() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.calculate_mse"]], "check_key_exist() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.check_key_exist"]], "combine_histogram() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.combine_histogram"]], "compare_objects() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.compare_objects"]], "compute_sparsity() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.compute_sparsity"]], "deep_get() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.deep_get"]], "deep_set() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.deep_set"]], "dequantize_weight() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.dequantize_weight"]], "dump_class_attrs() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.dump_class_attrs"]], "dump_data_to_local() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.dump_data_to_local"]], "dump_elapsed_time() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.dump_elapsed_time"]], "dump_table() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.dump_table"]], "dump_table_to_csv() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.dump_table_to_csv"]], "equal_dicts() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.equal_dicts"]], "fault_tolerant_file() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.fault_tolerant_file"]], "get_all_fp32_data() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_all_fp32_data"]], "get_number_of_sockets() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_number_of_sockets"]], "get_op_list() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_op_list"]], "get_size() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_size"]], "get_tensor_histogram() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_tensor_histogram"]], "get_tensors_info() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_tensors_info"]], "get_tuning_history() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_tuning_history"]], "get_weights_details() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.get_weights_details"]], "load_data_from_pkl() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.load_data_from_pkl"]], "mse_metric_gap() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.mse_metric_gap"]], "neural_compressor.utils.utility": [[257, "module-neural_compressor.utils.utility"]], "print_op_list() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.print_op_list"]], "print_table() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.print_table"]], "recover() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.recover"]], "set_random_seed() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.set_random_seed"]], "set_resume_from() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.set_resume_from"]], "set_tensorboard() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.set_tensorboard"]], "set_workspace() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.set_workspace"]], "show_memory_info() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.show_memory_info"]], "singleton() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.singleton"]], "str2array() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.str2array"]], "time_limit() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.time_limit"]], "version1_eq_version2() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.utils.utility)": [[257, "neural_compressor.utils.utility.version1_lte_version2"]], "weightsdetails (class in neural_compressor.utils.weights_details)": [[258, "neural_compressor.utils.weights_details.WeightsDetails"]], "weightsstatistics (class in neural_compressor.utils.weights_details)": [[258, "neural_compressor.utils.weights_details.WeightsStatistics"]], "neural_compressor.utils.weights_details": [[258, "module-neural_compressor.utils.weights_details"]], "neural_compressor.version": [[259, "module-neural_compressor.version"]]}})